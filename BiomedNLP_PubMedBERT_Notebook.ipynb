{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiomedNLP_PubMedBERT_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimas263/nlp_bert_relation_extraction/blob/main/BiomedNLP_PubMedBERT_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/external-flaticons-lineal-color-flat-icons/64/undefined/external-big-data-smart-technology-flaticons-lineal-color-flat-icons-2.png\"/>  **NLP Research**\n",
        "# **Bert Relation Extraction in Biomedical using BiomedNLP-PubMedBERT model and pytorch**\n",
        "## <img src=\"https://img.icons8.com/external-fauzidea-flat-fauzidea/64/undefined/external-man-avatar-avatar-fauzidea-flat-fauzidea.png\"/> **`Dimas Dwi Putra`**"
      ],
      "metadata": {
        "id": "QfRM-ftWOKX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/tiny-color/48/undefined/experimental-code-tiny-color.png\"/> **Source Code on** [**Github**](https://github.com/Dimas263/nlp_bert_relation_extraction)\n",
        "#  <img src=\"https://img.icons8.com/glyph-neue/64/undefined/github.png\"/> [**NLP - Bert Relation Extraction Biomedical**](https://github.com/Dimas263/nlp_bert_relation_extraction)\n",
        "# <img src=\"https://img.icons8.com/color/48/undefined/microsoft-excel-2019--v1.png\"/> [**Relation Extraction Report**](https://docs.google.com/spreadsheets/d/1Q6JgAC5rDz4EM00BuAlEaraC0tm3oZoYqBu_F01md7s/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "Qj9_WaU3ehWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/color/48/undefined/1-circle--v1.png\"/>**Connect Google Storage**"
      ],
      "metadata": {
        "id": "DnGRwGq8MYbg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5ckZ9Tj94k0",
        "outputId": "db693143-dacc-4e35-82b3-f88c8c0409eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/color/48/undefined/2-circle--v1.png\"/>**Requirements**"
      ],
      "metadata": {
        "id": "7Lp6apVhMKi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install pandas==1.4.2\n",
        "# ! pip install matplotlib==3.5.1\n",
        "! pip install openpyxl==3.0.9\n",
        "# ! pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "! pip install transformers==4.18.0\n",
        "! pip install scikit-learn==1.0.2\n",
        "! pip install pickleshare==0.7.5\n",
        "! pip install pickle5==0.0.12"
      ],
      "metadata": {
        "id": "J-x7B1by9_kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/color/48/undefined/3-circle--v1.png\"/>**Check Device**"
      ],
      "metadata": {
        "id": "3SywR6WxMFML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "if USE_CUDA:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"\\nUsing GPU\")\n",
        "    print('\\nDevice name:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"\\nNo GPU available, using the CPU instead.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAXU70uWJU-j",
        "outputId": "c9dcb881-27a8-4b83-8b0a-7698410092ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using GPU\n",
            "\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/color/48/undefined/4-circle--v1.png\"/>**Data Preprocessing into `train set` and `test set`**"
      ],
      "metadata": {
        "id": "4V17I1hsoLOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/data_preprocessing.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXwMR1GVnhOs",
        "outputId": "797e3016-18a4-456e-e459-ae71f86f7d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative                583\n",
            "Treatment_of_disease    507\n",
            "Cause_of_disease        183\n",
            "Association              34\n",
            "Name: relation, dtype: int64\n",
            "============================\n",
            "total data : 1307\n",
            "\n",
            "success to create predict.txt\n",
            "success to create train.txt\n",
            "success to create test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/color/48/undefined/5-circle--v1.png\"/>**Preprocess Program**\n",
        "### **preprocess data with special token using `biobert pretrained model`**"
      ],
      "metadata": {
        "id": "DYNYPV4GHkm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_biomedNLP_preprocess.sh\""
      ],
      "metadata": {
        "id": "NW_8F7c_BncY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fa8384-647e-4cae-cf30-18f9e986878c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'output_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint/BiomedNLP-PubMedBERT/', 'bert_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/model/BiomedNLP-PubMedBERT/', 'data_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/', 'log_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/', 'main_log_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/BiomedNLP-PubMedBERT-main.log', 'preprocess_log_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/BiomedNLP-PubMedBERT-preprocess.log', 'num_tags': 4, 'seed': 123, 'gpu_ids': '0', 'max_seq_len': 128, 'eval_batch_size': 64, 'swa_start': 3, 'train_epochs': 100, 'dropout_prob': 0.1, 'lr': 1e-05, 'other_lr': 0.0001, 'max_grad_norm': 1, 'warmup_proportion': 0.1, 'weight_decay': 0.01, 'adam_epsilon': 1e-12, 'train_batch_size': 64, 'eval_model': True}\n",
            "==========================\n",
            "example_text : However, more studies need to further explore the roles of vitex agnus castus in fracture repair processes. \n",
            "example_id_label : 0\n",
            "example_id_tags : [59, 77, 81, 89]\n",
            "==========================\n",
            "==========================\n",
            "example_text :  Allanblackia monticola (75-300 mg/kg) did not cause significant modification of the oedema induced by serotonin. \n",
            "example_id_label : 0\n",
            "example_id_tags : [1, 23, 85, 91]\n",
            "==========================\n",
            "==========================\n",
            "example_text : CONCLUSIONS: Moderate pre-pregnancy caffeinated coffee consumption may have a protective association with GDM . \n",
            "example_id_label : 2\n",
            "example_id_tags : [48, 54, 106, 109]\n",
            "==========================\n",
            "==========================\n",
            "example_text :  Green tea and death from pneumonia in Japan: the Ohsaki cohort study. \n",
            "example_id_label : 0\n",
            "example_id_tags : [1, 10, 26, 35]\n",
            "==========================\n",
            "Convert 187 examples to features\n",
            "*** train_example-0 ***\n",
            "text: [CLS] [UNK] o w e v e r, [UNK] m o r e [UNK] s t u d i e s [UNK] n e e d [UNK] t o [UNK] f u r t h e r [UNK] e x p l o r e [UNK] t h e [UNK] r o l e s [UNK] o f [UNK] v i t e x [UNK] a g n u s [UNK] c a s t u s [UNK] i n [UNK] f r a c t u r e [UNK] r e p a i r [UNK] p r o c e s s e s. [UNK] [SEP]\n",
            "token_ids: [2, 1, 57, 65, 47, 64, 47, 60, 16, 1, 55, 57, 60, 47, 1, 61, 62, 63, 46, 51, 47, 61, 1, 56, 47, 47, 46, 1, 62, 57, 1, 48, 63, 60, 62, 50, 47, 60, 1, 47, 66, 58, 54, 57, 60, 47, 1, 62, 50, 47, 1, 60, 57, 54, 47, 61, 1, 57, 48, 1, 64, 51, 62, 47, 66, 1, 43, 49, 56, 63, 61, 1, 45, 43, 61, 62, 63, 61, 1, 51, 56, 1, 48, 60, 43, 45, 62, 63, 60, 47, 1, 60, 47, 58, 43, 51, 60, 1, 58, 60, 57, 45, 47, 61, 61, 47, 61, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 0\n",
            "ids: [60, 78, 82, 90]\n",
            "*** train_example-1 ***\n",
            "text: [CLS] [UNK] [UNK] l l a n b l a c k i a [UNK] m o n t i c o l a [UNK] ( 7 5 - 3 0 0 [UNK] m g / k g ) [UNK] d i d [UNK] n o t [UNK] c a u s e [UNK] s i g n i f i c a n t [UNK] m o d i f i c a t i o n [UNK] o f [UNK] t h e [UNK] o e d e m a [UNK] i n d u c e d [UNK] b y [UNK] s e r o t o n i n. [UNK] [SEP]\n",
            "token_ids: [2, 1, 1, 54, 54, 43, 56, 44, 54, 43, 45, 53, 51, 43, 1, 55, 57, 56, 62, 51, 45, 57, 54, 43, 1, 12, 27, 25, 17, 23, 20, 20, 1, 55, 49, 19, 53, 49, 13, 1, 46, 51, 46, 1, 56, 57, 62, 1, 45, 43, 63, 61, 47, 1, 61, 51, 49, 56, 51, 48, 51, 45, 43, 56, 62, 1, 55, 57, 46, 51, 48, 51, 45, 43, 62, 51, 57, 56, 1, 57, 48, 1, 62, 50, 47, 1, 57, 47, 46, 47, 55, 43, 1, 51, 56, 46, 63, 45, 47, 46, 1, 44, 67, 1, 61, 47, 60, 57, 62, 57, 56, 51, 56, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 0\n",
            "ids: [2, 24, 86, 92]\n",
            "*** train_example-2 ***\n",
            "text: [CLS] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] : [UNK] [UNK] o d e r a t e [UNK] p r e - p r e g n a n c y [UNK] c a f f e i n a t e d [UNK] c o f f e e [UNK] c o n s u m p t i o n [UNK] m a y [UNK] h a v e [UNK] a [UNK] p r o t e c t i v e [UNK] a s s o c i a t i o n [UNK] w i t h [UNK] [UNK] [UNK] [UNK] [UNK]. [UNK] [SEP]\n",
            "token_ids: [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 30, 1, 1, 57, 46, 47, 60, 43, 62, 47, 1, 58, 60, 47, 17, 58, 60, 47, 49, 56, 43, 56, 45, 67, 1, 45, 43, 48, 48, 47, 51, 56, 43, 62, 47, 46, 1, 45, 57, 48, 48, 47, 47, 1, 45, 57, 56, 61, 63, 55, 58, 62, 51, 57, 56, 1, 55, 43, 67, 1, 50, 43, 64, 47, 1, 43, 1, 58, 60, 57, 62, 47, 45, 62, 51, 64, 47, 1, 43, 61, 61, 57, 45, 51, 43, 62, 51, 57, 56, 1, 65, 51, 62, 50, 1, 1, 1, 1, 1, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 2\n",
            "ids: [49, 55, 107, 110]\n",
            "*** train_example-3 ***\n",
            "text: [CLS] [UNK] [UNK] r e e n [UNK] t e a [UNK] a n d [UNK] d e a t h [UNK] f r o m [UNK] p n e u m o n i a [UNK] i n [UNK] [UNK] a p a n : [UNK] t h e [UNK] [UNK] h s a k i [UNK] c o h o r t [UNK] s t u d y. [UNK] [SEP]\n",
            "token_ids: [2, 1, 1, 60, 47, 47, 56, 1, 62, 47, 43, 1, 43, 56, 46, 1, 46, 47, 43, 62, 50, 1, 48, 60, 57, 55, 1, 58, 56, 47, 63, 55, 57, 56, 51, 43, 1, 51, 56, 1, 1, 43, 58, 43, 56, 30, 1, 62, 50, 47, 1, 1, 50, 61, 43, 53, 51, 1, 45, 57, 50, 57, 60, 62, 1, 61, 62, 63, 46, 67, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 0\n",
            "ids: [2, 11, 27, 36]\n",
            "Build 187 features\n",
            "==========================\n",
            "example_text : Its effect on digitalis -caused atrial arrhythmias is unknown. \n",
            "example_id_label : 1\n",
            "example_id_tags : [14, 23, 32, 50]\n",
            "==========================\n",
            "==========================\n",
            "example_text : Total coffee consumption was not associated with an increased risk of coronary heart diseas e or stroke. \n",
            "example_id_label : 0\n",
            "example_id_tags : [6, 12, 70, 91]\n",
            "==========================\n",
            "==========================\n",
            "example_text : Efficacy of cancer prevention by high-selenium garlic is primarily dependent on the action of selenium. \n",
            "example_id_label : 2\n",
            "example_id_tags : [47, 53, 12, 18]\n",
            "==========================\n",
            "==========================\n",
            "example_text : Therefore the minimal optimal dose of garlic to inhibit colon cancer was 2.5%. \n",
            "example_id_label : 2\n",
            "example_id_tags : [38, 44, 56, 68]\n",
            "==========================\n",
            "Convert 47 examples to features\n",
            "*** dev_example-0 ***\n",
            "text: [CLS] [UNK] t s [UNK] e f f e c t [UNK] o n [UNK] d i g i t a l i s [UNK] - c a u s e d [UNK] a t r i a l [UNK] a r r h y t h m i a s [UNK] i s [UNK] u n k n o w n. [UNK] [SEP]\n",
            "token_ids: [2, 1, 62, 61, 1, 47, 48, 48, 47, 45, 62, 1, 57, 56, 1, 46, 51, 49, 51, 62, 43, 54, 51, 61, 1, 17, 45, 43, 63, 61, 47, 46, 1, 43, 62, 60, 51, 43, 54, 1, 43, 60, 60, 50, 67, 62, 50, 55, 51, 43, 61, 1, 51, 61, 1, 63, 56, 53, 56, 57, 65, 56, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 1\n",
            "ids: [15, 24, 33, 51]\n",
            "*** dev_example-1 ***\n",
            "text: [CLS] [UNK] o t a l [UNK] c o f f e e [UNK] c o n s u m p t i o n [UNK] w a s [UNK] n o t [UNK] a s s o c i a t e d [UNK] w i t h [UNK] a n [UNK] i n c r e a s e d [UNK] r i s k [UNK] o f [UNK] c o r o n a r y [UNK] h e a r t [UNK] d i s e a s [UNK] e [UNK] o r [UNK] s t r o k e. [UNK] [SEP]\n",
            "token_ids: [2, 1, 57, 62, 43, 54, 1, 45, 57, 48, 48, 47, 47, 1, 45, 57, 56, 61, 63, 55, 58, 62, 51, 57, 56, 1, 65, 43, 61, 1, 56, 57, 62, 1, 43, 61, 61, 57, 45, 51, 43, 62, 47, 46, 1, 65, 51, 62, 50, 1, 43, 56, 1, 51, 56, 45, 60, 47, 43, 61, 47, 46, 1, 60, 51, 61, 53, 1, 57, 48, 1, 45, 57, 60, 57, 56, 43, 60, 67, 1, 50, 47, 43, 60, 62, 1, 46, 51, 61, 47, 43, 61, 1, 47, 1, 57, 60, 1, 61, 62, 60, 57, 53, 47, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 0\n",
            "ids: [7, 13, 71, 92]\n",
            "*** dev_example-2 ***\n",
            "text: [CLS] [UNK] f f i c a c y [UNK] o f [UNK] c a n c e r [UNK] p r e v e n t i o n [UNK] b y [UNK] h i g h - s e l e n i u m [UNK] g a r l i c [UNK] i s [UNK] p r i m a r i l y [UNK] d e p e n d e n t [UNK] o n [UNK] t h e [UNK] a c t i o n [UNK] o f [UNK] s e l e n i u m. [UNK] [SEP]\n",
            "token_ids: [2, 1, 48, 48, 51, 45, 43, 45, 67, 1, 57, 48, 1, 45, 43, 56, 45, 47, 60, 1, 58, 60, 47, 64, 47, 56, 62, 51, 57, 56, 1, 44, 67, 1, 50, 51, 49, 50, 17, 61, 47, 54, 47, 56, 51, 63, 55, 1, 49, 43, 60, 54, 51, 45, 1, 51, 61, 1, 58, 60, 51, 55, 43, 60, 51, 54, 67, 1, 46, 47, 58, 47, 56, 46, 47, 56, 62, 1, 57, 56, 1, 62, 50, 47, 1, 43, 45, 62, 51, 57, 56, 1, 57, 48, 1, 61, 47, 54, 47, 56, 51, 63, 55, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 2\n",
            "ids: [48, 54, 13, 19]\n",
            "*** dev_example-3 ***\n",
            "text: [CLS] [UNK] h e r e f o r e [UNK] t h e [UNK] m i n i m a l [UNK] o p t i m a l [UNK] d o s e [UNK] o f [UNK] g a r l i c [UNK] t o [UNK] i n h i b i t [UNK] c o l o n [UNK] c a n c e r [UNK] w a s [UNK] 2. 5 %. [UNK] [SEP]\n",
            "token_ids: [2, 1, 50, 47, 60, 47, 48, 57, 60, 47, 1, 62, 50, 47, 1, 55, 51, 56, 51, 55, 43, 54, 1, 57, 58, 62, 51, 55, 43, 54, 1, 46, 57, 61, 47, 1, 57, 48, 1, 49, 43, 60, 54, 51, 45, 1, 62, 57, 1, 51, 56, 50, 51, 44, 51, 62, 1, 45, 57, 54, 57, 56, 1, 45, 43, 56, 45, 47, 60, 1, 65, 43, 61, 1, 22, 18, 25, 9, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 2\n",
            "ids: [39, 45, 57, 69]\n",
            "Build 47 features\n",
            "==========================\n",
            "example_text : Its effect on digitalis -caused atrial arrhythmias is unknown. \n",
            "example_id_label : 1\n",
            "example_id_tags : [14, 23, 32, 50]\n",
            "==========================\n",
            "==========================\n",
            "example_text : Total coffee consumption was not associated with an increased risk of coronary heart diseas e or stroke. \n",
            "example_id_label : 0\n",
            "example_id_tags : [6, 12, 70, 91]\n",
            "==========================\n",
            "==========================\n",
            "example_text : Efficacy of cancer prevention by high-selenium garlic is primarily dependent on the action of selenium. \n",
            "example_id_label : 2\n",
            "example_id_tags : [47, 53, 12, 18]\n",
            "==========================\n",
            "==========================\n",
            "example_text : Therefore the minimal optimal dose of garlic to inhibit colon cancer was 2.5%. \n",
            "example_id_label : 2\n",
            "example_id_tags : [38, 44, 56, 68]\n",
            "==========================\n",
            "Convert 47 examples to features\n",
            "*** test_example-0 ***\n",
            "text: [CLS] [UNK] t s [UNK] e f f e c t [UNK] o n [UNK] d i g i t a l i s [UNK] - c a u s e d [UNK] a t r i a l [UNK] a r r h y t h m i a s [UNK] i s [UNK] u n k n o w n. [UNK] [SEP]\n",
            "token_ids: [2, 1, 62, 61, 1, 47, 48, 48, 47, 45, 62, 1, 57, 56, 1, 46, 51, 49, 51, 62, 43, 54, 51, 61, 1, 17, 45, 43, 63, 61, 47, 46, 1, 43, 62, 60, 51, 43, 54, 1, 43, 60, 60, 50, 67, 62, 50, 55, 51, 43, 61, 1, 51, 61, 1, 63, 56, 53, 56, 57, 65, 56, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 1\n",
            "ids: [15, 24, 33, 51]\n",
            "*** test_example-1 ***\n",
            "text: [CLS] [UNK] o t a l [UNK] c o f f e e [UNK] c o n s u m p t i o n [UNK] w a s [UNK] n o t [UNK] a s s o c i a t e d [UNK] w i t h [UNK] a n [UNK] i n c r e a s e d [UNK] r i s k [UNK] o f [UNK] c o r o n a r y [UNK] h e a r t [UNK] d i s e a s [UNK] e [UNK] o r [UNK] s t r o k e. [UNK] [SEP]\n",
            "token_ids: [2, 1, 57, 62, 43, 54, 1, 45, 57, 48, 48, 47, 47, 1, 45, 57, 56, 61, 63, 55, 58, 62, 51, 57, 56, 1, 65, 43, 61, 1, 56, 57, 62, 1, 43, 61, 61, 57, 45, 51, 43, 62, 47, 46, 1, 65, 51, 62, 50, 1, 43, 56, 1, 51, 56, 45, 60, 47, 43, 61, 47, 46, 1, 60, 51, 61, 53, 1, 57, 48, 1, 45, 57, 60, 57, 56, 43, 60, 67, 1, 50, 47, 43, 60, 62, 1, 46, 51, 61, 47, 43, 61, 1, 47, 1, 57, 60, 1, 61, 62, 60, 57, 53, 47, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 0\n",
            "ids: [7, 13, 71, 92]\n",
            "*** test_example-2 ***\n",
            "text: [CLS] [UNK] f f i c a c y [UNK] o f [UNK] c a n c e r [UNK] p r e v e n t i o n [UNK] b y [UNK] h i g h - s e l e n i u m [UNK] g a r l i c [UNK] i s [UNK] p r i m a r i l y [UNK] d e p e n d e n t [UNK] o n [UNK] t h e [UNK] a c t i o n [UNK] o f [UNK] s e l e n i u m. [UNK] [SEP]\n",
            "token_ids: [2, 1, 48, 48, 51, 45, 43, 45, 67, 1, 57, 48, 1, 45, 43, 56, 45, 47, 60, 1, 58, 60, 47, 64, 47, 56, 62, 51, 57, 56, 1, 44, 67, 1, 50, 51, 49, 50, 17, 61, 47, 54, 47, 56, 51, 63, 55, 1, 49, 43, 60, 54, 51, 45, 1, 51, 61, 1, 58, 60, 51, 55, 43, 60, 51, 54, 67, 1, 46, 47, 58, 47, 56, 46, 47, 56, 62, 1, 57, 56, 1, 62, 50, 47, 1, 43, 45, 62, 51, 57, 56, 1, 57, 48, 1, 61, 47, 54, 47, 56, 51, 63, 55, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 2\n",
            "ids: [48, 54, 13, 19]\n",
            "*** test_example-3 ***\n",
            "text: [CLS] [UNK] h e r e f o r e [UNK] t h e [UNK] m i n i m a l [UNK] o p t i m a l [UNK] d o s e [UNK] o f [UNK] g a r l i c [UNK] t o [UNK] i n h i b i t [UNK] c o l o n [UNK] c a n c e r [UNK] w a s [UNK] 2. 5 %. [UNK] [SEP]\n",
            "token_ids: [2, 1, 50, 47, 60, 47, 48, 57, 60, 47, 1, 62, 50, 47, 1, 55, 51, 56, 51, 55, 43, 54, 1, 57, 58, 62, 51, 55, 43, 54, 1, 46, 57, 61, 47, 1, 57, 48, 1, 49, 43, 60, 54, 51, 45, 1, 62, 57, 1, 51, 56, 50, 51, 44, 51, 62, 1, 45, 57, 54, 57, 56, 1, 45, 43, 56, 45, 47, 60, 1, 65, 43, 61, 1, 22, 18, 25, 9, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "labels: 2\n",
            "ids: [39, 45, 57, 69]\n",
            "Build 47 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/color/48/undefined/6-circle--v1.png\"/>**Main Program**\n",
        "### **`train`, `eval`, create new `model pytorch`, test model , <br>compute `cross validation`, `f-1 score`, and <br>test predict data with new model `.pt`**"
      ],
      "metadata": {
        "id": "167FnNFAGdGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_run_main = open(\"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_biomedNLP_main.sh\", \"r\")\n",
        "print(f_run_main.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di73LYnvvI40",
        "outputId": "ba89c374-e0f9-4744-cd60-5fe820c4faba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env bash\n",
            "python \"drive/MyDrive/Colab Notebooks/bert_relation_extraction/main.py\" \\\n",
            "--bert_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/model/BiomedNLP-PubMedBERT/\" \\\n",
            "--data_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/\" \\\n",
            "--log_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/\" \\\n",
            "--main_log_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/BiomedNLP-PubMedBERT-main.log\" \\\n",
            "--preprocess_log_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/BiomedNLP-PubMedBERT-preprocess.log\" \\\n",
            "--output_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint/BiomedNLP-PubMedBERT/\" \\\n",
            "--num_tags=4 \\\n",
            "--seed=123 \\\n",
            "--gpu_ids=\"0\" \\\n",
            "--max_seq_len=128 \\\n",
            "--lr=1e-5 \\\n",
            "--other_lr=1e-4 \\\n",
            "--train_batch_size=16 \\\n",
            "--train_epochs=100 \\\n",
            "--eval_batch_size=16 \\\n",
            "--dropout_prob=0.1 \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_biomedNLP_main.sh\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGtbTcn1wvPG",
        "outputId": "5d4ebbf0-bf61-4473-c6ff-e0f6b14a0af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.553112 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7344\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：30 step:371/1200 loss：0.078333\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.571493 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7344\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:372/1200 loss：0.091423\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.579675 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7344\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:373/1200 loss：0.159688\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.493654 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:374/1200 loss：0.153462\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.420970 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7342\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:375/1200 loss：0.078692\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.394518 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7497\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:376/1200 loss：0.102512\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.393385 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7648\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:377/1200 loss：0.043730\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.424111 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7442\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:378/1200 loss：0.037600\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.463464 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7462\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:379/1200 loss：0.120585\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.484054 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7645\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:380/1200 loss：0.057428\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.524420 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7645\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:381/1200 loss：0.069458\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.532299 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：31 step:382/1200 loss：0.061740\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.563998 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：31 step:383/1200 loss：0.056649\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.614773 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:384/1200 loss：0.077028\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.675294 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:385/1200 loss：0.072391\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.653650 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:386/1200 loss：0.074046\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.667710 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:387/1200 loss：0.087714\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.630578 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:388/1200 loss：0.083369\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.531456 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:389/1200 loss：0.102742\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.517961 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7773\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:390/1200 loss：0.061026\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.542251 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7624\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:391/1200 loss：0.076930\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.663289 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7898\n",
            "------------>Save best model\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:392/1200 loss：0.053927\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.823338 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7898\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:393/1200 loss：0.080397\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.937247 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7748\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：32 step:394/1200 loss：0.119896\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.974859 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7512\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：32 step:395/1200 loss：0.132749\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.943547 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7390\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:396/1200 loss：0.056750\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.941575 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7142\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:397/1200 loss：0.038583\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.942142 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7142\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:398/1200 loss：0.110747\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.884333 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7371\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:399/1200 loss：0.146270\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.772356 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7333\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:400/1200 loss：0.111082\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.716374 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7157\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:401/1200 loss：0.064215\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.751201 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6990\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:402/1200 loss：0.077656\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.830599 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7134\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:403/1200 loss：0.048953\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.892333 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7278\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:404/1200 loss：0.105396\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.973741 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7447\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:405/1200 loss：0.097034\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.124632 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7611\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：33 step:406/1200 loss：0.075241\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.212600 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7479\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：33 step:407/1200 loss：0.032104\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.263567 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:408/1200 loss：0.052576\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.295332 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7624\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:409/1200 loss：0.123542\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.202164 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:410/1200 loss：0.050381\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.148315 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7313\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:411/1200 loss：0.138687\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.191840 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7333\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:412/1200 loss：0.082916\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.221425 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7333\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:413/1200 loss：0.047233\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.221977 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7333\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:414/1200 loss：0.081915\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.177089 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:415/1200 loss：0.086472\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.104662 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:416/1200 loss：0.051240\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.059736 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7627\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:417/1200 loss：0.052269\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.022752 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7278\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：34 step:418/1200 loss：0.057970\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.005768 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7278\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：34 step:419/1200 loss：0.093394\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.083465 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:420/1200 loss：0.070288\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.160766 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:421/1200 loss：0.088430\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.161386 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:422/1200 loss：0.033067\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.163282 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:423/1200 loss：0.085722\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.225861 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:424/1200 loss：0.071996\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.337325 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7645\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:425/1200 loss：0.093688\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.420782 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7412\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:426/1200 loss：0.059418\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.527692 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7412\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:427/1200 loss：0.111245\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.508721 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7412\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:428/1200 loss：0.110936\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.294241 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:429/1200 loss：0.049965\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.113971 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：35 step:430/1200 loss：0.038129\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.035135 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：35 step:431/1200 loss：0.083791\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.959628 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7498\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:432/1200 loss：0.026500\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.902465 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7234\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:433/1200 loss：0.039508\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.942835 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:434/1200 loss：0.062108\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.970863 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7498\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:435/1200 loss：0.049859\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.007831 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7339\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:436/1200 loss：0.016943\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.045601 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7339\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:437/1200 loss：0.087379\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.143296 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7134\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:438/1200 loss：0.038546\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.266338 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:439/1200 loss：0.044676\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.352908 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:440/1200 loss：0.066186\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.469815 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:441/1200 loss：0.088739\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.481627 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：36 step:442/1200 loss：0.157493\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.405849 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：36 step:443/1200 loss：0.045229\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.401080 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:444/1200 loss：0.025312\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.395914 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7061\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:445/1200 loss：0.070562\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.382574 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7452\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:446/1200 loss：0.121666\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.365805 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7321\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:447/1200 loss：0.094866\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.336076 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7134\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:448/1200 loss：0.054855\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.286593 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7134\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:449/1200 loss：0.049565\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.257941 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7302\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:450/1200 loss：0.037299\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.250083 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7102\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:451/1200 loss：0.042780\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.258927 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:452/1200 loss：0.035952\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.286937 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:453/1200 loss：0.056296\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.320565 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：37 step:454/1200 loss：0.191087\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.262449 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：37 step:455/1200 loss：0.066305\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.145168 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7032\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:456/1200 loss：0.039975\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.025610 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6842\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:457/1200 loss：0.026853\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.924849 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7180\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:458/1200 loss：0.074879\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.911551 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6985\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:459/1200 loss：0.049612\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.932703 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7017\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:460/1200 loss：0.036627\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.989615 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7032\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:461/1200 loss：0.023004\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.036887 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:462/1200 loss：0.032754\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.093465 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7444\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:463/1200 loss：0.075692\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.101783 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7444\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:464/1200 loss：0.029562\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.121085 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7444\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:465/1200 loss：0.122388\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.061802 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7266\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：38 step:466/1200 loss：0.165516\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.022897 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：38 step:467/1200 loss：0.031492\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.003783 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7445\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:468/1200 loss：0.058343\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.028617 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7445\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:469/1200 loss：0.017515\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.047389 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7445\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:470/1200 loss：0.048875\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.101540 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:471/1200 loss：0.040582\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.146541 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7466\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:472/1200 loss：0.121387\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.905101 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7641\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:473/1200 loss：0.123407\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.621786 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7807\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:474/1200 loss：0.069215\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.454027 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7622\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:475/1200 loss：0.042372\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.419104 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7456\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:476/1200 loss：0.053925\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.555550 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7491\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:477/1200 loss：0.049024\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.833555 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7219\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：39 step:478/1200 loss：0.107553\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.766566 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7219\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：39 step:479/1200 loss：0.077603\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.763465 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7360\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:480/1200 loss：0.247124\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.428744 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:481/1200 loss：0.107189\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.191576 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7726\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:482/1200 loss：0.043037\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.104413 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7903\n",
            "------------>Save best model\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:483/1200 loss：0.022884\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.141310 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7740\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:484/1200 loss：0.095782\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.260247 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7967\n",
            "------------>Save best model\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:485/1200 loss：0.115337\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.435574 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:486/1200 loss：0.019924\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.585797 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:487/1200 loss：0.068414\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.611995 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:488/1200 loss：0.019220\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.642504 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7780\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:489/1200 loss：0.023706\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.651848 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7969\n",
            "------------>Save best model\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：40 step:490/1200 loss：0.027949\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.655721 accuracy：0.7660 micro_f1：0.7660 macro_f1：0.8119\n",
            "------------>Save best model\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：40 step:491/1200 loss：0.097982\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.576167 accuracy：0.7660 micro_f1：0.7660 macro_f1：0.8119\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:492/1200 loss：0.020397\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.518270 accuracy：0.7660 micro_f1：0.7660 macro_f1：0.8120\n",
            "------------>Save best model\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:493/1200 loss：0.068658\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.455263 accuracy：0.7660 micro_f1：0.7660 macro_f1：0.8120\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:494/1200 loss：0.014576\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.406015 accuracy：0.7660 micro_f1：0.7660 macro_f1：0.8120\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:495/1200 loss：0.043662\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.328211 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7861\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:496/1200 loss：0.075112\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.436168 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7729\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:497/1200 loss：0.048346\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.492114 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7515\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:498/1200 loss：0.032402\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.513435 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7515\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:499/1200 loss：0.021159\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.507690 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7515\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:500/1200 loss：0.063656\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.455056 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7344\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:501/1200 loss：0.025952\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.426459 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7344\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：41 step:502/1200 loss：0.015693\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.403716 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7344\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：41 step:503/1200 loss：0.138066\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.338411 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7444\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:504/1200 loss：0.171282\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.282908 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7492\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:505/1200 loss：0.036984\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.300154 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7666\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:506/1200 loss：0.077836\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.346744 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7666\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:507/1200 loss：0.029602\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.408080 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7812\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:508/1200 loss：0.021104\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.471928 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7625\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:509/1200 loss：0.017906\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.544434 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7433\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:510/1200 loss：0.022501\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.628506 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:511/1200 loss：0.034174\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.699309 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:512/1200 loss：0.035398\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.792067 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:513/1200 loss：0.051015\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.898135 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7758\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：42 step:514/1200 loss：0.016335\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.998668 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7780\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：42 step:515/1200 loss：0.049774\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.165232 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7718\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:516/1200 loss：0.016612\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.319377 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7895\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:517/1200 loss：0.153507\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.179822 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7563\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:518/1200 loss：0.065179\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.944862 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7563\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:519/1200 loss：0.027683\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.787767 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:520/1200 loss：0.092077\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.699393 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:521/1200 loss：0.102113\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.634976 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7630\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:522/1200 loss：0.033632\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.598392 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7630\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:523/1200 loss：0.029909\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.581740 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7630\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:524/1200 loss：0.037125\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.572214 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7630\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:525/1200 loss：0.028436\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.565063 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7630\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：43 step:526/1200 loss：0.030464\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.568585 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7630\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：43 step:527/1200 loss：0.032246\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.607648 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7630\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:528/1200 loss：0.079519\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.616476 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7630\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:529/1200 loss：0.100653\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.661234 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7227\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:530/1200 loss：0.033105\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.765746 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:531/1200 loss：0.045484\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.860627 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:532/1200 loss：0.016284\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.988953 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7638\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:533/1200 loss：0.012187\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.140385 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7645\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:534/1200 loss：0.032913\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.288271 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7645\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:535/1200 loss：0.012628\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.418272 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7690\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:536/1200 loss：0.213715\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.965194 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7746\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:537/1200 loss：0.028227\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.767362 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7421\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：44 step:538/1200 loss：0.048801\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.759676 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7790\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：44 step:539/1200 loss：0.023521\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.825196 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7644\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:540/1200 loss：0.075786\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.868682 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7644\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:541/1200 loss：0.032342\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.875288 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7644\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:542/1200 loss：0.024628\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.876267 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7656\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:543/1200 loss：0.019914\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.876215 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7656\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:544/1200 loss：0.060025\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.858554 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7808\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:545/1200 loss：0.028547\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.827286 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7982\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:546/1200 loss：0.222238\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.812473 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:547/1200 loss：0.059789\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.876034 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7937\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:548/1200 loss：0.038804\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.986294 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:549/1200 loss：0.038472\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.033417 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7767\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：45 step:550/1200 loss：0.020068\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.079173 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7767\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：45 step:551/1200 loss：0.025326\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.116721 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7767\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:552/1200 loss：0.062159\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.027019 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7767\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:553/1200 loss：0.032968\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.966059 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:554/1200 loss：0.076559\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.041481 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7767\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:555/1200 loss：0.025131\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.095083 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7767\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:556/1200 loss：0.013449\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.152347 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7767\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:557/1200 loss：0.026212\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.185441 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7620\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:558/1200 loss：0.024960\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.186104 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7620\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:559/1200 loss：0.165053\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.879880 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:560/1200 loss：0.046408\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.702185 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:561/1200 loss：0.108135\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.551706 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7821\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：46 step:562/1200 loss：0.017244\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.588020 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.6735\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：46 step:563/1200 loss：0.037542\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.729627 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.6705\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:564/1200 loss：0.029043\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.821458 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.6705\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:565/1200 loss：0.034099\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.835803 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.6898\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:566/1200 loss：0.080376\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.669073 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.6540\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:567/1200 loss：0.042614\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.527933 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7075\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:568/1200 loss：0.045914\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.512253 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7942\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:569/1200 loss：0.026798\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.612016 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:570/1200 loss：0.012401\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.782349 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7542\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:571/1200 loss：0.048706\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.045532 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:572/1200 loss：0.024243\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.356292 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7551\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:573/1200 loss：0.017807\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.649147 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7431\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：47 step:574/1200 loss：0.052342\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.768336 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7431\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：47 step:575/1200 loss：0.197483\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.421443 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7419\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:576/1200 loss：0.079967\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.960327 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:577/1200 loss：0.017751\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.672096 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:578/1200 loss：0.016312\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.537565 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7608\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:579/1200 loss：0.016506\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.510217 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7798\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:580/1200 loss：0.025188\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.567647 accuracy：0.7872 micro_f1：0.7872 macro_f1：0.8343\n",
            "------------>Save best model\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:581/1200 loss：0.045461\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.624705 accuracy：0.7660 micro_f1：0.7660 macro_f1：0.8193\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:582/1200 loss：0.016844\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.699222 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7862\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:583/1200 loss：0.147495\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.619848 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.8042\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:584/1200 loss：0.016191\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.563705 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.8016\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:585/1200 loss：0.032846\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.531155 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7798\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：48 step:586/1200 loss：0.065122\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.539133 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：48 step:587/1200 loss：0.101875\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.894069 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:588/1200 loss：0.025780\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.378586 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7333\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:589/1200 loss：0.020362\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.804778 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7315\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:590/1200 loss：0.080875\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.890143 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7185\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:591/1200 loss：0.069321\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.832889 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7321\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:592/1200 loss：0.026145\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.731193 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7321\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:593/1200 loss：0.056778\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.484482 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7647\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:594/1200 loss：0.022927\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.251265 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7479\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:595/1200 loss：0.067653\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.881937 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7426\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:596/1200 loss：0.028125\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.632537 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7426\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:597/1200 loss：0.035226\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.524473 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7518\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：49 step:598/1200 loss：0.012193\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.649941 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7867\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：49 step:599/1200 loss：0.030419\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.874244 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7678\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:600/1200 loss：0.026095\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.074482 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7288\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:601/1200 loss：0.027968\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.257856 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7076\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:602/1200 loss：0.066416\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.198567 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7288\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:603/1200 loss：0.185327\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.757065 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7663\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:604/1200 loss：0.026548\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.597184 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7659\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:605/1200 loss：0.031379\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.783586 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:606/1200 loss：0.005393\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.162113 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:607/1200 loss：0.023128\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.540314 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7566\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:608/1200 loss：0.038904\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.832196 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7441\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:609/1200 loss：0.168501\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.745242 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7566\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：50 step:610/1200 loss：0.068806\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.455379 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7542\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：50 step:611/1200 loss：0.009415\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.210461 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7563\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:612/1200 loss：0.015119\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.003684 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:613/1200 loss：0.026380\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.854453 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7112\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:614/1200 loss：0.197574\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.658542 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7641\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:615/1200 loss：0.077892\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.672198 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7531\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:616/1200 loss：0.024342\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.889590 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7287\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:617/1200 loss：0.097063\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.995074 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7287\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:618/1200 loss：0.026760\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.978636 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7287\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:619/1200 loss：0.053084\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.805606 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7506\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:620/1200 loss：0.046233\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.599276 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7882\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:621/1200 loss：0.059685\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.468384 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7696\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：51 step:622/1200 loss：0.022548\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.475619 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：51 step:623/1200 loss：0.156699\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.823549 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7611\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:624/1200 loss：0.024052\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.330459 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7556\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:625/1200 loss：0.022731\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.858010 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6915\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:626/1200 loss：0.012421\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.355358 accuracy：0.5745 micro_f1：0.5745 macro_f1：0.6763\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:627/1200 loss：0.047051\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.684085 accuracy：0.5745 micro_f1：0.5745 macro_f1：0.6763\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:628/1200 loss：0.051383\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.755372 accuracy：0.5745 micro_f1：0.5745 macro_f1：0.6763\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:629/1200 loss：0.102844\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.418786 accuracy：0.5745 micro_f1：0.5745 macro_f1：0.6763\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:630/1200 loss：0.047411\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.986826 accuracy：0.5745 micro_f1：0.5745 macro_f1：0.6786\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:631/1200 loss：0.047816\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.544827 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6914\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:632/1200 loss：0.014186\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.220298 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7363\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:633/1200 loss：0.111603\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.905213 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6851\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：52 step:634/1200 loss：0.008518\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.819697 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6232\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：52 step:635/1200 loss：0.035375\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.916673 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.6436\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:636/1200 loss：0.044451\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.127162 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.5833\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:637/1200 loss：0.028714\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.398090 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.6500\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:638/1200 loss：0.123254\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.335828 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.6348\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:639/1200 loss：0.091251\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.084102 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7523\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:640/1200 loss：0.018918\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.890325 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7372\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:641/1200 loss：0.060650\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.752613 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7381\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:642/1200 loss：0.029584\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.735300 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:643/1200 loss：0.021096\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.838898 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6984\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:644/1200 loss：0.036805\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.081482 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:645/1200 loss：0.012460\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.386574 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7372\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：53 step:646/1200 loss：0.031694\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.732432 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7372\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：53 step:647/1200 loss：0.035044\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.981580 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7142\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:648/1200 loss：0.060871\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.078243 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7185\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:649/1200 loss：0.297953\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.723356 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7638\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:650/1200 loss：0.081196\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.491141 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7895\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:651/1200 loss：0.048588\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.252602 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:652/1200 loss：0.022748\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.057012 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:653/1200 loss：0.008034\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.906907 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7542\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:654/1200 loss：0.015660\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.792964 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:655/1200 loss：0.014161\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.721040 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:656/1200 loss：0.060358\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.721240 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:657/1200 loss：0.007846\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.726399 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7573\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：54 step:658/1200 loss：0.061119\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.794230 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：54 step:659/1200 loss：0.006228\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.870007 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:660/1200 loss：0.031692\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.917806 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7213\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:661/1200 loss：0.037015\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.954844 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:662/1200 loss：0.011428\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.991352 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:663/1200 loss：0.053422\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.065681 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7406\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:664/1200 loss：0.006483\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.137627 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7406\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:665/1200 loss：0.020441\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.193892 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7406\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:666/1200 loss：0.010977\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.243118 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:667/1200 loss：0.017306\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.268082 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:668/1200 loss：0.033430\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.264306 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7784\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:669/1200 loss：0.037207\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.262968 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7784\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：55 step:670/1200 loss：0.026173\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.259278 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7807\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：55 step:671/1200 loss：0.032278\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.198034 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7807\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:672/1200 loss：0.010822\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.148463 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7807\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:673/1200 loss：0.055017\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.023739 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7807\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:674/1200 loss：0.065495\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.956849 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7624\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:675/1200 loss：0.013011\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.884427 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7444\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:676/1200 loss：0.013852\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.833640 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7444\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:677/1200 loss：0.018433\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.794726 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7194\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:678/1200 loss：0.027207\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.748413 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:679/1200 loss：0.031399\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.704517 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7006\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:680/1200 loss：0.062475\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.705517 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:681/1200 loss：0.012599\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.707278 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7006\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：56 step:682/1200 loss：0.017584\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.701044 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7006\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：56 step:683/1200 loss：0.033097\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.694119 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:684/1200 loss：0.011181\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.686866 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7271\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:685/1200 loss：0.018042\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.687282 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:686/1200 loss：0.031424\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.692771 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:687/1200 loss：0.022601\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.719195 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7542\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:688/1200 loss：0.017962\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.763382 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7542\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:689/1200 loss：0.016245\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.822399 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7542\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:690/1200 loss：0.030000\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.864197 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7542\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:691/1200 loss：0.047998\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.951138 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:692/1200 loss：0.012622\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.027659 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:693/1200 loss：0.006319\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.099635 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：57 step:694/1200 loss：0.014209\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.155409 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：57 step:695/1200 loss：0.010776\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.194269 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:696/1200 loss：0.005753\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.229976 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:697/1200 loss：0.024479\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.224789 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:698/1200 loss：0.005246\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.219641 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:699/1200 loss：0.084109\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.283868 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7406\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:700/1200 loss：0.031116\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.306018 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7406\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:701/1200 loss：0.005923\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.322831 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:702/1200 loss：0.016534\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.333431 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:703/1200 loss：0.013008\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.357713 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:704/1200 loss：0.028416\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.348567 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:705/1200 loss：0.010043\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.345775 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：58 step:706/1200 loss：0.015174\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.314909 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：58 step:707/1200 loss：0.008237\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.278319 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:708/1200 loss：0.018507\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.213663 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:709/1200 loss：0.009373\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.154486 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:710/1200 loss：0.008393\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.091205 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7748\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:711/1200 loss：0.010677\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.033534 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7718\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:712/1200 loss：0.048629\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.920065 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:713/1200 loss：0.009998\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.832187 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:714/1200 loss：0.005914\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.770412 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:715/1200 loss：0.014535\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.738302 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:716/1200 loss：0.009138\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.714872 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:717/1200 loss：0.013945\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.702648 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：59 step:718/1200 loss：0.027089\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.713342 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：59 step:719/1200 loss：0.011289\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.733001 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:720/1200 loss：0.010420\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.762672 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7391\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:721/1200 loss：0.024940\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.793729 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7391\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:722/1200 loss：0.017033\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.840004 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7391\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:723/1200 loss：0.017062\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.903759 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7528\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:724/1200 loss：0.004420\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.965098 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7528\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:725/1200 loss：0.012563\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.033342 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:726/1200 loss：0.006752\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.093789 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:727/1200 loss：0.015341\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.142204 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:728/1200 loss：0.005773\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.190558 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:729/1200 loss：0.007344\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.230890 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：60 step:730/1200 loss：0.017231\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.220531 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：60 step:731/1200 loss：0.012600\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.233849 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:732/1200 loss：0.011210\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.250926 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:733/1200 loss：0.025403\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.303739 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:734/1200 loss：0.011005\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.352415 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:735/1200 loss：0.014738\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.386110 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:736/1200 loss：0.016250\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.400891 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:737/1200 loss：0.013414\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.396817 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:738/1200 loss：0.004109\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.393949 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:739/1200 loss：0.018870\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.402438 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:740/1200 loss：0.010499\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.411485 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:741/1200 loss：0.011390\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.410625 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：61 step:742/1200 loss：0.009741\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.421226 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：61 step:743/1200 loss：0.013434\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.425885 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:744/1200 loss：0.060998\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.285529 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:745/1200 loss：0.025884\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.152519 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7238\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:746/1200 loss：0.012523\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.068496 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7098\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:747/1200 loss：0.007691\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.029316 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:748/1200 loss：0.017531\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.024927 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7798\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:749/1200 loss：0.008963\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.034416 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7798\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:750/1200 loss：0.020225\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.007711 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7798\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:751/1200 loss：0.056562\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.987919 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7798\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:752/1200 loss：0.008124\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.972101 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7659\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:753/1200 loss：0.011111\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.970442 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7659\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：62 step:754/1200 loss：0.015663\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.973994 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7518\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：62 step:755/1200 loss：0.004468\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.986249 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:756/1200 loss：0.011580\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.004225 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:757/1200 loss：0.009916\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.022457 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:758/1200 loss：0.008867\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.049239 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:759/1200 loss：0.015927\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.083625 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:760/1200 loss：0.062730\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.261066 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7201\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:761/1200 loss：0.011043\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.440205 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7056\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:762/1200 loss：0.004506\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.618251 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7056\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:763/1200 loss：0.135486\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.593035 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7056\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:764/1200 loss：0.011231\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.556156 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7056\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:765/1200 loss：0.012523\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.514517 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7201\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：63 step:766/1200 loss：0.008206\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.473688 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：63 step:767/1200 loss：0.004118\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.435449 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:768/1200 loss：0.006938\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.403759 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:769/1200 loss：0.005668\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.370451 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:770/1200 loss：0.008299\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.340648 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:771/1200 loss：0.009808\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.310043 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:772/1200 loss：0.007795\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.300012 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:773/1200 loss：0.003916\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.293007 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7271\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:774/1200 loss：0.007897\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.279643 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7271\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:775/1200 loss：0.013718\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.238465 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7271\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:776/1200 loss：0.007473\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.203377 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:777/1200 loss：0.014117\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.172015 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：64 step:778/1200 loss：0.022039\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.160777 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：64 step:779/1200 loss：0.014006\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.161511 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:780/1200 loss：0.010124\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.157357 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:781/1200 loss：0.092254\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.254948 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:782/1200 loss：0.014445\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.381033 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:783/1200 loss：0.017638\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.450366 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:784/1200 loss：0.009232\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.509408 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:785/1200 loss：0.009458\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.556447 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:786/1200 loss：0.014572\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.592396 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:787/1200 loss：0.011149\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.613484 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7258\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:788/1200 loss：0.010505\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.617053 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7438\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:789/1200 loss：0.006122\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.609776 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7438\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：65 step:790/1200 loss：0.011652\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.596226 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7438\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：65 step:791/1200 loss：0.017840\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.544538 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7438\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:792/1200 loss：0.007948\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.483807 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:793/1200 loss：0.005057\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.427322 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7591\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:794/1200 loss：0.018523\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.323558 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:795/1200 loss：0.012142\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.227085 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:796/1200 loss：0.021826\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.117299 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:797/1200 loss：0.025151\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.990081 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:798/1200 loss：0.007098\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.897127 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:799/1200 loss：0.012234\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.836122 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7608\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:800/1200 loss：0.010057\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.808262 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:801/1200 loss：0.009937\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.803974 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7659\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：66 step:802/1200 loss：0.007447\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.821438 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7659\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：66 step:803/1200 loss：0.013499\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.834968 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7650\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:804/1200 loss：0.011680\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.843455 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7650\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:805/1200 loss：0.023559\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.862075 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7835\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:806/1200 loss：0.016067\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.851784 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7835\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:807/1200 loss：0.016191\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.827701 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7650\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:808/1200 loss：0.008425\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.802266 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7650\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:809/1200 loss：0.015935\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.791029 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7650\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:810/1200 loss：0.010556\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.780344 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7659\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:811/1200 loss：0.011754\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.785662 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:812/1200 loss：0.003101\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.810131 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:813/1200 loss：0.008243\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.856208 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：67 step:814/1200 loss：0.006047\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.915282 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：67 step:815/1200 loss：0.004695\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.980210 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:816/1200 loss：0.012496\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.033580 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:817/1200 loss：0.004215\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.087124 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:818/1200 loss：0.013701\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.120930 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:819/1200 loss：0.004937\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.139747 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:820/1200 loss：0.010764\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.151380 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:821/1200 loss：0.006730\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.159345 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7417\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:822/1200 loss：0.013427\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.144851 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:823/1200 loss：0.005850\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.126446 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:824/1200 loss：0.030980\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.089181 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:825/1200 loss：0.013728\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.084145 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：68 step:826/1200 loss：0.010576\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.101608 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：68 step:827/1200 loss：0.007023\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.123195 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7072\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:828/1200 loss：0.049522\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.084932 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7072\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:829/1200 loss：0.035561\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.145657 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7072\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:830/1200 loss：0.006683\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.209785 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7072\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:831/1200 loss：0.015888\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.305827 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7072\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:832/1200 loss：0.010653\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.394252 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6949\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:833/1200 loss：0.005694\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.486501 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6949\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:834/1200 loss：0.004110\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.569386 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6851\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:835/1200 loss：0.018179\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.594016 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6851\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:836/1200 loss：0.011899\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.602393 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6851\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:837/1200 loss：0.006559\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.612194 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6851\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：69 step:838/1200 loss：0.009322\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.613728 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7185\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：69 step:839/1200 loss：0.014651\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.565339 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7333\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:840/1200 loss：0.010563\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.560517 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7333\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:841/1200 loss：0.016008\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.524441 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:842/1200 loss：0.009581\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.502364 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:843/1200 loss：0.004791\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.485357 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7463\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:844/1200 loss：0.003769\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.466344 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7438\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:845/1200 loss：0.016213\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.388519 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7438\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:846/1200 loss：0.009188\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.305419 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7438\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:847/1200 loss：0.007498\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.231651 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7271\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:848/1200 loss：0.005713\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.173509 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7271\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:849/1200 loss：0.008158\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.109864 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7271\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：70 step:850/1200 loss：0.009195\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.058500 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7271\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：70 step:851/1200 loss：0.006740\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.023838 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:852/1200 loss：0.008138\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：2.995193 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7400\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:853/1200 loss：0.054507\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.388011 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7238\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:854/1200 loss：0.008178\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.812785 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:855/1200 loss：0.010165\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.035820 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:856/1200 loss：0.015922\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.193674 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:857/1200 loss：0.006815\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.304824 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7405\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:858/1200 loss：0.008487\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.397934 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7556\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:859/1200 loss：0.147404\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.527912 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7405\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:860/1200 loss：0.020475\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.634215 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7314\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:861/1200 loss：0.018009\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.722590 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7159\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：71 step:862/1200 loss：0.021689\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.759910 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7034\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：71 step:863/1200 loss：0.006378\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.791392 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6907\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:864/1200 loss：0.006503\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.803482 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6907\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:865/1200 loss：0.030228\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.647184 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6881\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:866/1200 loss：0.008888\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.476129 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6854\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:867/1200 loss：0.005553\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.316189 accuracy：0.5745 micro_f1：0.5745 macro_f1：0.6721\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:868/1200 loss：0.020002\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.184884 accuracy：0.5532 micro_f1：0.5532 macro_f1：0.6561\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:869/1200 loss：0.011483\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.051265 accuracy：0.5532 micro_f1：0.5532 macro_f1：0.6561\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:870/1200 loss：0.009620\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.935562 accuracy：0.5532 micro_f1：0.5532 macro_f1：0.6561\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:871/1200 loss：0.011909\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.841309 accuracy：0.5532 micro_f1：0.5532 macro_f1：0.6561\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:872/1200 loss：0.019595\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.758224 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6934\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:873/1200 loss：0.014762\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.687374 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6934\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：72 step:874/1200 loss：0.052910\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.571087 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7254\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：72 step:875/1200 loss：0.066190\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.561181 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6893\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:876/1200 loss：0.008645\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.613085 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6984\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:877/1200 loss：0.018589\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.700806 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6984\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:878/1200 loss：0.005546\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.802920 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7238\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:879/1200 loss：0.008420\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.903657 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7287\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:880/1200 loss：0.006869\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.003430 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7473\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:881/1200 loss：0.020880\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.078974 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7473\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:882/1200 loss：0.005401\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.150240 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7594\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:883/1200 loss：0.007134\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.199575 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7633\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:884/1200 loss：0.003322\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.242554 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7633\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:885/1200 loss：0.008657\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.282983 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7633\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：73 step:886/1200 loss：0.041030\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.254001 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7633\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：73 step:887/1200 loss：0.012753\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.226380 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7633\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:888/1200 loss：0.016811\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.213412 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7436\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:889/1200 loss：0.004202\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.200183 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7403\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:890/1200 loss：0.003568\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.190455 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7403\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:891/1200 loss：0.010252\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.169227 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:892/1200 loss：0.018418\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.153258 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:893/1200 loss：0.004915\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.133570 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:894/1200 loss：0.027498\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.023006 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:895/1200 loss：0.085953\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.836556 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:896/1200 loss：0.006266\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.655514 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:897/1200 loss：0.005811\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.507850 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7433\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：74 step:898/1200 loss：0.003325\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.412594 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7488\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：74 step:899/1200 loss：0.011914\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.365295 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7654\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:900/1200 loss：0.008634\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.356047 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7511\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:901/1200 loss：0.016730\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.373316 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7511\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:902/1200 loss：0.005573\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.400918 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7511\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:903/1200 loss：0.038664\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.395923 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7511\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:904/1200 loss：0.017983\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.392858 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7511\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:905/1200 loss：0.015116\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.444322 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7331\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:906/1200 loss：0.006848\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.528420 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.6988\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:907/1200 loss：0.021410\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.669208 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7292\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:908/1200 loss：0.107751\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.028238 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7315\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:909/1200 loss：0.009590\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.385643 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7344\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：75 step:910/1200 loss：0.042733\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.493036 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7510\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：75 step:911/1200 loss：0.022501\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.539954 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7185\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:912/1200 loss：0.052112\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.405686 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7680\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:913/1200 loss：0.005531\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.308726 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7807\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:914/1200 loss：0.057983\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.026109 accuracy：0.7447 micro_f1：0.7447 macro_f1：0.7895\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:915/1200 loss：0.004514\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.808947 accuracy：0.7234 micro_f1：0.7234 macro_f1：0.7718\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:916/1200 loss：0.003298\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.646572 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:917/1200 loss：0.003146\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.525688 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:918/1200 loss：0.007970\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.441412 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7380\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:919/1200 loss：0.006550\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.390635 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7364\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:920/1200 loss：0.011143\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.364445 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7402\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:921/1200 loss：0.011611\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.356566 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7262\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：76 step:922/1200 loss：0.010180\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.355688 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7456\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：76 step:923/1200 loss：0.043900\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.344361 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7262\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:924/1200 loss：0.009834\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.336878 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7262\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:925/1200 loss：0.011698\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.341300 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7276\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:926/1200 loss：0.008102\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.333149 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7276\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:927/1200 loss：0.008755\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.333349 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7276\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:928/1200 loss：0.003896\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.342119 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7276\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:929/1200 loss：0.004695\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.352493 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7238\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:930/1200 loss：0.015075\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.323786 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7238\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:931/1200 loss：0.021830\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.264645 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7276\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:932/1200 loss：0.005914\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.211779 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7276\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:933/1200 loss：0.005263\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.168835 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7445\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：77 step:934/1200 loss：0.006708\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.132384 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7445\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：77 step:935/1200 loss：0.004332\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.104065 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7315\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:936/1200 loss：0.017932\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.073342 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7315\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:937/1200 loss：0.020967\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.053761 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7315\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:938/1200 loss：0.007334\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.046024 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7315\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:939/1200 loss：0.004496\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.046126 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7671\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:940/1200 loss：0.003809\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.049820 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7659\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:941/1200 loss：0.005520\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.054596 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7659\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:942/1200 loss：0.017931\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.070534 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7518\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:943/1200 loss：0.014982\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.087857 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7518\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:944/1200 loss：0.004342\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.108379 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7535\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:945/1200 loss：0.005861\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.132519 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7342\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：78 step:946/1200 loss：0.006928\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.155758 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7342\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：78 step:947/1200 loss：0.004204\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.180029 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7342\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:948/1200 loss：0.015714\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.226862 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7342\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:949/1200 loss：0.020101\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.260475 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:950/1200 loss：0.013815\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.240699 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:951/1200 loss：0.002248\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.229767 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7342\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:952/1200 loss：0.005267\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.226437 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:953/1200 loss：0.017351\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.240300 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7342\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:954/1200 loss：0.004270\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.253205 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:955/1200 loss：0.011797\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.274580 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:956/1200 loss：0.003415\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.295649 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:957/1200 loss：0.003018\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.319290 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：79 step:958/1200 loss：0.005930\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.348842 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：79 step:959/1200 loss：0.003807\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.376997 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:960/1200 loss：0.010286\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.406861 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:961/1200 loss：0.005399\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.427552 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:962/1200 loss：0.005890\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.458826 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:963/1200 loss：0.004049\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.489582 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:964/1200 loss：0.005672\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.516646 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:965/1200 loss：0.014707\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.524605 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:966/1200 loss：0.005136\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.521610 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:967/1200 loss：0.003666\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.521453 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:968/1200 loss：0.005643\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.523275 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:969/1200 loss：0.006037\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.513036 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：80 step:970/1200 loss：0.005655\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.505295 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：80 step:971/1200 loss：0.006828\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.503239 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:972/1200 loss：0.003575\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.499813 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:973/1200 loss：0.006798\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.493640 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:974/1200 loss：0.005708\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.485977 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:975/1200 loss：0.006695\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.478072 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:976/1200 loss：0.002832\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.470177 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:977/1200 loss：0.003220\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.463507 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:978/1200 loss：0.003369\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.458520 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:979/1200 loss：0.005312\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.450772 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:980/1200 loss：0.032585\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.417206 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:981/1200 loss：0.004630\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.398585 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：81 step:982/1200 loss：0.002396\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.387575 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7318\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：81 step:983/1200 loss：0.036588\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.401615 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7318\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:984/1200 loss：0.014463\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.440327 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:985/1200 loss：0.004242\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.483190 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:986/1200 loss：0.009130\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.539697 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:987/1200 loss：0.003415\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.599130 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:988/1200 loss：0.002075\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.657482 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:989/1200 loss：0.005315\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.714194 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:990/1200 loss：0.002968\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.764254 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:991/1200 loss：0.002811\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.809248 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:992/1200 loss：0.009982\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.853563 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:993/1200 loss：0.007829\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.894997 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：82 step:994/1200 loss：0.005164\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.921808 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7292\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：82 step:995/1200 loss：0.004648\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.943053 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7292\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:996/1200 loss：0.005047\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.953099 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7444\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:997/1200 loss：0.012511\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.907442 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:998/1200 loss：0.006518\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.868638 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7140\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:999/1200 loss：0.010420\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.810059 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7125\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:1000/1200 loss：0.004697\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.747362 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:1001/1200 loss：0.002561\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.692584 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:1002/1200 loss：0.006199\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.632941 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:1003/1200 loss：0.003759\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.582752 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:1004/1200 loss：0.003735\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.543156 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:1005/1200 loss：0.006644\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.504637 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：83 step:1006/1200 loss：0.002659\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.473894 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：83 step:1007/1200 loss：0.006502\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.460648 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1008/1200 loss：0.004337\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.446819 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1009/1200 loss：0.005805\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.438816 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1010/1200 loss：0.003338\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.426153 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1011/1200 loss：0.002161\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.416394 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1012/1200 loss：0.003171\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.410579 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1013/1200 loss：0.004636\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.402465 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1014/1200 loss：0.004047\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.398003 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1015/1200 loss：0.023991\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.408314 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1016/1200 loss：0.006234\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.426744 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1017/1200 loss：0.006009\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.443858 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：84 step:1018/1200 loss：0.003927\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.463407 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：84 step:1019/1200 loss：0.009500\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.482096 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7291\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1020/1200 loss：0.004670\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.502378 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1021/1200 loss：0.003722\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.517798 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1022/1200 loss：0.004538\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.531827 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1023/1200 loss：0.003477\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.542234 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1024/1200 loss：0.003434\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.550410 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1025/1200 loss：0.004458\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.557778 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1026/1200 loss：0.009941\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.522149 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1027/1200 loss：0.011885\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.497813 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7313\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1028/1200 loss：0.002659\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.480541 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7313\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1029/1200 loss：0.006841\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.461520 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7313\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：85 step:1030/1200 loss：0.044207\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.337052 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7156\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：85 step:1031/1200 loss：0.009524\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.268968 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7188\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1032/1200 loss：0.003243\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.236604 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1033/1200 loss：0.017144\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.254599 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1034/1200 loss：0.005707\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.273740 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7326\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1035/1200 loss：0.012333\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.305424 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7482\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1036/1200 loss：0.009698\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.341308 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7341\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1037/1200 loss：0.006555\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.375637 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7049\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1038/1200 loss：0.012201\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.405073 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7049\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1039/1200 loss：0.005962\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.416911 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7341\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1040/1200 loss：0.002664\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.428654 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7341\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1041/1200 loss：0.006628\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.435802 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7341\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：86 step:1042/1200 loss：0.005303\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.447276 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7341\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：86 step:1043/1200 loss：0.005005\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.463238 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7341\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1044/1200 loss：0.003866\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.472773 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7341\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1045/1200 loss：0.004903\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.481470 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7341\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1046/1200 loss：0.027872\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.520410 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7497\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1047/1200 loss：0.003751\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.563489 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7292\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1048/1200 loss：0.028312\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.561327 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7292\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1049/1200 loss：0.003679\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.567474 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7313\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1050/1200 loss：0.003158\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.581110 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1051/1200 loss：0.005440\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.601166 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1052/1200 loss：0.006054\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.615272 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1053/1200 loss：0.003993\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.631545 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7134\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：87 step:1054/1200 loss：0.009160\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.669128 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7134\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：87 step:1055/1200 loss：0.004895\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.703996 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7134\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1056/1200 loss：0.006051\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.721312 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1057/1200 loss：0.005346\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.744007 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1058/1200 loss：0.005193\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.755866 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1059/1200 loss：0.005905\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.752202 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1060/1200 loss：0.002550\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.745769 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1061/1200 loss：0.004152\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.741684 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1062/1200 loss：0.009097\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.741111 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1063/1200 loss：0.004700\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.745808 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1064/1200 loss：0.005808\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.735367 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1065/1200 loss：0.002776\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.727250 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：88 step:1066/1200 loss：0.011070\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.720838 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：88 step:1067/1200 loss：0.003969\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.707577 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1068/1200 loss：0.006721\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.681227 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1069/1200 loss：0.003710\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.647739 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1070/1200 loss：0.002491\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.619340 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1071/1200 loss：0.005932\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.593456 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6854\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1072/1200 loss：0.006877\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.573166 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7188\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1073/1200 loss：0.006624\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.539484 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7188\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1074/1200 loss：0.006672\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.501962 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7188\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1075/1200 loss：0.007801\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.478322 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1076/1200 loss：0.004616\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.459814 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1077/1200 loss：0.004708\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.444906 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：89 step:1078/1200 loss：0.002493\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.433409 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：89 step:1079/1200 loss：0.004678\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.427401 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1080/1200 loss：0.002106\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.423095 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1081/1200 loss：0.005519\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.419499 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1082/1200 loss：0.003348\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.416101 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1083/1200 loss：0.007424\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.410184 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1084/1200 loss：0.002803\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.404936 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1085/1200 loss：0.004800\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.412005 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1086/1200 loss：0.004551\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.418696 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1087/1200 loss：0.008138\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.423881 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1088/1200 loss：0.004506\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.433846 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1089/1200 loss：0.005576\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.441839 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：90 step:1090/1200 loss：0.002816\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.450182 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：90 step:1091/1200 loss：0.002465\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.458864 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1092/1200 loss：0.004440\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.474856 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1093/1200 loss：0.017694\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.441311 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1094/1200 loss：0.004586\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.424025 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1095/1200 loss：0.004019\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.415067 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1096/1200 loss：0.002846\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.408458 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1097/1200 loss：0.002009\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.407377 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1098/1200 loss：0.005106\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.407982 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7570\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1099/1200 loss：0.004277\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.409523 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7570\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1100/1200 loss：0.004263\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.410441 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7570\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1101/1200 loss：0.005576\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.411786 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7570\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：91 step:1102/1200 loss：0.006134\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.410970 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7570\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：91 step:1103/1200 loss：0.004433\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.406422 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7570\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1104/1200 loss：0.006725\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.402107 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1105/1200 loss：0.004044\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.399709 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1106/1200 loss：0.004488\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.398982 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1107/1200 loss：0.006362\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.398220 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1108/1200 loss：0.002982\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.398817 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1109/1200 loss：0.005235\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.401376 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1110/1200 loss：0.002010\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.406137 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1111/1200 loss：0.005259\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.411367 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1112/1200 loss：0.001751\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.417613 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1113/1200 loss：0.003443\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.424614 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7418\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：92 step:1114/1200 loss：0.011559\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.411195 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7418\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：92 step:1115/1200 loss：0.002327\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.402353 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1116/1200 loss：0.003081\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.397765 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7397\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1117/1200 loss：0.002379\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.395962 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1118/1200 loss：0.002497\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.399499 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1119/1200 loss：0.003888\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.398973 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1120/1200 loss：0.002629\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.400896 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1121/1200 loss：0.005460\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.409535 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1122/1200 loss：0.002191\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.418649 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1123/1200 loss：0.002217\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.429611 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7240\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1124/1200 loss：0.003232\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.439845 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7240\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1125/1200 loss：0.001790\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.449749 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7240\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：93 step:1126/1200 loss：0.004039\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.450761 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7240\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：93 step:1127/1200 loss：0.002501\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.447862 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7240\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1128/1200 loss：0.005624\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.442990 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7240\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1129/1200 loss：0.015478\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.443681 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7402\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1130/1200 loss：0.003598\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.454754 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7402\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1131/1200 loss：0.007523\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.454932 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7402\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1132/1200 loss：0.006083\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.439200 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7240\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1133/1200 loss：0.001824\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.426363 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7052\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1134/1200 loss：0.017309\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.553084 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7211\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1135/1200 loss：0.001254\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.702589 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1136/1200 loss：0.006093\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.836872 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1137/1200 loss：0.003433\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.961867 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：94 step:1138/1200 loss：0.001652\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.077518 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：94 step:1139/1200 loss：0.002535\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.184989 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1140/1200 loss：0.018568\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.137298 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1141/1200 loss：0.002840\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：4.091849 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7163\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1142/1200 loss：0.025735\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.836540 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1143/1200 loss：0.003893\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.638291 accuracy：0.5957 micro_f1：0.5957 macro_f1：0.6854\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1144/1200 loss：0.002266\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.506947 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7167\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1145/1200 loss：0.001950\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.421474 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1146/1200 loss：0.001829\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.371141 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1147/1200 loss：0.006420\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.333808 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1148/1200 loss：0.004951\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.317846 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7716\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1149/1200 loss：0.007884\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.315488 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7716\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：95 step:1150/1200 loss：0.001683\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.325017 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7716\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：95 step:1151/1200 loss：0.005622\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.342572 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7709\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1152/1200 loss：0.003859\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.355950 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7709\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1153/1200 loss：0.006570\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.365835 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7709\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1154/1200 loss：0.005366\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.363972 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7709\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1155/1200 loss：0.009017\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.348672 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7716\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1156/1200 loss：0.006321\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.335770 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7716\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1157/1200 loss：0.010826\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.313954 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7539\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1158/1200 loss：0.005204\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.305594 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7539\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1159/1200 loss：0.002161\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.307344 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1160/1200 loss：0.005343\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.302897 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1161/1200 loss：0.002781\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.305976 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7218\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：96 step:1162/1200 loss：0.003100\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.322795 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7240\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：96 step:1163/1200 loss：0.007410\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.348078 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7052\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1164/1200 loss：0.003419\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.371604 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7052\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1165/1200 loss：0.002408\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.397820 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7052\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1166/1200 loss：0.002455\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.420104 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7052\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1167/1200 loss：0.003286\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.441531 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7052\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1168/1200 loss：0.002135\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.462832 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7052\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1169/1200 loss：0.002548\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.485264 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7211\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1170/1200 loss：0.002725\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.503817 accuracy：0.6383 micro_f1：0.6383 macro_f1：0.7211\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1171/1200 loss：0.013895\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.581724 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1172/1200 loss：0.003358\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.655905 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1173/1200 loss：0.004254\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.724441 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：97 step:1174/1200 loss：0.002936\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.788036 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：97 step:1175/1200 loss：0.015631\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.719622 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1176/1200 loss：0.004232\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.657229 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1177/1200 loss：0.011167\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.564817 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7009\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1178/1200 loss：0.001946\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.497305 accuracy：0.6170 micro_f1：0.6170 macro_f1：0.7052\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1179/1200 loss：0.003018\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.447108 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1180/1200 loss：0.002821\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.408135 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1181/1200 loss：0.002810\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.381112 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1182/1200 loss：0.005956\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.367573 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1183/1200 loss：0.001147\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.357604 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1184/1200 loss：0.005204\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.343031 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7357\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1185/1200 loss：0.002415\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.337096 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7539\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：98 step:1186/1200 loss：0.006272\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.332224 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：98 step:1187/1200 loss：0.006816\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.327444 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1188/1200 loss：0.001581\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.323870 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1189/1200 loss：0.003153\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.324058 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1190/1200 loss：0.002008\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.325297 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1191/1200 loss：0.004616\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.328680 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1192/1200 loss：0.003213\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.333804 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1193/1200 loss：0.003186\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.346059 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1194/1200 loss：0.001347\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.357921 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1195/1200 loss：0.003977\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.370199 accuracy：0.7021 micro_f1：0.7021 macro_f1：0.7703\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1196/1200 loss：0.002292\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.383325 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7518\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1197/1200 loss：0.002046\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.396247 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7518\n",
            "torch.Size([16, 4, 768])\n",
            "【train】 epoch：99 step:1198/1200 loss：0.002141\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.408111 accuracy：0.6809 micro_f1：0.6809 macro_f1：0.7518\n",
            "torch.Size([11, 4, 768])\n",
            "【train】 epoch：99 step:1199/1200 loss：0.004400\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【dev】 loss：3.423277 accuracy：0.6596 micro_f1：0.6596 macro_f1：0.7377\n",
            "======== Calculate Testing========\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([16, 4, 768])\n",
            "torch.Size([15, 4, 768])\n",
            "【test】 loss：2.567647 accuracy：0.7872 micro_f1：0.7872 macro_f1：0.8343\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "            Negative       0.83      0.67      0.74        15\n",
            "    Cause_of_disease       0.69      0.92      0.79        12\n",
            "Treatment_of_disease       0.83      0.79      0.81        19\n",
            "         Association       1.00      1.00      1.00         1\n",
            "\n",
            "            accuracy                           0.79        47\n",
            "           macro avg       0.84      0.84      0.83        47\n",
            "        weighted avg       0.80      0.79      0.79        47\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_biomedNLP_predict.sh\""
      ],
      "metadata": {
        "id": "_jYrUj6-sZ30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d392fd-48c1-4c82-c0d5-f9ff1a7ccee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Negative': 0, 'Cause_of_disease': 1, 'Treatment_of_disease': 2, 'Association': 3}\n",
            "======== Prediction ========\n",
            "OBJECTIVE: To study the role of pecan tree pollen in the development of allergy . \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Negative\n",
            "==========================\n",
            " Garlic consumption and cancer prevention: meta-analyses of colorectal and stomach cancers . \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Treatment_of_disease\n",
            "true label：Negative\n",
            "==========================\n",
            "Patients with anaphylaxis to pea can have peanut allergy caused by cross-reactive IgE to vicilin (Ara h 1). \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Cause_of_disease\n",
            "==========================\n",
            "Genetic predisposition to schizophrenia associated with increased use of cannabis . \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Negative\n",
            "==========================\n",
            "Efficacy of cancer prevention by high-selenium garlic is primarily dependent on the action of selenium. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "Mutagen sensitivity, tobacco smoking and breast cancer risk: a case-control study. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Treatment_of_disease\n",
            "true label：Negative\n",
            "==========================\n",
            " HAs and HPE were demonstrated to cause cancer cell apoptosis, especially in leukemia and gastric cancer. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "Significant cancer protection was observed with treatment by the Se- garlic extract (at 3 p.p.m. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "Our data also suggest that bleomycin sensitivity may modulate the effect of tobacco smoking on breast cancer risk. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Treatment_of_disease\n",
            "true label：Cause_of_disease\n",
            "==========================\n",
            "Animals given AFB1 together with fresh garlic or garlic oil showed a significant reduction in tumor incidence. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "The tumor incidences were 3% and 9% in animals given AFB1 plus garlic and AFB1 plus garlic oil, respectively. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Negative\n",
            "==========================\n",
            " Tobacco smoke carcinogens, DNA damage and p53 mutations in smoking-associated cancers . \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Cause_of_disease\n",
            "==========================\n",
            "Its effect on digitalis -caused atrial arrhythmias is unknown. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Cause_of_disease\n",
            "==========================\n",
            "A lipid-soluble red ginseng extract inhibits the growth of human lung tumor xenografts in nude mice. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Treatment_of_disease\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "CONCLUSION: Lespedeza Michx was effective on MCN . \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "Thus smaller tumor volume and longer survival time were found in the garlic group than in the controls (p < 0.01). \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "Preventive action of garlic on aflatoxin B1-induced carcinogenesis in the toad Bufo regularis. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "Caffeine and coffee as therapeutics against Alzheimer's disease . \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Treatment_of_disease\n",
            "==========================\n",
            "An excess risk of dying of lung cancer and heart diseases probably reflects a high tobacco consumption. \n",
            "torch.Size([1, 4, 768])\n",
            "predict labels：Negative\n",
            "true label：Cause_of_disease\n",
            "==========================\n",
            "Halothane is known to oppose <e1start> digitalis <e1end>-induced <e2start> ventricular arrhythmias <e2end>.\n",
            "torch.Size([1, 4, 768])\n",
            "predict labels： ['Negative']\n",
            "true label： Cause_of_disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://img.icons8.com/color/48/undefined/7-circle--v1.png\"/>**Summary**"
      ],
      "metadata": {
        "id": "Lkml6AWbmpQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Train Output***"
      ],
      "metadata": {
        "id": "BnA3TTJlc64R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "url_view = 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-train-view.csv'\n",
        "url = 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-train.csv'\n",
        "\n",
        "biobert_train = pd.read_csv(url_view)\n",
        "\n",
        "print(biobert_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USSuglMjc9Ox",
        "outputId": "49cee911-561d-4f3d-9ceb-d3a24b33a1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Time  Epoch  Step      Loss\n",
            "0     2022-06-14 20:25:35      0     0  1.229355\n",
            "1     2022-06-14 20:26:02      0     1  1.106556\n",
            "2     2022-06-14 20:26:02      0     2  1.406058\n",
            "3     2022-06-14 20:26:09      0     3  1.427826\n",
            "4     2022-06-14 20:26:09      0     4  1.150533\n",
            "...                   ...    ...   ...       ...\n",
            "1195  2022-06-14 20:40:54     99  1195  0.003977\n",
            "1196  2022-06-14 20:40:54     99  1196  0.002292\n",
            "1197  2022-06-14 20:40:55     99  1197  0.002046\n",
            "1198  2022-06-14 20:40:55     99  1198  0.002141\n",
            "1199  2022-06-14 20:40:56     99  1199  0.004400\n",
            "\n",
            "[1200 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "with open(url, 'r') as csvfile:\n",
        "    lines = csv.reader(csvfile, delimiter=',')\n",
        "    for row in lines:\n",
        "        x.append(int(row[2]))\n",
        "        y.append(float(row[3]))\n",
        "\n",
        "plt.plot(x, y, color='g', linestyle='dashed',\n",
        "         marker='o', label=\"Training Loss\")\n",
        "\n",
        "plt.xticks(rotation=25)\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training', fontsize=20)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "jft5hmyJdRxs",
        "outputId": "8ef15b0d-161e-467c-d70c-18124e54b266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-train-chart.py\""
      ],
      "metadata": {
        "id": "J57mIdDqd7yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Dev Output***"
      ],
      "metadata": {
        "id": "bK8lrwmTfHVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_url_view = 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-dev-view.csv'\n",
        "dev_url = 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-dev.csv'\n",
        "\n",
        "biobert_dev = pd.read_csv(dev_url_view)\n",
        "\n",
        "print(biobert_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaL_JFVLekw5",
        "outputId": "484d3e49-77a2-426f-8b87-89499bed6585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Time      Loss  accuracy  micro_f1  macro_f1\n",
            "0     2022-06-14 20:25:35  3.989423    0.2553    0.2553    0.1306\n",
            "1     2022-06-14 20:26:02  3.982429    0.2766    0.2766    0.1261\n",
            "2     2022-06-14 20:26:03  3.930491    0.3830    0.3830    0.1385\n",
            "3     2022-06-14 20:26:09  3.864778    0.3830    0.3830    0.1385\n",
            "4     2022-06-14 20:26:09  3.819381    0.2766    0.2766    0.1271\n",
            "...                   ...       ...       ...       ...       ...\n",
            "1195  2022-06-14 20:40:54  3.370199    0.7021    0.7021    0.7703\n",
            "1196  2022-06-14 20:40:55  3.383325    0.6809    0.6809    0.7518\n",
            "1197  2022-06-14 20:40:55  3.396247    0.6809    0.6809    0.7518\n",
            "1198  2022-06-14 20:40:56  3.408111    0.6809    0.6809    0.7518\n",
            "1199  2022-06-14 20:40:56  3.423277    0.6596    0.6596    0.7377\n",
            "\n",
            "[1200 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_x = []\n",
        "dev_y = []\n",
        "\n",
        "with open(dev_url, 'r') as dev_csvfile:\n",
        "    dev_lines = csv.reader(dev_csvfile, delimiter=',')\n",
        "    for dev_row in dev_lines:\n",
        "        dev_x.append(float(dev_row[4]))\n",
        "        dev_y.append(float(dev_row[2]))\n",
        "\n",
        "plt.plot(dev_x, dev_y, color='g', linestyle='None',\n",
        "         marker='o', label=\"Dev Accuracy\")\n",
        "\n",
        "plt.xticks(rotation=25)\n",
        "plt.xlabel('F-1')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Development', fontsize=20)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "FFVSP4rie1o-",
        "outputId": "934d8c58-b6b1-4e3a-aa55-2c8e2eb30880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-dev-chart.py\""
      ],
      "metadata": {
        "id": "zplYqxLme8bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Training, Validation, Test***"
      ],
      "metadata": {
        "id": "0IZfK4rIfM2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "2022-06-14 20:35:06,300 - INFO - main.py - train - 86 - 【train】 epoch：48 step:580/1200 loss：0.025188\n",
        "2022-06-14 20:35:06,651 - INFO - main.py - train - 92 - 【dev】 loss：2.567647 accuracy：0.7872 micro_f1：0.7872 macro_f1：0.8343\n",
        "2022-06-14 20:35:06,652 - INFO - main.py - train - 94 - ------------>Save best model\n",
        "...\n",
        "2022-06-14 20:40:56,848 - INFO - main.py - <module> - 247 - ======== Calculate Testing========\n",
        "2022-06-14 20:40:59,872 - INFO - main.py - <module> - 251 - 【test】 loss：2.567647 accuracy：0.7872 micro_f1：0.7872 macro_f1：0.8343\n",
        "```"
      ],
      "metadata": {
        "id": "vr8NCfCafPKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "                        precision    recall   per-class   support\n",
        "                                              f1-scores\n",
        "\n",
        "            Negative       0.83       0.67      0.74        15\n",
        "    Cause_of_disease       0.69       0.92      0.79        12\n",
        "Treatment_of_disease       0.83       0.79      0.81        19\n",
        "         Association       1.00       1.00      1.00         1\n",
        "```\n",
        "\n",
        "\n",
        "<center><img src=\"https://img.icons8.com/external-royyan-wijaya-detailed-outline-royyan-wijaya/24/undefined/external-arrow-arrow-line-royyan-wijaya-detailed-outline-royyan-wijaya-8.png\"/></center>\n",
        "\n",
        "\n",
        "```\n",
        "                          precision    recall   Average     support\n",
        "                                               f1-scores\n",
        "\n",
        "            accuracy                              0.79        47\n",
        "           macro avg       0.84         0.84      0.83        47\n",
        "        weighted avg       0.80         0.79      0.79        47\n",
        "```"
      ],
      "metadata": {
        "id": "24nqLJP6fscV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Output**"
      ],
      "metadata": {
        "id": "JaS8ZJ0Mf-9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -lh \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint/BiomedNLP-PubMedBERT\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO1z2Y-Wf6vt",
        "outputId": "22fefe92-0859-4fbe-eff1-5e6102537a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.3G\n",
            "-rw------- 1 root root 1.3G Jun 14 20:35 best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br><br>\n",
        "# \"*Alone we can do so little, together we can do so much*\""
      ],
      "metadata": {
        "id": "ThHpTmKTZC4Y"
      }
    }
  ]
}