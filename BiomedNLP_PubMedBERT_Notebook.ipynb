{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "BiomedNLP_PubMedBERT_Notebook.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+) **NLP Research**\n",
    "# **Bert Relation Extraction in Biomedical using BiomedNLP-PubMedBERT model and pytorch**\n",
    "## <img src=\"https://img.icons8.com/external-fauzidea-flat-fauzidea/64/undefined/external-man-avatar-avatar-fauzidea-flat-fauzidea.png\"/> **`Dimas Dwi Putra`**"
   ],
   "metadata": {
    "id": "QfRM-ftWOKX5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/1-circle--v1.png\"/>**Connect Google Storage**"
   ],
   "metadata": {
    "id": "DnGRwGq8MYbg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5ckZ9Tj94k0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542975879,
     "user_tz": -420,
     "elapsed": 19612,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "9c36dfa5-0f0b-40aa-f99a-5e2463f58b4a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/2-circle--v1.png\"/>**Requirements**"
   ],
   "metadata": {
    "id": "7Lp6apVhMKi4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ! pip install pandas==1.4.2\n",
    "# ! pip install matplotlib==3.5.1\n",
    "! pip install openpyxl==3.0.9\n",
    "# ! pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "! pip install transformers==4.18.0\n",
    "! pip install scikit-learn==1.0.2\n",
    "! pip install pickleshare==0.7.5\n",
    "! pip install pickle5==0.0.12"
   ],
   "metadata": {
    "id": "J-x7B1by9_kB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/3-circle--v1.png\"/>**Check Device**"
   ],
   "metadata": {
    "id": "3SywR6WxMFML"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"\\nUsing GPU\")\n",
    "    print('\\nDevice name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"\\nNo GPU available, using the CPU instead.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAXU70uWJU-j",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654536799038,
     "user_tz": -420,
     "elapsed": 3133,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    },
    "outputId": "6ecd9c1a-4e38-49e7-f613-a9c0179d439d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Using GPU\n",
      "\n",
      "Device name: Tesla T4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/4-circle--v1.png\"/>**Data Preprocessing into `train set` and `test set`**"
   ],
   "metadata": {
    "id": "4V17I1hsoLOE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/data_preprocessing.py\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXwMR1GVnhOs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654536849815,
     "user_tz": -420,
     "elapsed": 3626,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    },
    "outputId": "3be89c68-2b26-4c90-8935-5f7fd11d8f5c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Negative                583\n",
      "Treatment_of_disease    507\n",
      "Cause_of_disease        183\n",
      "Association              34\n",
      "Name: relation, dtype: int64\n",
      "============================\n",
      "total data : 1307\n",
      "\n",
      "success to create predict.txt\n",
      "success to create train.txt\n",
      "success to create test.txt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/5-circle--v1.png\"/>**Preprocess Program**\n",
    "### **preprocess data with special token using `biobert pretrained model`**"
   ],
   "metadata": {
    "id": "DYNYPV4GHkm8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_preprocess.sh\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NW_8F7c_BncY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654536915115,
     "user_tz": -420,
     "elapsed": 8612,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    },
    "outputId": "83f5dd1d-115f-4ba9-aead-2015d0a3b83e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'output_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint/', 'bert_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/model/BiomedNLP-PubMedBERT/', 'data_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/', 'log_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/', 'num_tags': 4, 'seed': 123, 'gpu_ids': '0', 'max_seq_len': 128, 'eval_batch_size': 64, 'swa_start': 3, 'train_epochs': 500, 'dropout_prob': 0.1, 'lr': 1e-05, 'other_lr': 0.0001, 'max_grad_norm': 1, 'warmup_proportion': 0.1, 'weight_decay': 0.01, 'adam_epsilon': 1e-12, 'train_batch_size': 64, 'eval_model': True}\n",
      "==========================\n",
      "example_text : Halothane is known to oppose <e1start> digitalis <e1end>-induced <e2start> ventricular arrhythmias <e2end>. \n",
      "example_id_label : 0\n",
      "example_id_tags : [29, 56, 65, 106]\n",
      "==========================\n",
      "==========================\n",
      "example_text : Both cases proved to be <e1start> cotton <e1end>-material-induced <e2start> granulomas <e2end>. \n",
      "example_id_label : 0\n",
      "example_id_tags : [24, 48, 66, 94]\n",
      "==========================\n",
      "==========================\n",
      "example_text : The evidence for <e1start> soybean <e1end> products as <e2start> cancer <e2end> preventive agents.  \n",
      "example_id_label : 1\n",
      "example_id_tags : [17, 42, 55, 79]\n",
      "==========================\n",
      "==========================\n",
      "example_text : [Mortality trends in <e2start> cancer <e2end> attributable to <e1start> tobacco <e1end> in Mexico].  \n",
      "example_id_label : 0\n",
      "example_id_tags : [62, 87, 21, 45]\n",
      "==========================\n",
      "Convert 46 examples to features\n",
      "*** train_example-0 ***\n",
      "text: [CLS] [UNK] a l o t h a n e [UNK] i s [UNK] k n o w n [UNK] t o [UNK] o p p o s e [UNK] < e 1 s t a r t > [UNK] d i g i t a l i s [UNK] < e 1 e n d > - i n d u c e d [UNK] < e 2 s t a r t > [UNK] v e n t r i c u l a r [UNK] a r r h y t h m i a s [UNK] < e 2 e n d >. [UNK] [SEP]\n",
      "token_ids: [2, 1, 43, 54, 57, 62, 50, 43, 56, 47, 1, 51, 61, 1, 53, 56, 57, 65, 56, 1, 62, 57, 1, 57, 58, 58, 57, 61, 47, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 46, 51, 49, 51, 62, 43, 54, 51, 61, 1, 32, 47, 21, 47, 56, 46, 34, 17, 51, 56, 46, 63, 45, 47, 46, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 64, 47, 56, 62, 60, 51, 45, 63, 54, 43, 60, 1, 43, 60, 60, 50, 67, 62, 50, 55, 51, 43, 61, 1, 32, 47, 22, 47, 56, 46, 34, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [30, 57, 66, 107]\n",
      "*** train_example-1 ***\n",
      "text: [CLS] [UNK] o t h [UNK] c a s e s [UNK] p r o v e d [UNK] t o [UNK] b e [UNK] < e 1 s t a r t > [UNK] c o t t o n [UNK] < e 1 e n d > - m a t e r i a l - i n d u c e d [UNK] < e 2 s t a r t > [UNK] g r a n u l o m a s [UNK] < e 2 e n d >. [UNK] [SEP]\n",
      "token_ids: [2, 1, 57, 62, 50, 1, 45, 43, 61, 47, 61, 1, 58, 60, 57, 64, 47, 46, 1, 62, 57, 1, 44, 47, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 45, 57, 62, 62, 57, 56, 1, 32, 47, 21, 47, 56, 46, 34, 17, 55, 43, 62, 47, 60, 51, 43, 54, 17, 51, 56, 46, 63, 45, 47, 46, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 49, 60, 43, 56, 63, 54, 57, 55, 43, 61, 1, 32, 47, 22, 47, 56, 46, 34, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [25, 49, 67, 95]\n",
      "*** train_example-2 ***\n",
      "text: [CLS] [UNK] h e [UNK] e v i d e n c e [UNK] f o r [UNK] < e 1 s t a r t > [UNK] s o y b e a n [UNK] < e 1 e n d > [UNK] p r o d u c t s [UNK] a s [UNK] < e 2 s t a r t > [UNK] c a n c e r [UNK] < e 2 e n d > [UNK] p r e v e n t i v e [UNK] a g e n t s. [UNK] [UNK] [SEP]\n",
      "token_ids: [2, 1, 50, 47, 1, 47, 64, 51, 46, 47, 56, 45, 47, 1, 48, 57, 60, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 61, 57, 67, 44, 47, 43, 56, 1, 32, 47, 21, 47, 56, 46, 34, 1, 58, 60, 57, 46, 63, 45, 62, 61, 1, 43, 61, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 45, 43, 56, 45, 47, 60, 1, 32, 47, 22, 47, 56, 46, 34, 1, 58, 60, 47, 64, 47, 56, 62, 51, 64, 47, 1, 43, 49, 47, 56, 62, 61, 18, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 1\n",
      "ids: [18, 43, 56, 80]\n",
      "*** train_example-3 ***\n",
      "text: [CLS] [ [UNK] o r t a l i t y [UNK] t r e n d s [UNK] i n [UNK] < e 2 s t a r t > [UNK] c a n c e r [UNK] < e 2 e n d > [UNK] a t t r i b u t a b l e [UNK] t o [UNK] < e 1 s t a r t > [UNK] t o b a c c o [UNK] < e 1 e n d > [UNK] i n [UNK] [UNK] e x i c o ]. [UNK] [UNK] [SEP]\n",
      "token_ids: [2, 37, 1, 57, 60, 62, 43, 54, 51, 62, 67, 1, 62, 60, 47, 56, 46, 61, 1, 51, 56, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 45, 43, 56, 45, 47, 60, 1, 32, 47, 22, 47, 56, 46, 34, 1, 43, 62, 62, 60, 51, 44, 63, 62, 43, 44, 54, 47, 1, 62, 57, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 62, 57, 44, 43, 45, 45, 57, 1, 32, 47, 21, 47, 56, 46, 34, 1, 51, 56, 1, 1, 47, 66, 51, 45, 57, 39, 18, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [63, 88, 22, 46]\n",
      "Build 46 features\n",
      "==========================\n",
      "example_text : Its effect on <e1start> digitalis <e1end>-caused <e2start> atrial arrhythmias <e2end> is unknown. \n",
      "example_id_label : 0\n",
      "example_id_tags : [14, 41, 49, 85]\n",
      "==========================\n",
      "==========================\n",
      "example_text : However, the growth rate of <e2start> tumors <e2end> was not markedly inhibited by <e1start> garlic <e1end>. \n",
      "example_id_label : 2\n",
      "example_id_tags : [83, 107, 28, 52]\n",
      "==========================\n",
      "==========================\n",
      "example_text : <e1start> Tobacco <e1end>-related <e2start> cancers <e2end> in Madras, India.  \n",
      "example_id_label : 0\n",
      "example_id_tags : [0, 25, 34, 59]\n",
      "==========================\n",
      "==========================\n",
      "example_text : The importance of the <e1start> pecan <e1end> tree pollen in <e2start> allergic <e2end> manifestations.  \n",
      "example_id_label : 0\n",
      "example_id_tags : [22, 45, 61, 87]\n",
      "==========================\n",
      "Convert 11 examples to features\n",
      "*** dev_example-0 ***\n",
      "text: [CLS] [UNK] t s [UNK] e f f e c t [UNK] o n [UNK] < e 1 s t a r t > [UNK] d i g i t a l i s [UNK] < e 1 e n d > - c a u s e d [UNK] < e 2 s t a r t > [UNK] a t r i a l [UNK] a r r h y t h m i a s [UNK] < e 2 e n d > [UNK] i s [UNK] u n k n o w n. [UNK] [SEP]\n",
      "token_ids: [2, 1, 62, 61, 1, 47, 48, 48, 47, 45, 62, 1, 57, 56, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 46, 51, 49, 51, 62, 43, 54, 51, 61, 1, 32, 47, 21, 47, 56, 46, 34, 17, 45, 43, 63, 61, 47, 46, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 43, 62, 60, 51, 43, 54, 1, 43, 60, 60, 50, 67, 62, 50, 55, 51, 43, 61, 1, 32, 47, 22, 47, 56, 46, 34, 1, 51, 61, 1, 63, 56, 53, 56, 57, 65, 56, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [15, 42, 50, 86]\n",
      "*** dev_example-1 ***\n",
      "text: [CLS] [UNK] o w e v e r, [UNK] t h e [UNK] g r o w t h [UNK] r a t e [UNK] o f [UNK] < e 2 s t a r t > [UNK] t u m o r s [UNK] < e 2 e n d > [UNK] w a s [UNK] n o t [UNK] m a r k e d l y [UNK] i n h i b i t e d [UNK] b y [UNK] < e 1 s t a r t > [UNK] g a r l i c [UNK] < e 1 e n d >. [UNK] [SEP]\n",
      "token_ids: [2, 1, 57, 65, 47, 64, 47, 60, 16, 1, 62, 50, 47, 1, 49, 60, 57, 65, 62, 50, 1, 60, 43, 62, 47, 1, 57, 48, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 62, 63, 55, 57, 60, 61, 1, 32, 47, 22, 47, 56, 46, 34, 1, 65, 43, 61, 1, 56, 57, 62, 1, 55, 43, 60, 53, 47, 46, 54, 67, 1, 51, 56, 50, 51, 44, 51, 62, 47, 46, 1, 44, 67, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 49, 43, 60, 54, 51, 45, 1, 32, 47, 21, 47, 56, 46, 34, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 2\n",
      "ids: [84, 108, 29, 53]\n",
      "*** dev_example-2 ***\n",
      "text: [CLS] < e 1 s t a r t > [UNK] [UNK] o b a c c o [UNK] < e 1 e n d > - r e l a t e d [UNK] < e 2 s t a r t > [UNK] c a n c e r s [UNK] < e 2 e n d > [UNK] i n [UNK] [UNK] a d r a s, [UNK] [UNK] n d i a. [UNK] [UNK] [SEP]\n",
      "token_ids: [2, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 1, 57, 44, 43, 45, 45, 57, 1, 32, 47, 21, 47, 56, 46, 34, 17, 60, 47, 54, 43, 62, 47, 46, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 45, 43, 56, 45, 47, 60, 61, 1, 32, 47, 22, 47, 56, 46, 34, 1, 51, 56, 1, 1, 43, 46, 60, 43, 61, 16, 1, 1, 56, 46, 51, 43, 18, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [1, 26, 35, 60]\n",
      "*** dev_example-3 ***\n",
      "text: [CLS] [UNK] h e [UNK] i m p o r t a n c e [UNK] o f [UNK] t h e [UNK] < e 1 s t a r t > [UNK] p e c a n [UNK] < e 1 e n d > [UNK] t r e e [UNK] p o l l e n [UNK] i n [UNK] < e 2 s t a r t > [UNK] a l l e r g i c [UNK] < e 2 e n d > [UNK] m a n i f e s t a t i o n s. [UNK] [UNK] [SEP]\n",
      "token_ids: [2, 1, 50, 47, 1, 51, 55, 58, 57, 60, 62, 43, 56, 45, 47, 1, 57, 48, 1, 62, 50, 47, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 58, 47, 45, 43, 56, 1, 32, 47, 21, 47, 56, 46, 34, 1, 62, 60, 47, 47, 1, 58, 57, 54, 54, 47, 56, 1, 51, 56, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 43, 54, 54, 47, 60, 49, 51, 45, 1, 32, 47, 22, 47, 56, 46, 34, 1, 55, 43, 56, 51, 48, 47, 61, 62, 43, 62, 51, 57, 56, 61, 18, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [23, 46, 62, 88]\n",
      "Build 11 features\n",
      "==========================\n",
      "example_text : Its effect on <e1start> digitalis <e1end>-caused <e2start> atrial arrhythmias <e2end> is unknown. \n",
      "example_id_label : 0\n",
      "example_id_tags : [14, 41, 49, 85]\n",
      "==========================\n",
      "==========================\n",
      "example_text : However, the growth rate of <e2start> tumors <e2end> was not markedly inhibited by <e1start> garlic <e1end>. \n",
      "example_id_label : 2\n",
      "example_id_tags : [83, 107, 28, 52]\n",
      "==========================\n",
      "==========================\n",
      "example_text : <e1start> Tobacco <e1end>-related <e2start> cancers <e2end> in Madras, India.  \n",
      "example_id_label : 0\n",
      "example_id_tags : [0, 25, 34, 59]\n",
      "==========================\n",
      "==========================\n",
      "example_text : The importance of the <e1start> pecan <e1end> tree pollen in <e2start> allergic <e2end> manifestations.  \n",
      "example_id_label : 0\n",
      "example_id_tags : [22, 45, 61, 87]\n",
      "==========================\n",
      "Convert 11 examples to features\n",
      "*** test_example-0 ***\n",
      "text: [CLS] [UNK] t s [UNK] e f f e c t [UNK] o n [UNK] < e 1 s t a r t > [UNK] d i g i t a l i s [UNK] < e 1 e n d > - c a u s e d [UNK] < e 2 s t a r t > [UNK] a t r i a l [UNK] a r r h y t h m i a s [UNK] < e 2 e n d > [UNK] i s [UNK] u n k n o w n. [UNK] [SEP]\n",
      "token_ids: [2, 1, 62, 61, 1, 47, 48, 48, 47, 45, 62, 1, 57, 56, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 46, 51, 49, 51, 62, 43, 54, 51, 61, 1, 32, 47, 21, 47, 56, 46, 34, 17, 45, 43, 63, 61, 47, 46, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 43, 62, 60, 51, 43, 54, 1, 43, 60, 60, 50, 67, 62, 50, 55, 51, 43, 61, 1, 32, 47, 22, 47, 56, 46, 34, 1, 51, 61, 1, 63, 56, 53, 56, 57, 65, 56, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [15, 42, 50, 86]\n",
      "*** test_example-1 ***\n",
      "text: [CLS] [UNK] o w e v e r, [UNK] t h e [UNK] g r o w t h [UNK] r a t e [UNK] o f [UNK] < e 2 s t a r t > [UNK] t u m o r s [UNK] < e 2 e n d > [UNK] w a s [UNK] n o t [UNK] m a r k e d l y [UNK] i n h i b i t e d [UNK] b y [UNK] < e 1 s t a r t > [UNK] g a r l i c [UNK] < e 1 e n d >. [UNK] [SEP]\n",
      "token_ids: [2, 1, 57, 65, 47, 64, 47, 60, 16, 1, 62, 50, 47, 1, 49, 60, 57, 65, 62, 50, 1, 60, 43, 62, 47, 1, 57, 48, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 62, 63, 55, 57, 60, 61, 1, 32, 47, 22, 47, 56, 46, 34, 1, 65, 43, 61, 1, 56, 57, 62, 1, 55, 43, 60, 53, 47, 46, 54, 67, 1, 51, 56, 50, 51, 44, 51, 62, 47, 46, 1, 44, 67, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 49, 43, 60, 54, 51, 45, 1, 32, 47, 21, 47, 56, 46, 34, 18, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 2\n",
      "ids: [84, 108, 29, 53]\n",
      "*** test_example-2 ***\n",
      "text: [CLS] < e 1 s t a r t > [UNK] [UNK] o b a c c o [UNK] < e 1 e n d > - r e l a t e d [UNK] < e 2 s t a r t > [UNK] c a n c e r s [UNK] < e 2 e n d > [UNK] i n [UNK] [UNK] a d r a s, [UNK] [UNK] n d i a. [UNK] [UNK] [SEP]\n",
      "token_ids: [2, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 1, 57, 44, 43, 45, 45, 57, 1, 32, 47, 21, 47, 56, 46, 34, 17, 60, 47, 54, 43, 62, 47, 46, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 45, 43, 56, 45, 47, 60, 61, 1, 32, 47, 22, 47, 56, 46, 34, 1, 51, 56, 1, 1, 43, 46, 60, 43, 61, 16, 1, 1, 56, 46, 51, 43, 18, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [1, 26, 35, 60]\n",
      "*** test_example-3 ***\n",
      "text: [CLS] [UNK] h e [UNK] i m p o r t a n c e [UNK] o f [UNK] t h e [UNK] < e 1 s t a r t > [UNK] p e c a n [UNK] < e 1 e n d > [UNK] t r e e [UNK] p o l l e n [UNK] i n [UNK] < e 2 s t a r t > [UNK] a l l e r g i c [UNK] < e 2 e n d > [UNK] m a n i f e s t a t i o n s. [UNK] [UNK] [SEP]\n",
      "token_ids: [2, 1, 50, 47, 1, 51, 55, 58, 57, 60, 62, 43, 56, 45, 47, 1, 57, 48, 1, 62, 50, 47, 1, 32, 47, 21, 61, 62, 43, 60, 62, 34, 1, 58, 47, 45, 43, 56, 1, 32, 47, 21, 47, 56, 46, 34, 1, 62, 60, 47, 47, 1, 58, 57, 54, 54, 47, 56, 1, 51, 56, 1, 32, 47, 22, 61, 62, 43, 60, 62, 34, 1, 43, 54, 54, 47, 60, 49, 51, 45, 1, 32, 47, 22, 47, 56, 46, 34, 1, 55, 43, 56, 51, 48, 47, 61, 62, 43, 62, 51, 57, 56, 61, 18, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [23, 46, 62, 88]\n",
      "Build 11 features\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/6-circle--v1.png\"/>**Main Program**\n",
    "### **`train`, `eval`, create new `model pytorch`, test model , <br>compute `cross validation`, `f-1 score`, and <br>test predict data with new model `.pt`**"
   ],
   "metadata": {
    "id": "167FnNFAGdGN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "f_run_main = open(\"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_main.sh\", \"r\")\n",
    "print(f_run_main.read())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Di73LYnvvI40",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654536932625,
     "user_tz": -420,
     "elapsed": 347,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    },
    "outputId": "a1d91741-f91b-40d0-8654-6270dd324a0d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#!/usr/bin/env bash\n",
      "python \"drive/MyDrive/Colab Notebooks/bert_relation_extraction/main.py\" \\\n",
      "--bert_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/model/BiomedNLP-PubMedBERT/\" \\\n",
      "--data_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/\" \\\n",
      "--log_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/\" \\\n",
      "--output_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint/\" \\\n",
      "--num_tags=4 \\\n",
      "--seed=123 \\\n",
      "--gpu_ids=\"0\" \\\n",
      "--max_seq_len=128 \\\n",
      "--lr=1e-5 \\\n",
      "--other_lr=1e-4 \\\n",
      "--train_batch_size=64 \\\n",
      "--train_epochs=500 \\\n",
      "--eval_batch_size=64 \\\n",
      "--dropout_prob=0.1 \\\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_main.sh\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGtbTcn1wvPG",
    "outputId": "61de8188-f036-4c90-a2b2-f84b1e4ff9ee",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654537688906,
     "user_tz": -420,
     "elapsed": 749457,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Cause_of_disease': 0, 'Treatment_of_disease': 1, 'Negative': 2, 'Association': 3}\n",
      "======== Training And Validation========\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：0 step:0/500 loss：1.424365\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.336937 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.1333\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：1 step:1/500 loss：1.363355\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.325184 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.1333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：2 step:2/500 loss：1.358954\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.319065 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2154\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：3 step:3/500 loss：1.334832\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.318076 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.2792\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：4 step:4/500 loss：1.332550\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.317605 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.2750\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：5 step:5/500 loss：1.285122\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.324122 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.2750\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：6 step:6/500 loss：1.306835\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.321750 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2214\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：7 step:7/500 loss：1.295493\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.323830 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1364\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：8 step:8/500 loss：1.260810\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.308589 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1250\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：9 step:9/500 loss：1.231165\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.300367 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1250\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：10 step:10/500 loss：1.219043\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.291219 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2197\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：11 step:11/500 loss：1.230663\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.283316 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2197\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：12 step:12/500 loss：1.191827\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.276945 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2214\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：13 step:13/500 loss：1.173903\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.251717 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2381\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：14 step:14/500 loss：1.122322\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.233856 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1667\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：15 step:15/500 loss：1.102429\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.239922 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2214\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：16 step:16/500 loss：1.035712\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.255159 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2197\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：17 step:17/500 loss：1.026662\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.299081 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2197\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：18 step:18/500 loss：1.035250\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.276917 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2197\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：19 step:19/500 loss：0.977556\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.221301 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1667\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：20 step:20/500 loss：0.946217\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.206462 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1667\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：21 step:21/500 loss：0.926405\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.211668 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1500\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：22 step:22/500 loss：0.905435\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.255349 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1364\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：23 step:23/500 loss：0.814053\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.248186 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1364\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：24 step:24/500 loss：0.841691\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.223321 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.1500\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：25 step:25/500 loss：0.769231\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.268497 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.3333\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：26 step:26/500 loss：0.706905\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.344183 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.3333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：27 step:27/500 loss：0.689902\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.307180 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.3333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：28 step:28/500 loss：0.696796\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.251478 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4000\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：29 step:29/500 loss：0.662169\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.297497 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：30 step:30/500 loss：0.650991\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.393816 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4833\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：31 step:31/500 loss：0.579234\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.375046 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：32 step:32/500 loss：0.573946\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.317349 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：33 step:33/500 loss：0.539542\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.358803 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.3333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：34 step:34/500 loss：0.576047\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.527482 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2708\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：35 step:35/500 loss：0.497741\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.508951 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2917\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：36 step:36/500 loss：0.467489\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.301797 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：37 step:37/500 loss：0.450032\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.277190 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：38 step:38/500 loss：0.386887\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.419577 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5429\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：39 step:39/500 loss：0.415251\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.439351 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5429\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：40 step:40/500 loss：0.409285\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.264475 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5625\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：41 step:41/500 loss：0.354771\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.207898 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：42 step:42/500 loss：0.410906\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.435840 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3917\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：43 step:43/500 loss：0.320668\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.644963 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.3167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：44 step:44/500 loss：0.270182\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.643968 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：45 step:45/500 loss：0.294408\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.500804 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：46 step:46/500 loss：0.249636\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.281161 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：47 step:47/500 loss：0.231208\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.262364 accuracy：0.7273 micro_f1：0.7273 macro_f1：0.7560\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：48 step:48/500 loss：0.243144\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.365684 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5429\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：49 step:49/500 loss：0.220803\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.466657 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：50 step:50/500 loss：0.242142\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.459946 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5417\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：51 step:51/500 loss：0.176061\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.453205 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：52 step:52/500 loss：0.174196\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.508924 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：53 step:53/500 loss：0.189934\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.627820 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5417\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：54 step:54/500 loss：0.167296\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.622172 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5125\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：55 step:55/500 loss：0.136284\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.494436 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5208\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：56 step:56/500 loss：0.116378\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.401310 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：57 step:57/500 loss：0.125696\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.428605 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：58 step:58/500 loss：0.120667\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.589701 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5417\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：59 step:59/500 loss：0.113307\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.616612 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：60 step:60/500 loss：0.107211\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.611552 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：61 step:61/500 loss：0.119141\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.599152 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：62 step:62/500 loss：0.088742\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.602329 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：63 step:63/500 loss：0.067869\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.623866 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：64 step:64/500 loss：0.086904\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.673701 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：65 step:65/500 loss：0.088724\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.706726 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：66 step:66/500 loss：0.070180\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.787580 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：67 step:67/500 loss：0.088584\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.813216 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：68 step:68/500 loss：0.062475\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.752337 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：69 step:69/500 loss：0.072323\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.662370 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4167\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：70 step:70/500 loss：0.049554\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.548785 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：71 step:71/500 loss：0.068430\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.492066 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：72 step:72/500 loss：0.087769\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.520217 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：73 step:73/500 loss：0.071259\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.533171 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：74 step:74/500 loss：0.052469\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.575489 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：75 step:75/500 loss：0.040565\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.631963 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：76 step:76/500 loss：0.038438\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.688561 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：77 step:77/500 loss：0.051440\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.633212 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：78 step:78/500 loss：0.036128\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.550331 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：79 step:79/500 loss：0.036048\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.518095 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：80 step:80/500 loss：0.045755\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.531291 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：81 step:81/500 loss：0.055015\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.580961 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：82 step:82/500 loss：0.050436\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.577490 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：83 step:83/500 loss：0.036846\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.588081 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：84 step:84/500 loss：0.047663\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.708417 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：85 step:85/500 loss：0.035248\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.888026 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：86 step:86/500 loss：0.065804\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.801846 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：87 step:87/500 loss：0.034400\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.834408 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：88 step:88/500 loss：0.030646\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.893594 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：89 step:89/500 loss：0.034310\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.872134 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：90 step:90/500 loss：0.033168\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.752206 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6208\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：91 step:91/500 loss：0.027565\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.686148 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：92 step:92/500 loss：0.027922\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.681642 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：93 step:93/500 loss：0.019385\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.693088 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：94 step:94/500 loss：0.023581\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.741333 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：95 step:95/500 loss：0.023195\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.835618 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：96 step:96/500 loss：0.016907\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.935837 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：97 step:97/500 loss：0.018673\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.995786 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：98 step:98/500 loss：0.033609\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.913683 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：99 step:99/500 loss：0.022457\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.827982 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：100 step:100/500 loss：0.015444\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.771670 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：101 step:101/500 loss：0.015279\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.750654 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：102 step:102/500 loss：0.018398\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.749903 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：103 step:103/500 loss：0.014717\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.752914 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：104 step:104/500 loss：0.018036\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.759938 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：105 step:105/500 loss：0.018312\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.770338 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：106 step:106/500 loss：0.024923\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.790187 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：107 step:107/500 loss：0.018350\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.821355 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：108 step:108/500 loss：0.011640\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.855641 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：109 step:109/500 loss：0.011986\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.890301 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：110 step:110/500 loss：0.012428\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.926609 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：111 step:111/500 loss：0.011447\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.959107 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：112 step:112/500 loss：0.015894\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.974127 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：113 step:113/500 loss：0.010804\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.978018 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：114 step:114/500 loss：0.010898\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.971514 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：115 step:115/500 loss：0.009575\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.965450 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：116 step:116/500 loss：0.013782\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.919638 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：117 step:117/500 loss：0.010254\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.880454 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：118 step:118/500 loss：0.008817\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.852003 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：119 step:119/500 loss：0.010220\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.829003 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：120 step:120/500 loss：0.012535\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.815308 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：121 step:121/500 loss：0.010125\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.811329 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：122 step:122/500 loss：0.014655\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.821901 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：123 step:123/500 loss：0.015262\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.855194 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：124 step:124/500 loss：0.010202\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.909182 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：125 step:125/500 loss：0.009251\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.974495 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：126 step:126/500 loss：0.008506\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.029658 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：127 step:127/500 loss：0.008865\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.074697 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：128 step:128/500 loss：0.006772\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.113206 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：129 step:129/500 loss：0.007459\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.138024 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：130 step:130/500 loss：0.011445\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.132380 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：131 step:131/500 loss：0.010574\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.130239 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：132 step:132/500 loss：0.025189\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.001162 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：133 step:133/500 loss：0.006813\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.912214 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：134 step:134/500 loss：0.017282\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.871270 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：135 step:135/500 loss：0.010131\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.837057 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：136 step:136/500 loss：0.007683\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.820542 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：137 step:137/500 loss：0.009015\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.815390 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：138 step:138/500 loss：0.008642\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.813516 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：139 step:139/500 loss：0.011542\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.813778 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：140 step:140/500 loss：0.007994\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.818084 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：141 step:141/500 loss：0.011053\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.825623 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：142 step:142/500 loss：0.009688\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.827722 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：143 step:143/500 loss：0.015210\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.836779 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：144 step:144/500 loss：0.041914\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.830011 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：145 step:145/500 loss：0.008098\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.892149 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：146 step:146/500 loss：0.022577\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.888900 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：147 step:147/500 loss：0.016949\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.058208 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：148 step:148/500 loss：0.008622\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.316984 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3958\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：149 step:149/500 loss：0.018479\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.379991 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3958\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：150 step:150/500 loss：0.018056\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.194011 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3875\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：151 step:151/500 loss：0.007878\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.071873 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：152 step:152/500 loss：0.008257\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.033839 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：153 step:153/500 loss：0.007425\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.060072 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：154 step:154/500 loss：0.015619\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.936113 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：155 step:155/500 loss：0.006555\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.850686 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：156 step:156/500 loss：0.007979\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.815917 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：157 step:157/500 loss：0.007646\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.808901 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：158 step:158/500 loss：0.008409\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.816481 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：159 step:159/500 loss：0.006703\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.822893 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：160 step:160/500 loss：0.008192\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.828722 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：161 step:161/500 loss：0.008571\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.831412 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：162 step:162/500 loss：0.006870\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.831632 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：163 step:163/500 loss：0.007951\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.830431 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：164 step:164/500 loss：0.007135\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.828386 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：165 step:165/500 loss：0.007714\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.829237 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：166 step:166/500 loss：0.007152\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.838908 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：167 step:167/500 loss：0.004901\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.859627 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：168 step:168/500 loss：0.005594\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.890574 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：169 step:169/500 loss：0.005466\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.928465 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：170 step:170/500 loss：0.004952\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.965882 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：171 step:171/500 loss：0.004272\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.002137 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：172 step:172/500 loss：0.005579\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.025029 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：173 step:173/500 loss：0.005375\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.030511 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：174 step:174/500 loss：0.005539\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.004551 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：175 step:175/500 loss：0.004337\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.978478 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：176 step:176/500 loss：0.004213\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.953914 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：177 step:177/500 loss：0.004640\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.930505 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：178 step:178/500 loss：0.004497\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.911890 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：179 step:179/500 loss：0.005822\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.903719 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：180 step:180/500 loss：0.005097\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.894475 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：181 step:181/500 loss：0.004006\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.884593 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：182 step:182/500 loss：0.003508\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.876292 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：183 step:183/500 loss：0.003600\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.870236 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：184 step:184/500 loss：0.003407\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.866681 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：185 step:185/500 loss：0.006060\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.859301 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：186 step:186/500 loss：0.004271\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.855841 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：187 step:187/500 loss：0.010421\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.874758 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：188 step:188/500 loss：0.005810\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.881250 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：189 step:189/500 loss：0.010445\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.893466 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：190 step:190/500 loss：0.005305\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.903410 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：191 step:191/500 loss：0.003878\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.909587 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：192 step:192/500 loss：0.007341\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.924120 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：193 step:193/500 loss：0.003246\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.939092 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：194 step:194/500 loss：0.003318\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.955375 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：195 step:195/500 loss：0.003681\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.970205 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：196 step:196/500 loss：0.003912\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.986376 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：197 step:197/500 loss：0.003769\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.998034 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：198 step:198/500 loss：0.003409\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.004719 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：199 step:199/500 loss：0.003213\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.010002 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：200 step:200/500 loss：0.003366\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.009864 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：201 step:201/500 loss：0.003103\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.003226 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：202 step:202/500 loss：0.003830\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.993367 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：203 step:203/500 loss：0.008912\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.919521 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：204 step:204/500 loss：0.003902\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.883778 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：205 step:205/500 loss：0.003911\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.879578 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：206 step:206/500 loss：0.004983\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.888796 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：207 step:207/500 loss：0.003846\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.901249 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：208 step:208/500 loss：0.004308\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.913295 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：209 step:209/500 loss：0.008019\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.936996 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：210 step:210/500 loss：0.008299\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.941212 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：211 step:211/500 loss：0.006338\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.942911 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：212 step:212/500 loss：0.004966\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.948238 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：213 step:213/500 loss：0.003736\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.960139 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：214 step:214/500 loss：0.004201\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.978001 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：215 step:215/500 loss：0.003245\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.998562 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：216 step:216/500 loss：0.002982\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.020044 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：217 step:217/500 loss：0.002619\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.041275 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：218 step:218/500 loss：0.002892\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.061137 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：219 step:219/500 loss：0.002955\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.081001 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：220 step:220/500 loss：0.003910\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.097954 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：221 step:221/500 loss：0.004415\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.102953 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：222 step:222/500 loss：0.005602\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.090596 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：223 step:223/500 loss：0.006078\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.105893 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：224 step:224/500 loss：0.003244\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.098842 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：225 step:225/500 loss：0.003013\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.073068 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：226 step:226/500 loss：0.007821\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.042566 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：227 step:227/500 loss：0.003999\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.029988 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：228 step:228/500 loss：0.004240\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.024235 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：229 step:229/500 loss：0.004221\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.015043 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：230 step:230/500 loss：0.002471\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.995891 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：231 step:231/500 loss：0.003983\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.979155 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：232 step:232/500 loss：0.002691\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.968442 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：233 step:233/500 loss：0.004725\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.969720 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：234 step:234/500 loss：0.004815\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.974649 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：235 step:235/500 loss：0.003943\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.985129 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：236 step:236/500 loss：0.003165\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.000176 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：237 step:237/500 loss：0.002966\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.015748 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：238 step:238/500 loss：0.002724\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.030060 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：239 step:239/500 loss：0.002642\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.040437 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：240 step:240/500 loss：0.002361\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.046408 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：241 step:241/500 loss：0.002328\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.050147 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：242 step:242/500 loss：0.002546\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.052107 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：243 step:243/500 loss：0.002470\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.053739 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：244 step:244/500 loss：0.002974\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.053159 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：245 step:245/500 loss：0.002659\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.051800 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：246 step:246/500 loss：0.002302\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.052181 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：247 step:247/500 loss：0.002335\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.051721 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：248 step:248/500 loss：0.002260\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.051281 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：249 step:249/500 loss：0.003206\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.050483 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：250 step:250/500 loss：0.005490\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.042390 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：251 step:251/500 loss：0.002388\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.036737 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：252 step:252/500 loss：0.002619\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.032948 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：253 step:253/500 loss：0.002230\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.030262 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：254 step:254/500 loss：0.002377\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.028321 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：255 step:255/500 loss：0.002126\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.027001 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：256 step:256/500 loss：0.003487\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.027755 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：257 step:257/500 loss：0.002114\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.028358 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：258 step:258/500 loss：0.005002\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.030958 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：259 step:259/500 loss：0.002143\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.033762 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：260 step:260/500 loss：0.002424\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.036901 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：261 step:261/500 loss：0.002464\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.040533 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：262 step:262/500 loss：0.002130\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.044531 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：263 step:263/500 loss：0.002667\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.048065 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：264 step:264/500 loss：0.002200\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.051332 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：265 step:265/500 loss：0.002075\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.054827 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：266 step:266/500 loss：0.002660\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.059251 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：267 step:267/500 loss：0.002077\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.063111 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：268 step:268/500 loss：0.001874\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.066380 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：269 step:269/500 loss：0.002513\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.068592 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：270 step:270/500 loss：0.002133\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.070221 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：271 step:271/500 loss：0.002365\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.070792 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：272 step:272/500 loss：0.001916\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.071579 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：273 step:273/500 loss：0.002122\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.073184 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：274 step:274/500 loss：0.002142\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.076996 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：275 step:275/500 loss：0.001959\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.081149 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：276 step:276/500 loss：0.002184\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.085356 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：277 step:277/500 loss：0.001741\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.089074 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：278 step:278/500 loss：0.001883\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.093723 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：279 step:279/500 loss：0.001913\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.096737 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：280 step:280/500 loss：0.002102\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.096759 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：281 step:281/500 loss：0.002038\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.096519 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：282 step:282/500 loss：0.001901\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.095817 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：283 step:283/500 loss：0.002205\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.095875 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：284 step:284/500 loss：0.002091\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.096077 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：285 step:285/500 loss：0.001922\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.095104 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：286 step:286/500 loss：0.001908\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.095078 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：287 step:287/500 loss：0.002007\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.096077 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：288 step:288/500 loss：0.001484\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.096602 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：289 step:289/500 loss：0.001860\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.096487 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：290 step:290/500 loss：0.001875\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.097190 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：291 step:291/500 loss：0.001851\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.097954 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：292 step:292/500 loss：0.001821\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.097525 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：293 step:293/500 loss：0.002361\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.097832 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：294 step:294/500 loss：0.001733\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.098256 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：295 step:295/500 loss：0.001967\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.098629 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：296 step:296/500 loss：0.002000\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.097722 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：297 step:297/500 loss：0.001897\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.095982 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：298 step:298/500 loss：0.003391\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.090683 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：299 step:299/500 loss：0.001780\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.086241 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：300 step:300/500 loss：0.002048\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.082981 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：301 step:301/500 loss：0.001811\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.079855 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：302 step:302/500 loss：0.001696\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.077492 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：303 step:303/500 loss：0.002122\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.076807 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：304 step:304/500 loss：0.001609\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.076462 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：305 step:305/500 loss：0.002782\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.073239 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：306 step:306/500 loss：0.001952\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.071963 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：307 step:307/500 loss：0.002006\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.075122 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：308 step:308/500 loss：0.001846\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.078590 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：309 step:309/500 loss：0.001973\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.083678 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：310 step:310/500 loss：0.003041\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.095773 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：311 step:311/500 loss：0.001652\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.107295 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：312 step:312/500 loss：0.001848\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.116766 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：313 step:313/500 loss：0.001887\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.128980 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：314 step:314/500 loss：0.002608\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.142526 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：315 step:315/500 loss：0.001700\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.153486 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：316 step:316/500 loss：0.001658\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.163292 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：317 step:317/500 loss：0.001726\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.169184 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：318 step:318/500 loss：0.001778\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.173616 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：319 step:319/500 loss：0.001885\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.178132 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：320 step:320/500 loss：0.001595\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.180420 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：321 step:321/500 loss：0.001940\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.184628 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：322 step:322/500 loss：0.001985\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.188475 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：323 step:323/500 loss：0.001559\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.191711 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：324 step:324/500 loss：0.001962\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.193545 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：325 step:325/500 loss：0.001522\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.192891 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：326 step:326/500 loss：0.001655\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.188607 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：327 step:327/500 loss：0.001253\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.184142 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：328 step:328/500 loss：0.001584\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.177727 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：329 step:329/500 loss：0.001468\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.171798 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：330 step:330/500 loss：0.001772\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.170912 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：331 step:331/500 loss：0.001269\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.169773 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：332 step:332/500 loss：0.001602\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.170644 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：333 step:333/500 loss：0.001661\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.173874 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：334 step:334/500 loss：0.001681\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.178145 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：335 step:335/500 loss：0.001476\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.182137 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：336 step:336/500 loss：0.001458\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.186984 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：337 step:337/500 loss：0.001310\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.191815 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：338 step:338/500 loss：0.001296\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.196526 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：339 step:339/500 loss：0.001431\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.198657 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：340 step:340/500 loss：0.001437\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.200218 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：341 step:341/500 loss：0.001927\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.196670 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：342 step:342/500 loss：0.001396\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.193897 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：343 step:343/500 loss：0.001453\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.191282 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：344 step:344/500 loss：0.001327\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.187854 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：345 step:345/500 loss：0.001949\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.185212 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：346 step:346/500 loss：0.001670\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.180713 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：347 step:347/500 loss：0.001377\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.175840 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：348 step:348/500 loss：0.001671\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.169427 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：349 step:349/500 loss：0.001607\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.163591 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：350 step:350/500 loss：0.001313\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.159630 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：351 step:351/500 loss：0.001567\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.155559 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：352 step:352/500 loss：0.001936\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.150980 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：353 step:353/500 loss：0.001401\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.146328 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：354 step:354/500 loss：0.001345\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.142355 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：355 step:355/500 loss：0.001802\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.141498 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：356 step:356/500 loss：0.001228\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.140262 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：357 step:357/500 loss：0.001425\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.140355 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：358 step:358/500 loss：0.001327\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.141960 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：359 step:359/500 loss：0.001448\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.143939 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：360 step:360/500 loss：0.001209\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.146648 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：361 step:361/500 loss：0.001810\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.146307 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：362 step:362/500 loss：0.001253\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.146418 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：363 step:363/500 loss：0.001950\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.146325 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：364 step:364/500 loss：0.003480\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.169688 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：365 step:365/500 loss：0.002340\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.206717 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：366 step:366/500 loss：0.001570\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.246026 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：367 step:367/500 loss：0.001629\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.273712 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：368 step:368/500 loss：0.001203\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.300326 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：369 step:369/500 loss：0.001701\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.311721 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：370 step:370/500 loss：0.001255\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.319887 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：371 step:371/500 loss：0.001161\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.325094 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：372 step:372/500 loss：0.001349\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.327141 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：373 step:373/500 loss：0.001453\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.317099 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：374 step:374/500 loss：0.001505\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.306505 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：375 step:375/500 loss：0.001414\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.296828 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：376 step:376/500 loss：0.001256\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.287716 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：377 step:377/500 loss：0.001298\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.278291 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：378 step:378/500 loss：0.001235\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.269962 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：379 step:379/500 loss：0.001294\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.261125 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：380 step:380/500 loss：0.001349\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.254611 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：381 step:381/500 loss：0.001491\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.243775 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：382 step:382/500 loss：0.001091\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.234627 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：383 step:383/500 loss：0.001266\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.226606 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：384 step:384/500 loss：0.001452\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.218328 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：385 step:385/500 loss：0.000980\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.211386 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：386 step:386/500 loss：0.002168\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.207770 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：387 step:387/500 loss：0.001260\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.204214 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：388 step:388/500 loss：0.001073\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.201041 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：389 step:389/500 loss：0.001113\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.199068 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：390 step:390/500 loss：0.001085\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.197427 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：391 step:391/500 loss：0.001149\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.195447 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：392 step:392/500 loss：0.001147\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.194496 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：393 step:393/500 loss：0.001290\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.196782 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：394 step:394/500 loss：0.001150\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.198792 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：395 step:395/500 loss：0.001093\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.201113 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：396 step:396/500 loss：0.001168\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.203745 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：397 step:397/500 loss：0.001468\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.208573 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：398 step:398/500 loss：0.001096\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.212186 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：399 step:399/500 loss：0.001173\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.216427 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：400 step:400/500 loss：0.001234\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.223016 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：401 step:401/500 loss：0.001067\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.228277 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：402 step:402/500 loss：0.001300\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.230918 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：403 step:403/500 loss：0.001187\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.232937 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：404 step:404/500 loss：0.000922\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.234902 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：405 step:405/500 loss：0.001005\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.236433 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：406 step:406/500 loss：0.001274\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.238099 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：407 step:407/500 loss：0.001254\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.238115 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：408 step:408/500 loss：0.001070\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.238501 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：409 step:409/500 loss：0.001374\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.238988 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：410 step:410/500 loss：0.000944\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.239086 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：411 step:411/500 loss：0.001120\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.237588 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：412 step:412/500 loss：0.001293\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.235675 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：413 step:413/500 loss：0.001113\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.232406 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：414 step:414/500 loss：0.001787\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.233738 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：415 step:415/500 loss：0.001017\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.234377 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：416 step:416/500 loss：0.001000\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.235151 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：417 step:417/500 loss：0.001053\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.236236 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：418 step:418/500 loss：0.001422\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.240357 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：419 step:419/500 loss：0.001083\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.243931 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：420 step:420/500 loss：0.001200\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.247798 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：421 step:421/500 loss：0.001091\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.251170 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：422 step:422/500 loss：0.000996\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.253842 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：423 step:423/500 loss：0.001019\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.257302 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：424 step:424/500 loss：0.001292\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.261906 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：425 step:425/500 loss：0.001150\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.265141 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：426 step:426/500 loss：0.001119\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.267174 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：427 step:427/500 loss：0.001066\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.269308 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：428 step:428/500 loss：0.000955\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.270859 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：429 step:429/500 loss：0.001042\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.271709 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：430 step:430/500 loss：0.002503\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.239037 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：431 step:431/500 loss：0.000895\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.218296 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：432 step:432/500 loss：0.001327\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.202907 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：433 step:433/500 loss：0.001074\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.190181 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：434 step:434/500 loss：0.001250\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.181482 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：435 step:435/500 loss：0.001078\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.174741 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：436 step:436/500 loss：0.001362\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.171660 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：437 step:437/500 loss：0.001173\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.170096 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：438 step:438/500 loss：0.001047\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.169509 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：439 step:439/500 loss：0.001502\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.171717 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：440 step:440/500 loss：0.001060\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.175420 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：441 step:441/500 loss：0.001376\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.182564 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：442 step:442/500 loss：0.001349\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.191946 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：443 step:443/500 loss：0.000885\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.201771 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：444 step:444/500 loss：0.008249\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.223643 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：445 step:445/500 loss：0.001142\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.332427 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：446 step:446/500 loss：0.007560\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.373823 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：447 step:447/500 loss：0.001381\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.426963 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：448 step:448/500 loss：0.001642\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.483412 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：449 step:449/500 loss：0.001085\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.535358 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：450 step:450/500 loss：0.001047\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.580358 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：451 step:451/500 loss：0.003538\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.403505 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：452 step:452/500 loss：0.001938\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.284412 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：453 step:453/500 loss：0.001931\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.231418 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6042\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：454 step:454/500 loss：0.002062\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.215468 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6042\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：455 step:455/500 loss：0.001327\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.213535 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：456 step:456/500 loss：0.001363\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.214288 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：457 step:457/500 loss：0.001599\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.214412 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：458 step:458/500 loss：0.003339\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.232781 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：459 step:459/500 loss：0.002229\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.271710 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：460 step:460/500 loss：0.001152\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.319415 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：461 step:461/500 loss：0.001033\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.369091 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：462 step:462/500 loss：0.001302\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.414460 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：463 step:463/500 loss：0.001391\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.450216 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：464 step:464/500 loss：0.001077\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.488083 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5333\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：465 step:465/500 loss：0.009060\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.629040 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：466 step:466/500 loss：0.001342\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.816964 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6083\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：467 step:467/500 loss：0.023769\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.904091 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：468 step:468/500 loss：0.001692\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：3.425336 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5429\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：469 step:469/500 loss：0.167669\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.485433 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6131\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：470 step:470/500 loss：0.379919\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.449430 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3958\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：471 step:471/500 loss：0.003150\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：4.288889 accuracy：0.2727 micro_f1：0.2727 macro_f1：0.2292\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：472 step:472/500 loss：0.506627\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：3.434469 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.2708\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：473 step:473/500 loss：0.144997\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.922744 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：474 step:474/500 loss：0.026799\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.729402 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4833\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：475 step:475/500 loss：0.055249\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.685835 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4881\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：476 step:476/500 loss：0.166801\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.524126 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4881\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：477 step:477/500 loss：0.140637\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.534387 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4554\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：478 step:478/500 loss：0.067975\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.670026 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5278\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：479 step:479/500 loss：0.061591\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.583331 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6042\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：480 step:480/500 loss：0.023697\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.763862 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6042\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：481 step:481/500 loss：0.024582\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.133430 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3958\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：482 step:482/500 loss：0.046500\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.385075 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3976\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：483 step:483/500 loss：0.039548\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.525949 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3976\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：484 step:484/500 loss：0.083349\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.461778 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.3976\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：485 step:485/500 loss：0.049626\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.243151 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5125\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：486 step:486/500 loss：0.033635\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.966164 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.5375\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：487 step:487/500 loss：0.015849\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.822643 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：488 step:488/500 loss：0.016277\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.819899 accuracy：0.7273 micro_f1：0.7273 macro_f1：0.7738\n",
      "------------>Save best model\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：489 step:489/500 loss：0.012938\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.844609 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7083\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：490 step:490/500 loss：0.011386\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.847842 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7083\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：491 step:491/500 loss：0.009042\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.833864 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6179\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：492 step:492/500 loss：0.009597\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.802227 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.6804\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：493 step:493/500 loss：0.005266\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.781154 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6042\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：494 step:494/500 loss：0.009426\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.793653 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6042\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：495 step:495/500 loss：0.005544\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.844197 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6042\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：496 step:496/500 loss：0.006471\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：1.934160 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：497 step:497/500 loss：0.005659\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.060688 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：498 step:498/500 loss：0.005008\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.193793 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "torch.Size([46, 4, 768])\n",
      "【train】 epoch：499 step:499/500 loss：0.003790\n",
      "torch.Size([11, 4, 768])\n",
      "【dev】 loss：2.323384 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6000\n",
      "======== Calculate Testing========\n",
      "torch.Size([11, 4, 768])\n",
      "【test】 loss：1.819899 accuracy：0.7273 micro_f1：0.7273 macro_f1：0.7738\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Cause_of_disease       1.00      0.75      0.86         4\n",
      "Treatment_of_disease       0.50      0.67      0.57         3\n",
      "            Negative       0.67      0.67      0.67         3\n",
      "         Association       1.00      1.00      1.00         1\n",
      "\n",
      "            accuracy                           0.73        11\n",
      "           macro avg       0.79      0.77      0.77        11\n",
      "        weighted avg       0.77      0.73      0.74        11\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_demo.sh\""
   ],
   "metadata": {
    "id": "_jYrUj6-sZ30",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654537757898,
     "user_tz": -420,
     "elapsed": 65130,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    },
    "outputId": "72aecd06-3116-4bdd-a905-8025b1103f02"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Cause_of_disease': 0, 'Treatment_of_disease': 1, 'Negative': 2, 'Association': 3}\n",
      "======== Prediction ========\n",
      "Halothane is known to oppose <e1start> digitalis <e1end>-induced <e2start> ventricular arrhythmias <e2end>. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "Both cases proved to be <e1start> cotton <e1end>-material-induced <e2start> granulomas <e2end>. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "The evidence for <e1start> soybean <e1end> products as <e2start> cancer <e2end> preventive agents.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "[Mortality trends in <e2start> cancer <e2end> attributable to <e1start> tobacco <e1end> in Mexico].  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "<e1start> Areca <e1end> nut chewing has a significant association with <e2start> systemic inflammation <e2end>.\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Association\n",
      "==========================\n",
      "<e2start> major depression <e2end> (MD) and regular <e1start> tobacco <e1end> use (RU) or nicotine dependence (ND).\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Association\n",
      "==========================\n",
      "Benefits of whole <e1start> ginger <e1end> extract in <e2start> prostate cancer <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "<e2start> schizophrenia <e2end> and <e1start> cannabis <e1end> is due to a shared genetic aetiology.\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Association\n",
      "==========================\n",
      "These risks may be even higher among <e1start> tobacco <e1end>-related <e2start> cancer <e2end> survivors (TRCS). \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "Role of Dau c 1 in three different patterns of <e1start> carrot <e1end>-induced <e2start> asthma <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "<e1start> Tobacco <e1end>-associated <e2start> cancers <e2end> included lung, esophageal, and H/N cancers. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "<e1start> Coffee <e1end> consumption not associated with risk of <e2start> pancreas cancer <e2end> in Finland.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Negative\n",
      "==========================\n",
      "Optimal dose of <e1start> garlic <e1end> to inhibit dimethylhydrazine-induced <e2start> colon cancer <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "<e2start> major depression <e2end> (MD) and regular tobacco use (<e1start> RU <e1end>) or nicotine dependence (ND).\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Association\n",
      "==========================\n",
      "Chinese <e1start> green tea <e1end> ameliorates <e2start> lung injury <e2end> in cigarette smoke-exposed rats.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "Studies on magnesium's mechanism of action in <e1start> digitalis <e1end>-induced <e2start> arrhythmias <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "Caffeine and <e1start> coffee <e1end> as therapeutics against <e2start> Alzheimer's disease <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "recent <e1start> coffee <e1end> drinking and the incidence of <e2start> cardiovascular disease <e2end>.\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Association\n",
      "==========================\n",
      "In nonexposed, tobacco-, or <e1start> marijuana <e1end>-smoke-exposed <e2start> breast cancer <e2end> cultures. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Negative\n",
      "==========================\n",
      "Aggressive <e1start> tobacco <e1end> control could avert millions of deaths from <e2start> tuberculosis <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "She had <e2start> asthma <e2end> when handling raw <e1start> carrots <e1end>. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "<e1start> Tobacco <e1end>-associated cancers included lung, <e2start> esophageal, and H/N cancers <e2end>. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "major depression (<e2start> MD <e2end>) and regular <e1start> tobacco <e1end> use (RU) or nicotine dependence (ND).\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Association\n",
      "==========================\n",
      "Halothane is known to oppose <e1start> digitalis <e1end>-induced <e2start> ventricular arrhythmias <e2end>.\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels： ['Cause_of_disease']\n",
      "true label： Treatment_of_disease\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/7-circle--v1.png\"/>**Summary**"
   ],
   "metadata": {
    "id": "Lkml6AWbmpQG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Train Output***"
   ],
   "metadata": {
    "id": "BnA3TTJlc64R"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "url = 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-train.csv'\n",
    "\n",
    "biobert_train = pd.read_csv(url)\n",
    "\n",
    "print(biobert_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USSuglMjc9Ox",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654543106230,
     "user_tz": -420,
     "elapsed": 2587,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "a0ed5f11-606b-4786-9786-e977976589e2"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    Time  Epoch  Step      Loss\n",
      "0    2022-06-06 17:36:07      0     0  1.424365\n",
      "1    2022-06-06 17:36:32      1     1  1.363355\n",
      "2    2022-06-06 17:36:33      2     2  1.358954\n",
      "3    2022-06-06 17:36:40      3     3  1.334832\n",
      "4    2022-06-06 17:36:47      4     4  1.332550\n",
      "..                   ...    ...   ...       ...\n",
      "495  2022-06-06 17:47:57    495   495  0.005544\n",
      "496  2022-06-06 17:47:58    496   496  0.006471\n",
      "497  2022-06-06 17:48:00    497   497  0.005659\n",
      "498  2022-06-06 17:48:01    498   498  0.005008\n",
      "499  2022-06-06 17:48:03    499   499  0.003790\n",
      "\n",
      "[500 rows x 4 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "with open(url, 'r') as csvfile:\n",
    "    lines = csv.reader(csvfile, delimiter=',')\n",
    "    for row in lines:\n",
    "        x.append(int(row[2]))\n",
    "        y.append(float(row[3]))\n",
    "\n",
    "plt.plot(x, y, color='g', linestyle='dashed',\n",
    "         marker='o', label=\"Training Loss\")\n",
    "\n",
    "plt.xticks(rotation=25)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "jft5hmyJdRxs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654543170958,
     "user_tz": -420,
     "elapsed": 1142,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "f167d619-e751-4c43-b5a0-2f60962932d6"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-train-chart.py\""
   ],
   "metadata": {
    "id": "J57mIdDqd7yt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654543498006,
     "user_tz": -420,
     "elapsed": 1661,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Dev Output***"
   ],
   "metadata": {
    "id": "bK8lrwmTfHVx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dev_url = 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-dev.csv'\n",
    "\n",
    "biobert_dev = pd.read_csv(dev_url)\n",
    "\n",
    "print(biobert_dev)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaL_JFVLekw5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654543549921,
     "user_tz": -420,
     "elapsed": 1318,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "7fae6c02-0b04-4f2f-9915-8271d5968515"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    Time      Loss  accuracy  micro_f1  macro_f1\n",
      "0    2022-06-06 17:36:08  1.336937    0.3636    0.3636    0.1333\n",
      "1    2022-06-06 17:36:32  1.325184    0.3636    0.3636    0.1333\n",
      "2    2022-06-06 17:36:33  1.319065    0.3636    0.3636    0.2154\n",
      "3    2022-06-06 17:36:40  1.318076    0.4545    0.4545    0.2792\n",
      "4    2022-06-06 17:36:47  1.317605    0.4545    0.4545    0.2750\n",
      "..                   ...       ...       ...       ...       ...\n",
      "495  2022-06-06 17:47:57  1.844197    0.5455    0.5455    0.6042\n",
      "496  2022-06-06 17:47:59  1.934160    0.5455    0.5455    0.6000\n",
      "497  2022-06-06 17:48:00  2.060688    0.5455    0.5455    0.6000\n",
      "498  2022-06-06 17:48:01  2.193793    0.5455    0.5455    0.6000\n",
      "499  2022-06-06 17:48:03  2.323384    0.5455    0.5455    0.6000\n",
      "\n",
      "[500 rows x 5 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dev_x = []\n",
    "dev_y = []\n",
    "\n",
    "with open(dev_url, 'r') as dev_csvfile:\n",
    "    dev_lines = csv.reader(dev_csvfile, delimiter=',')\n",
    "    for dev_row in dev_lines:\n",
    "        dev_x.append(float(dev_row[4]))\n",
    "        dev_y.append(float(dev_row[2]))\n",
    "\n",
    "plt.plot(dev_x, dev_y, color='g', linestyle='None',\n",
    "         marker='o', label=\"Dev Accuracy\")\n",
    "\n",
    "plt.xticks(rotation=25)\n",
    "plt.xlabel('F-1')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Development', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "FFVSP4rie1o-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654543578943,
     "user_tz": -420,
     "elapsed": 1248,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "576382f3-47d6-4b74-feb6-0f5436a67204"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/BiomedNLP-PubMedBERT-dev-chart.py\""
   ],
   "metadata": {
    "id": "zplYqxLme8bp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654543613325,
     "user_tz": -420,
     "elapsed": 1569,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Training, Validation, Test***"
   ],
   "metadata": {
    "id": "0IZfK4rIfM2Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "2022-06-06 17:47:43,346 - INFO - main.py - train - 86 - 【train】 epoch：488 step:488/500 loss：0.016277\n",
    "2022-06-06 17:47:43,547 - INFO - main.py - train - 92 - 【dev】 loss：1.819899 accuracy：0.7273 micro_f1：0.7273 macro_f1：0.7738\n",
    "2022-06-06 17:47:43,547 - INFO - main.py - train - 94 - ------------>Save best model\n",
    "...\n",
    "2022-06-06 17:48:03,406 - INFO - main.py - <module> - 247 - ======== Calculate Testing========\n",
    "2022-06-06 17:48:06,156 - INFO - main.py - <module> - 251 - 【test】 loss：1.819899 accuracy：0.7273 micro_f1：0.7273 macro_f1：0.7738\n",
    "```"
   ],
   "metadata": {
    "id": "vr8NCfCafPKG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "                       precision    recall  per-class    support\n",
    "                                            f1-scores\n",
    "\n",
    "    Cause_of_disease       1.00      0.75      0.86         4\n",
    "Treatment_of_disease       0.50      0.67      0.57         3\n",
    "            Negative       0.67      0.67      0.67         3\n",
    "         Association       1.00      1.00      1.00         1\n",
    "```\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://img.icons8.com/external-royyan-wijaya-detailed-outline-royyan-wijaya/24/undefined/external-arrow-arrow-line-royyan-wijaya-detailed-outline-royyan-wijaya-8.png\"/>\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "```\n",
    "                         precision    recall   Average     support\n",
    "                                              f1-scores\n",
    "\n",
    "            accuracy                            0.73         11\n",
    "           macro avg       0.79        0.77     0.77         11\n",
    "        weighted avg       0.77        0.73     0.74         11\n",
    "```"
   ],
   "metadata": {
    "id": "24nqLJP6fscV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Model Output**"
   ],
   "metadata": {
    "id": "JaS8ZJ0Mf-9z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! ls -lh \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hO1z2Y-Wf6vt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654543865259,
     "user_tz": -420,
     "elapsed": 657,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "952ecebd-3873-41b0-c867-6a75bbf0691f"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total 2.5G\n",
      "-rw------- 1 root root 1.3G Jun  6 18:14 best-Biobert.pt\n",
      "-rw------- 1 root root 1.3G Jun  6 17:51 best-BiomedNLP-PubMedBERT.pt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color-glass/48/undefined/code.png\"/> **Source Code on** [**Gitlab**](https://gitlab.com/research.dimas/nlp_bert_relation_extraction/) <img src=\"https://img.icons8.com/color/48/undefined/gitlab.png\"/>\n",
    "# ![#f03c15](https://via.placeholder.com/15/f03c15/000000?text=+) [**NLP Relation Extraction Bert**](https://gitlab.com/research.dimas/nlp_bert_relation_extraction/)"
   ],
   "metadata": {
    "id": "QBZWC4JOLUfM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "# \"*Alone we can do so little, together we can do so much*\""
   ],
   "metadata": {
    "id": "ThHpTmKTZC4Y"
   }
  }
 ]
}