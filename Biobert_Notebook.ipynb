{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Biobert_Notebook.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+) **NLP Research<br>Bert Relation Extraction in Biomedical using Biobert model and pytorch**\n",
    "## <img src=\"https://img.icons8.com/external-fauzidea-flat-fauzidea/64/undefined/external-man-avatar-avatar-fauzidea-flat-fauzidea.png\"/> **`Dimas Dwi Putra`**"
   ],
   "metadata": {
    "id": "QfRM-ftWOKX5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/1-circle--v1.png\"/>**Connect Google Storage**"
   ],
   "metadata": {
    "id": "DnGRwGq8MYbg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5ckZ9Tj94k0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542135058,
     "user_tz": -420,
     "elapsed": 21745,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "c1632525-b70b-4e8d-e14b-7a97ab7531c3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/2-circle--v1.png\"/>**Requirements**"
   ],
   "metadata": {
    "id": "7Lp6apVhMKi4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ! pip install pandas==1.4.2\n",
    "# ! pip install matplotlib==3.5.1\n",
    "! pip install openpyxl==3.0.9\n",
    "# ! pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "! pip install transformers==4.18.0\n",
    "! pip install scikit-learn==1.0.2\n",
    "! pip install pickleshare==0.7.5\n",
    "! pip install pickle5==0.0.12"
   ],
   "metadata": {
    "id": "J-x7B1by9_kB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/3-circle--v1.png\"/>**Check Device**"
   ],
   "metadata": {
    "id": "3SywR6WxMFML"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"\\nUsing GPU\")\n",
    "    print('\\nDevice name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"\\nNo GPU available, using the CPU instead.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAXU70uWJU-j",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654368033733,
     "user_tz": -420,
     "elapsed": 3535,
     "user": {
      "displayName": "Dimas D",
      "userId": "18269823303940984766"
     }
    },
    "outputId": "cec15bb7-83a8-4573-d43d-b4520cd7d817"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Using GPU\n",
      "\n",
      "Device name: Tesla T4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/4-circle--v1.png\"/>**Data Preprocessing into `train set` and `test set`**"
   ],
   "metadata": {
    "id": "4V17I1hsoLOE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/data_preprocessing.py\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXwMR1GVnhOs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654368040177,
     "user_tz": -420,
     "elapsed": 4664,
     "user": {
      "displayName": "Dimas D",
      "userId": "18269823303940984766"
     }
    },
    "outputId": "097e6093-705d-45eb-d1a4-74f8e9248654"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Negative                583\n",
      "Treatment_of_disease    507\n",
      "Cause_of_disease        183\n",
      "Association              34\n",
      "Name: relation, dtype: int64\n",
      "============================\n",
      "total data : 1307\n",
      "\n",
      "success to create predict.txt\n",
      "success to create train.txt\n",
      "success to create test.txt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/5-circle--v1.png\"/>**Preprocess Program**\n",
    "### **preprocess data with special token using `biobert pretrained model`**"
   ],
   "metadata": {
    "id": "DYNYPV4GHkm8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_preprocess.sh\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NW_8F7c_BncY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654538461309,
     "user_tz": -420,
     "elapsed": 17866,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    },
    "outputId": "6e9feb52-39f0-465b-9d4e-ae1230711fb4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'output_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint/', 'bert_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/model/Biobert/', 'data_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/', 'log_dir': 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/', 'num_tags': 4, 'seed': 123, 'gpu_ids': '0', 'max_seq_len': 128, 'eval_batch_size': 2, 'swa_start': 3, 'train_epochs': 75, 'dropout_prob': 0.8, 'lr': 1e-05, 'other_lr': 0.0001, 'max_grad_norm': 1, 'warmup_proportion': 0.1, 'weight_decay': 0.01, 'adam_epsilon': 1e-12, 'train_batch_size': 2, 'eval_model': True}\n",
      "==========================\n",
      "example_text : Halothane is known to oppose <e1start> digitalis <e1end>-induced <e2start> ventricular arrhythmias <e2end>. \n",
      "example_id_label : 0\n",
      "example_id_tags : [29, 56, 65, 106]\n",
      "==========================\n",
      "==========================\n",
      "example_text : Both cases proved to be <e1start> cotton <e1end>-material-induced <e2start> granulomas <e2end>. \n",
      "example_id_label : 0\n",
      "example_id_tags : [24, 48, 66, 94]\n",
      "==========================\n",
      "==========================\n",
      "example_text : The evidence for <e1start> soybean <e1end> products as <e2start> cancer <e2end> preventive agents.  \n",
      "example_id_label : 1\n",
      "example_id_tags : [17, 42, 55, 79]\n",
      "==========================\n",
      "==========================\n",
      "example_text : [Mortality trends in <e2start> cancer <e2end> attributable to <e1start> tobacco <e1end> in Mexico].  \n",
      "example_id_label : 0\n",
      "example_id_tags : [62, 87, 21, 45]\n",
      "==========================\n",
      "Convert 46 examples to features\n",
      "*** train_example-0 ***\n",
      "text: [CLS] H a l o t h a n e [UNK] i s [UNK] k n o w n [UNK] t o [UNK] o p p o s e [UNK] < e 1 s t a r t > [UNK] d i g i t a l i s [UNK] < e 1 e n d > - i n d u c e d [UNK] < e 2 s t a r t > [UNK] v e n t r i c u l a r [UNK] a r r h y t h m i a s [UNK] < e 2 e n d >. [UNK] [SEP]\n",
      "token_ids: [101, 145, 170, 181, 184, 189, 177, 170, 183, 174, 100, 178, 188, 100, 180, 183, 184, 192, 183, 100, 189, 184, 100, 184, 185, 185, 184, 188, 174, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 173, 178, 176, 178, 189, 170, 181, 178, 188, 100, 133, 174, 122, 174, 183, 173, 135, 118, 178, 183, 173, 190, 172, 174, 173, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 191, 174, 183, 189, 187, 178, 172, 190, 181, 170, 187, 100, 170, 187, 187, 177, 194, 189, 177, 182, 178, 170, 188, 100, 133, 174, 123, 174, 183, 173, 135, 119, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [30, 57, 66, 107]\n",
      "*** train_example-1 ***\n",
      "text: [CLS] B o t h [UNK] c a s e s [UNK] p r o v e d [UNK] t o [UNK] b e [UNK] < e 1 s t a r t > [UNK] c o t t o n [UNK] < e 1 e n d > - m a t e r i a l - i n d u c e d [UNK] < e 2 s t a r t > [UNK] g r a n u l o m a s [UNK] < e 2 e n d >. [UNK] [SEP]\n",
      "token_ids: [101, 139, 184, 189, 177, 100, 172, 170, 188, 174, 188, 100, 185, 187, 184, 191, 174, 173, 100, 189, 184, 100, 171, 174, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 172, 184, 189, 189, 184, 183, 100, 133, 174, 122, 174, 183, 173, 135, 118, 182, 170, 189, 174, 187, 178, 170, 181, 118, 178, 183, 173, 190, 172, 174, 173, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 176, 187, 170, 183, 190, 181, 184, 182, 170, 188, 100, 133, 174, 123, 174, 183, 173, 135, 119, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [25, 49, 67, 95]\n",
      "*** train_example-2 ***\n",
      "text: [CLS] T h e [UNK] e v i d e n c e [UNK] f o r [UNK] < e 1 s t a r t > [UNK] s o y b e a n [UNK] < e 1 e n d > [UNK] p r o d u c t s [UNK] a s [UNK] < e 2 s t a r t > [UNK] c a n c e r [UNK] < e 2 e n d > [UNK] p r e v e n t i v e [UNK] a g e n t s. [UNK] [UNK] [SEP]\n",
      "token_ids: [101, 157, 177, 174, 100, 174, 191, 178, 173, 174, 183, 172, 174, 100, 175, 184, 187, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 188, 184, 194, 171, 174, 170, 183, 100, 133, 174, 122, 174, 183, 173, 135, 100, 185, 187, 184, 173, 190, 172, 189, 188, 100, 170, 188, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 172, 170, 183, 172, 174, 187, 100, 133, 174, 123, 174, 183, 173, 135, 100, 185, 187, 174, 191, 174, 183, 189, 178, 191, 174, 100, 170, 176, 174, 183, 189, 188, 119, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 1\n",
      "ids: [18, 43, 56, 80]\n",
      "*** train_example-3 ***\n",
      "text: [CLS] [ M o r t a l i t y [UNK] t r e n d s [UNK] i n [UNK] < e 2 s t a r t > [UNK] c a n c e r [UNK] < e 2 e n d > [UNK] a t t r i b u t a b l e [UNK] t o [UNK] < e 1 s t a r t > [UNK] t o b a c c o [UNK] < e 1 e n d > [UNK] i n [UNK] M e x i c o ]. [UNK] [UNK] [SEP]\n",
      "token_ids: [101, 164, 150, 184, 187, 189, 170, 181, 178, 189, 194, 100, 189, 187, 174, 183, 173, 188, 100, 178, 183, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 172, 170, 183, 172, 174, 187, 100, 133, 174, 123, 174, 183, 173, 135, 100, 170, 189, 189, 187, 178, 171, 190, 189, 170, 171, 181, 174, 100, 189, 184, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 189, 184, 171, 170, 172, 172, 184, 100, 133, 174, 122, 174, 183, 173, 135, 100, 178, 183, 100, 150, 174, 193, 178, 172, 184, 166, 119, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [63, 88, 22, 46]\n",
      "Build 46 features\n",
      "==========================\n",
      "example_text : Its effect on <e1start> digitalis <e1end>-caused <e2start> atrial arrhythmias <e2end> is unknown. \n",
      "example_id_label : 0\n",
      "example_id_tags : [14, 41, 49, 85]\n",
      "==========================\n",
      "==========================\n",
      "example_text : However, the growth rate of <e2start> tumors <e2end> was not markedly inhibited by <e1start> garlic <e1end>. \n",
      "example_id_label : 2\n",
      "example_id_tags : [83, 107, 28, 52]\n",
      "==========================\n",
      "==========================\n",
      "example_text : <e1start> Tobacco <e1end>-related <e2start> cancers <e2end> in Madras, India.  \n",
      "example_id_label : 0\n",
      "example_id_tags : [0, 25, 34, 59]\n",
      "==========================\n",
      "==========================\n",
      "example_text : The importance of the <e1start> pecan <e1end> tree pollen in <e2start> allergic <e2end> manifestations.  \n",
      "example_id_label : 0\n",
      "example_id_tags : [22, 45, 61, 87]\n",
      "==========================\n",
      "Convert 11 examples to features\n",
      "*** dev_example-0 ***\n",
      "text: [CLS] I t s [UNK] e f f e c t [UNK] o n [UNK] < e 1 s t a r t > [UNK] d i g i t a l i s [UNK] < e 1 e n d > - c a u s e d [UNK] < e 2 s t a r t > [UNK] a t r i a l [UNK] a r r h y t h m i a s [UNK] < e 2 e n d > [UNK] i s [UNK] u n k n o w n. [UNK] [SEP]\n",
      "token_ids: [101, 146, 189, 188, 100, 174, 175, 175, 174, 172, 189, 100, 184, 183, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 173, 178, 176, 178, 189, 170, 181, 178, 188, 100, 133, 174, 122, 174, 183, 173, 135, 118, 172, 170, 190, 188, 174, 173, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 170, 189, 187, 178, 170, 181, 100, 170, 187, 187, 177, 194, 189, 177, 182, 178, 170, 188, 100, 133, 174, 123, 174, 183, 173, 135, 100, 178, 188, 100, 190, 183, 180, 183, 184, 192, 183, 119, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [15, 42, 50, 86]\n",
      "*** dev_example-1 ***\n",
      "text: [CLS] H o w e v e r, [UNK] t h e [UNK] g r o w t h [UNK] r a t e [UNK] o f [UNK] < e 2 s t a r t > [UNK] t u m o r s [UNK] < e 2 e n d > [UNK] w a s [UNK] n o t [UNK] m a r k e d l y [UNK] i n h i b i t e d [UNK] b y [UNK] < e 1 s t a r t > [UNK] g a r l i c [UNK] < e 1 e n d >. [UNK] [SEP]\n",
      "token_ids: [101, 145, 184, 192, 174, 191, 174, 187, 117, 100, 189, 177, 174, 100, 176, 187, 184, 192, 189, 177, 100, 187, 170, 189, 174, 100, 184, 175, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 189, 190, 182, 184, 187, 188, 100, 133, 174, 123, 174, 183, 173, 135, 100, 192, 170, 188, 100, 183, 184, 189, 100, 182, 170, 187, 180, 174, 173, 181, 194, 100, 178, 183, 177, 178, 171, 178, 189, 174, 173, 100, 171, 194, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 176, 170, 187, 181, 178, 172, 100, 133, 174, 122, 174, 183, 173, 135, 119, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 2\n",
      "ids: [84, 108, 29, 53]\n",
      "*** dev_example-2 ***\n",
      "text: [CLS] < e 1 s t a r t > [UNK] T o b a c c o [UNK] < e 1 e n d > - r e l a t e d [UNK] < e 2 s t a r t > [UNK] c a n c e r s [UNK] < e 2 e n d > [UNK] i n [UNK] M a d r a s, [UNK] I n d i a. [UNK] [UNK] [SEP]\n",
      "token_ids: [101, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 157, 184, 171, 170, 172, 172, 184, 100, 133, 174, 122, 174, 183, 173, 135, 118, 187, 174, 181, 170, 189, 174, 173, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 172, 170, 183, 172, 174, 187, 188, 100, 133, 174, 123, 174, 183, 173, 135, 100, 178, 183, 100, 150, 170, 173, 187, 170, 188, 117, 100, 146, 183, 173, 178, 170, 119, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [1, 26, 35, 60]\n",
      "*** dev_example-3 ***\n",
      "text: [CLS] T h e [UNK] i m p o r t a n c e [UNK] o f [UNK] t h e [UNK] < e 1 s t a r t > [UNK] p e c a n [UNK] < e 1 e n d > [UNK] t r e e [UNK] p o l l e n [UNK] i n [UNK] < e 2 s t a r t > [UNK] a l l e r g i c [UNK] < e 2 e n d > [UNK] m a n i f e s t a t i o n s. [UNK] [UNK] [SEP]\n",
      "token_ids: [101, 157, 177, 174, 100, 178, 182, 185, 184, 187, 189, 170, 183, 172, 174, 100, 184, 175, 100, 189, 177, 174, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 185, 174, 172, 170, 183, 100, 133, 174, 122, 174, 183, 173, 135, 100, 189, 187, 174, 174, 100, 185, 184, 181, 181, 174, 183, 100, 178, 183, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 170, 181, 181, 174, 187, 176, 178, 172, 100, 133, 174, 123, 174, 183, 173, 135, 100, 182, 170, 183, 178, 175, 174, 188, 189, 170, 189, 178, 184, 183, 188, 119, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [23, 46, 62, 88]\n",
      "Build 11 features\n",
      "==========================\n",
      "example_text : Its effect on <e1start> digitalis <e1end>-caused <e2start> atrial arrhythmias <e2end> is unknown. \n",
      "example_id_label : 0\n",
      "example_id_tags : [14, 41, 49, 85]\n",
      "==========================\n",
      "==========================\n",
      "example_text : However, the growth rate of <e2start> tumors <e2end> was not markedly inhibited by <e1start> garlic <e1end>. \n",
      "example_id_label : 2\n",
      "example_id_tags : [83, 107, 28, 52]\n",
      "==========================\n",
      "==========================\n",
      "example_text : <e1start> Tobacco <e1end>-related <e2start> cancers <e2end> in Madras, India.  \n",
      "example_id_label : 0\n",
      "example_id_tags : [0, 25, 34, 59]\n",
      "==========================\n",
      "==========================\n",
      "example_text : The importance of the <e1start> pecan <e1end> tree pollen in <e2start> allergic <e2end> manifestations.  \n",
      "example_id_label : 0\n",
      "example_id_tags : [22, 45, 61, 87]\n",
      "==========================\n",
      "Convert 11 examples to features\n",
      "*** test_example-0 ***\n",
      "text: [CLS] I t s [UNK] e f f e c t [UNK] o n [UNK] < e 1 s t a r t > [UNK] d i g i t a l i s [UNK] < e 1 e n d > - c a u s e d [UNK] < e 2 s t a r t > [UNK] a t r i a l [UNK] a r r h y t h m i a s [UNK] < e 2 e n d > [UNK] i s [UNK] u n k n o w n. [UNK] [SEP]\n",
      "token_ids: [101, 146, 189, 188, 100, 174, 175, 175, 174, 172, 189, 100, 184, 183, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 173, 178, 176, 178, 189, 170, 181, 178, 188, 100, 133, 174, 122, 174, 183, 173, 135, 118, 172, 170, 190, 188, 174, 173, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 170, 189, 187, 178, 170, 181, 100, 170, 187, 187, 177, 194, 189, 177, 182, 178, 170, 188, 100, 133, 174, 123, 174, 183, 173, 135, 100, 178, 188, 100, 190, 183, 180, 183, 184, 192, 183, 119, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [15, 42, 50, 86]\n",
      "*** test_example-1 ***\n",
      "text: [CLS] H o w e v e r, [UNK] t h e [UNK] g r o w t h [UNK] r a t e [UNK] o f [UNK] < e 2 s t a r t > [UNK] t u m o r s [UNK] < e 2 e n d > [UNK] w a s [UNK] n o t [UNK] m a r k e d l y [UNK] i n h i b i t e d [UNK] b y [UNK] < e 1 s t a r t > [UNK] g a r l i c [UNK] < e 1 e n d >. [UNK] [SEP]\n",
      "token_ids: [101, 145, 184, 192, 174, 191, 174, 187, 117, 100, 189, 177, 174, 100, 176, 187, 184, 192, 189, 177, 100, 187, 170, 189, 174, 100, 184, 175, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 189, 190, 182, 184, 187, 188, 100, 133, 174, 123, 174, 183, 173, 135, 100, 192, 170, 188, 100, 183, 184, 189, 100, 182, 170, 187, 180, 174, 173, 181, 194, 100, 178, 183, 177, 178, 171, 178, 189, 174, 173, 100, 171, 194, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 176, 170, 187, 181, 178, 172, 100, 133, 174, 122, 174, 183, 173, 135, 119, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 2\n",
      "ids: [84, 108, 29, 53]\n",
      "*** test_example-2 ***\n",
      "text: [CLS] < e 1 s t a r t > [UNK] T o b a c c o [UNK] < e 1 e n d > - r e l a t e d [UNK] < e 2 s t a r t > [UNK] c a n c e r s [UNK] < e 2 e n d > [UNK] i n [UNK] M a d r a s, [UNK] I n d i a. [UNK] [UNK] [SEP]\n",
      "token_ids: [101, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 157, 184, 171, 170, 172, 172, 184, 100, 133, 174, 122, 174, 183, 173, 135, 118, 187, 174, 181, 170, 189, 174, 173, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 172, 170, 183, 172, 174, 187, 188, 100, 133, 174, 123, 174, 183, 173, 135, 100, 178, 183, 100, 150, 170, 173, 187, 170, 188, 117, 100, 146, 183, 173, 178, 170, 119, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [1, 26, 35, 60]\n",
      "*** test_example-3 ***\n",
      "text: [CLS] T h e [UNK] i m p o r t a n c e [UNK] o f [UNK] t h e [UNK] < e 1 s t a r t > [UNK] p e c a n [UNK] < e 1 e n d > [UNK] t r e e [UNK] p o l l e n [UNK] i n [UNK] < e 2 s t a r t > [UNK] a l l e r g i c [UNK] < e 2 e n d > [UNK] m a n i f e s t a t i o n s. [UNK] [UNK] [SEP]\n",
      "token_ids: [101, 157, 177, 174, 100, 178, 182, 185, 184, 187, 189, 170, 183, 172, 174, 100, 184, 175, 100, 189, 177, 174, 100, 133, 174, 122, 188, 189, 170, 187, 189, 135, 100, 185, 174, 172, 170, 183, 100, 133, 174, 122, 174, 183, 173, 135, 100, 189, 187, 174, 174, 100, 185, 184, 181, 181, 174, 183, 100, 178, 183, 100, 133, 174, 123, 188, 189, 170, 187, 189, 135, 100, 170, 181, 181, 174, 187, 176, 178, 172, 100, 133, 174, 123, 174, 183, 173, 135, 100, 182, 170, 183, 178, 175, 174, 188, 189, 170, 189, 178, 184, 183, 188, 119, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: 0\n",
      "ids: [23, 46, 62, 88]\n",
      "Build 11 features\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/6-circle--v1.png\"/>**Main Program**\n",
    "### **`train`, `eval`, create new `model pytorch`, test model , <br>compute `cross validation`, `f-1 score`, and <br>test predict data with new model `.pt`**"
   ],
   "metadata": {
    "id": "167FnNFAGdGN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "f_run_main = open(\"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_main.sh\", \"r\")\n",
    "print(f_run_main.read())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Di73LYnvvI40",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654538467761,
     "user_tz": -420,
     "elapsed": 2704,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    },
    "outputId": "925bff89-9643-46f9-a72f-25cd66639c87"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#!/usr/bin/env bash\n",
      "python \"drive/MyDrive/Colab Notebooks/bert_relation_extraction/main.py\" \\\n",
      "--bert_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/model/Biobert/\" \\\n",
      "--data_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/input/data/\" \\\n",
      "--log_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/logs/\" \\\n",
      "--output_dir=\"drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint/\" \\\n",
      "--num_tags=4 \\\n",
      "--seed=123 \\\n",
      "--gpu_ids=\"0\" \\\n",
      "--max_seq_len=128 \\\n",
      "--lr=1e-5 \\\n",
      "--other_lr=1e-4 \\\n",
      "--train_batch_size=2 \\\n",
      "--train_epochs=75 \\\n",
      "--eval_batch_size=2 \\\n",
      "--dropout_prob=0.8 \\\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_main.sh\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGtbTcn1wvPG",
    "outputId": "650f01af-a642-4cae-a1af-3ba82be6875c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654539140703,
     "user_tz": -420,
     "elapsed": 656582,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001B[0m\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.261079 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6083\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：50 step:1172/1725 loss：0.006138\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.992808 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6083\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1173/1725 loss：0.022178\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.832147 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6083\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1174/1725 loss：0.025977\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.790958 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6083\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1175/1725 loss：0.024700\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.817288 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1176/1725 loss：0.004604\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.855080 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1177/1725 loss：0.001802\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.890969 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1178/1725 loss：0.039585\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.902422 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1179/1725 loss：0.024427\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.890062 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1180/1725 loss：0.004557\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.877610 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1181/1725 loss：0.018011\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.868607 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1182/1725 loss：0.112072\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.772945 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1183/1725 loss：0.020726\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.677344 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4750\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1184/1725 loss：0.008736\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.600148 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4697\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1185/1725 loss：0.029564\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.552129 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6083\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1186/1725 loss：0.004946\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.525346 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6083\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1187/1725 loss：0.006570\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.515229 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4714\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1188/1725 loss：0.008637\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.524056 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4714\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1189/1725 loss：0.025851\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.558768 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4714\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1190/1725 loss：0.004125\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.606109 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4714\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1191/1725 loss：0.018773\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.659311 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4714\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1192/1725 loss：0.008796\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.712613 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4714\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1193/1725 loss：0.011204\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.753128 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4714\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1194/1725 loss：0.002693\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.793475 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.4714\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：51 step:1195/1725 loss：0.007955\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.840592 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1196/1725 loss：0.047643\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.769321 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1197/1725 loss：0.009597\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.705056 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1198/1725 loss：0.012683\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.646681 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1199/1725 loss：0.011633\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.601762 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1200/1725 loss：0.005128\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.565577 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1201/1725 loss：0.009028\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.540528 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1202/1725 loss：0.017582\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.500590 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1203/1725 loss：0.035306\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.461920 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1204/1725 loss：0.012512\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.432001 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1205/1725 loss：0.016168\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.414564 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1206/1725 loss：0.120983\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.365382 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1207/1725 loss：0.004050\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.324105 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1208/1725 loss：0.025032\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.266190 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1209/1725 loss：0.039423\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.263055 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1210/1725 loss：0.008269\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.261205 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1211/1725 loss：0.022121\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.279459 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1212/1725 loss：0.061312\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.295001 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1213/1725 loss：0.002426\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.312512 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1214/1725 loss：0.019094\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.325780 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1215/1725 loss：0.004290\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.338144 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1216/1725 loss：0.007264\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.351307 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1217/1725 loss：0.049959\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.356938 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：52 step:1218/1725 loss：0.010091\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.362217 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1219/1725 loss：0.013380\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.350204 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1220/1725 loss：0.010313\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.350193 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1221/1725 loss：0.039307\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.303294 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1222/1725 loss：0.009022\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.263462 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1223/1725 loss：0.007834\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.231899 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1224/1725 loss：0.043734\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.219164 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1225/1725 loss：0.011998\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.209060 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1226/1725 loss：0.005888\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.198865 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1227/1725 loss：0.003197\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.189280 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1228/1725 loss：0.009208\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.179847 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1229/1725 loss：0.003349\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.171395 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1230/1725 loss：0.009864\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.165744 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1231/1725 loss：0.008110\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.160290 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1232/1725 loss：0.012069\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.150577 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1233/1725 loss：0.008045\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.143407 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1234/1725 loss：0.004274\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.135567 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1235/1725 loss：0.004593\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.130609 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1236/1725 loss：0.053917\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.055706 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1237/1725 loss：0.004277\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.997012 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1238/1725 loss：0.014369\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.945293 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1239/1725 loss：0.005181\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.902941 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1240/1725 loss：0.014882\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.875489 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：53 step:1241/1725 loss：0.004214\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.853752 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1242/1725 loss：0.006292\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.834598 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1243/1725 loss：0.015952\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.820278 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1244/1725 loss：0.014304\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.815625 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1245/1725 loss：0.006962\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.810640 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1246/1725 loss：0.003986\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.806617 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1247/1725 loss：0.006778\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.803813 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1248/1725 loss：0.004973\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.802579 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1249/1725 loss：0.009976\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.798727 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1250/1725 loss：0.022441\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.790543 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1251/1725 loss：0.004472\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.785775 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1252/1725 loss：0.005376\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.780806 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1253/1725 loss：0.005924\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.778110 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1254/1725 loss：0.005235\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.775091 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1255/1725 loss：0.041687\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.776627 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1256/1725 loss：0.005959\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.778643 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1257/1725 loss：0.002111\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.780905 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1258/1725 loss：0.014485\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.786588 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1259/1725 loss：0.017764\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.797879 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1260/1725 loss：0.006367\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.808631 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1261/1725 loss：0.014589\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.820826 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1262/1725 loss：0.059291\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.835453 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1263/1725 loss：0.004237\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.849017 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：54 step:1264/1725 loss：0.045563\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.874558 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1265/1725 loss：0.006876\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.899294 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1266/1725 loss：0.002801\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.922193 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1267/1725 loss：0.004189\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.943170 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1268/1725 loss：0.003069\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.962596 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1269/1725 loss：0.010267\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.977335 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1270/1725 loss：0.007294\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：11.999566 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1271/1725 loss：0.004474\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.017630 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1272/1725 loss：0.016183\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.034713 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1273/1725 loss：0.009241\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.051404 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1274/1725 loss：0.010854\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.103619 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1275/1725 loss：0.014108\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.166104 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1276/1725 loss：0.032697\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.229119 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1277/1725 loss：0.010478\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.294910 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1278/1725 loss：0.002040\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.358558 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1279/1725 loss：0.031443\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.399008 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1280/1725 loss：0.012002\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.438889 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1281/1725 loss：0.010457\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.482254 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1282/1725 loss：0.017978\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.521961 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1283/1725 loss：0.012468\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.552481 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1284/1725 loss：0.003341\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.580044 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1285/1725 loss：0.023523\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.622827 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1286/1725 loss：0.020943\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.634126 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：55 step:1287/1725 loss：0.001399\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.644105 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1288/1725 loss：0.005121\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.655491 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1289/1725 loss：0.016073\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.694772 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1290/1725 loss：0.021710\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.718490 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1291/1725 loss：0.008227\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.738702 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1292/1725 loss：0.003526\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.757172 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1293/1725 loss：0.028153\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.655624 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1294/1725 loss：0.022029\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.567929 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1295/1725 loss：0.014049\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.502836 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1296/1725 loss：0.004998\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.452202 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1297/1725 loss：0.004085\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.413287 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1298/1725 loss：0.030831\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.393748 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1299/1725 loss：0.017935\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.389501 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1300/1725 loss：0.006889\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.385818 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1301/1725 loss：0.022715\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.398298 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1302/1725 loss：0.007918\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.409528 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1303/1725 loss：0.002662\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.422206 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1304/1725 loss：0.003357\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.434552 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1305/1725 loss：0.025106\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.442123 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1306/1725 loss：0.012478\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.457069 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1307/1725 loss：0.013392\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.468618 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1308/1725 loss：0.005804\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.481902 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1309/1725 loss：0.005186\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.495806 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：56 step:1310/1725 loss：0.007138\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.507914 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1311/1725 loss：0.023602\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.532255 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1312/1725 loss：0.016440\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.571717 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1313/1725 loss：0.010564\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.612539 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1314/1725 loss：0.065223\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.681761 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1315/1725 loss：0.003389\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.752544 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1316/1725 loss：0.007791\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.824334 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1317/1725 loss：0.032149\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.886850 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1318/1725 loss：0.010531\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.942075 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1319/1725 loss：0.013950\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.985483 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1320/1725 loss：0.006930\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.018456 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1321/1725 loss：0.007240\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.045615 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1322/1725 loss：0.002991\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.068949 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1323/1725 loss：0.005423\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.086065 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1324/1725 loss：0.008951\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.101216 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1325/1725 loss：0.003469\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.113553 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1326/1725 loss：0.008119\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.121649 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1327/1725 loss：0.004320\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.128658 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1328/1725 loss：0.004119\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.131904 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1329/1725 loss：0.003448\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.138997 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1330/1725 loss：0.042710\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.103761 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1331/1725 loss：0.019081\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.097136 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1332/1725 loss：0.021026\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.037999 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：57 step:1333/1725 loss：0.001568\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.985524 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1334/1725 loss：0.002647\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.940785 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1335/1725 loss：0.014029\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.889839 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1336/1725 loss：0.027731\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.857834 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1337/1725 loss：0.022604\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.815468 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1338/1725 loss：0.004363\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.775711 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1339/1725 loss：0.006714\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.736428 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1340/1725 loss：0.010261\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.702523 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1341/1725 loss：0.012816\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.683441 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1342/1725 loss：0.005788\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.656670 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1343/1725 loss：0.005567\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.630903 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1344/1725 loss：0.002359\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.609744 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1345/1725 loss：0.046435\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.551477 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1346/1725 loss：0.026837\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.537837 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1347/1725 loss：0.006261\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.522455 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1348/1725 loss：0.018014\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.494566 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1349/1725 loss：0.008080\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.480805 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1350/1725 loss：0.012701\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.463359 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1351/1725 loss：0.003208\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.449759 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1352/1725 loss：0.001624\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.438810 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1353/1725 loss：0.007791\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.436922 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1354/1725 loss：0.017327\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.428789 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1355/1725 loss：0.008639\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.421991 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：58 step:1356/1725 loss：0.012464\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.418107 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1357/1725 loss：0.001969\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.415010 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1358/1725 loss：0.004856\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.414098 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1359/1725 loss：0.005734\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.414960 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1360/1725 loss：0.034366\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.469526 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1361/1725 loss：0.001275\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.525138 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1362/1725 loss：0.004856\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.583849 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1363/1725 loss：0.006145\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.642011 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1364/1725 loss：0.021948\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.702965 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1365/1725 loss：0.020550\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.760671 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1366/1725 loss：0.014721\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.805431 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1367/1725 loss：0.033101\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.874856 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1368/1725 loss：0.001781\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.940833 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1369/1725 loss：0.006249\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.006740 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1370/1725 loss：0.013341\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.066005 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1371/1725 loss：0.002363\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.120324 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1372/1725 loss：0.011073\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.163431 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1373/1725 loss：0.008654\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.189923 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1374/1725 loss：0.002692\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.213097 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1375/1725 loss：0.001600\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.234974 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1376/1725 loss：0.004687\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.259679 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1377/1725 loss：0.018436\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.251142 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1378/1725 loss：0.003200\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.246233 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：59 step:1379/1725 loss：0.002221\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.244818 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1380/1725 loss：0.035626\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.239572 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1381/1725 loss：0.003175\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.235451 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1382/1725 loss：0.003639\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.234136 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1383/1725 loss：0.006920\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.230018 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1384/1725 loss：0.004390\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.224475 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1385/1725 loss：0.006545\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.217563 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1386/1725 loss：0.002921\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.216763 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1387/1725 loss：0.011702\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.233017 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1388/1725 loss：0.004763\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.248294 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1389/1725 loss：0.005244\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.254255 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1390/1725 loss：0.008510\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.256127 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1391/1725 loss：0.039546\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.209859 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1392/1725 loss：0.010169\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.172174 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1393/1725 loss：0.001965\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.139448 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1394/1725 loss：0.025190\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.102850 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1395/1725 loss：0.003192\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.074726 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1396/1725 loss：0.003233\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.049849 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1397/1725 loss：0.017740\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.034296 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1398/1725 loss：0.007292\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.019513 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1399/1725 loss：0.014073\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.002081 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1400/1725 loss：0.005585\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.988227 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1401/1725 loss：0.002997\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.974960 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：60 step:1402/1725 loss：0.003877\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.965069 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1403/1725 loss：0.021272\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.935863 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1404/1725 loss：0.004637\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.912252 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1405/1725 loss：0.002745\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.892102 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1406/1725 loss：0.003325\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.876297 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1407/1725 loss：0.006559\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.862046 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1408/1725 loss：0.003331\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.846535 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1409/1725 loss：0.026219\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.838997 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1410/1725 loss：0.014471\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.832295 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1411/1725 loss：0.001287\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.826622 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1412/1725 loss：0.001779\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.821695 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1413/1725 loss：0.011213\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.823864 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1414/1725 loss：0.010003\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.832841 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1415/1725 loss：0.012631\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.834453 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1416/1725 loss：0.001771\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.836089 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1417/1725 loss：0.013440\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.834584 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1418/1725 loss：0.001824\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.834089 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1419/1725 loss：0.005208\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.833897 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1420/1725 loss：0.003027\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.834073 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1421/1725 loss：0.001376\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.835428 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1422/1725 loss：0.002509\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.837578 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1423/1725 loss：0.033582\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.824118 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1424/1725 loss：0.000948\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.811776 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：61 step:1425/1725 loss：0.165560\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.846257 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1426/1725 loss：0.010527\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.879834 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1427/1725 loss：0.008909\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.905956 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1428/1725 loss：0.007473\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.936110 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1429/1725 loss：0.035814\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.019936 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1430/1725 loss：0.003550\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.107932 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1431/1725 loss：0.011001\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.230337 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1432/1725 loss：0.017022\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.348644 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1433/1725 loss：0.015266\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.461468 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1434/1725 loss：0.004732\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.571121 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1435/1725 loss：0.007141\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.671499 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1436/1725 loss：0.000958\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.766465 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1437/1725 loss：0.002740\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.854734 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1438/1725 loss：0.004606\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.932444 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1439/1725 loss：0.036495\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.973855 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1440/1725 loss：0.006975\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.009933 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1441/1725 loss：0.039002\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.871705 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1442/1725 loss：0.002428\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.752314 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1443/1725 loss：0.001875\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.650958 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1444/1725 loss：0.006512\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.560944 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1445/1725 loss：0.004524\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.487608 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1446/1725 loss：0.004875\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.432099 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1447/1725 loss：0.003170\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.387184 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：62 step:1448/1725 loss：0.012378\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.350445 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1449/1725 loss：0.005724\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.307826 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1450/1725 loss：0.023426\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.314352 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1451/1725 loss：0.003857\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.321188 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1452/1725 loss：0.005123\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.327238 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1453/1725 loss：0.008847\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.328471 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1454/1725 loss：0.005230\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.329296 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1455/1725 loss：0.022471\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.366617 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1456/1725 loss：0.004386\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.411062 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1457/1725 loss：0.001912\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.453905 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1458/1725 loss：0.016366\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.480749 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1459/1725 loss：0.003614\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.498067 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1460/1725 loss：0.007996\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.510293 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1461/1725 loss：0.012952\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.533211 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1462/1725 loss：0.083574\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.384346 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1463/1725 loss：0.009970\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.267619 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1464/1725 loss：0.009644\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.163622 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1465/1725 loss：0.001080\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.079792 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1466/1725 loss：0.003078\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.013742 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1467/1725 loss：0.006665\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.959205 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1468/1725 loss：0.013733\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.905044 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1469/1725 loss：0.001841\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.860603 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1470/1725 loss：0.002429\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.823350 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：63 step:1471/1725 loss：0.009408\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.795579 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1472/1725 loss：0.006940\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.771193 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1473/1725 loss：0.020404\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.751451 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1474/1725 loss：0.003277\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.733792 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1475/1725 loss：0.025138\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.696424 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1476/1725 loss：0.003791\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.664353 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1477/1725 loss：0.003667\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.637862 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1478/1725 loss：0.007235\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.615757 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1479/1725 loss：0.005981\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.598331 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1480/1725 loss：0.008834\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.587637 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1481/1725 loss：0.016016\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.592367 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1482/1725 loss：0.007280\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.597309 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1483/1725 loss：0.001025\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.601827 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1484/1725 loss：0.008644\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.605483 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1485/1725 loss：0.002488\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.608323 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1486/1725 loss：0.006005\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.613128 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1487/1725 loss：0.005701\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.620338 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1488/1725 loss：0.011027\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.633111 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1489/1725 loss：0.005797\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.649417 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1490/1725 loss：0.002479\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.664917 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1491/1725 loss：0.004572\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.680820 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1492/1725 loss：0.001952\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.695541 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1493/1725 loss：0.001407\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.709194 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：64 step:1494/1725 loss：0.006056\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.726834 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1495/1725 loss：0.006928\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.744167 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1496/1725 loss：0.007689\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.764453 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1497/1725 loss：0.003301\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.783626 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1498/1725 loss：0.003560\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.800822 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1499/1725 loss：0.008413\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.816165 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1500/1725 loss：0.001828\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.829343 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1501/1725 loss：0.008014\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.840127 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1502/1725 loss：0.007867\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.849251 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1503/1725 loss：0.009347\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.855661 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1504/1725 loss：0.023660\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.869493 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1505/1725 loss：0.010866\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.906522 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1506/1725 loss：0.005316\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.941144 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1507/1725 loss：0.011850\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.986932 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1508/1725 loss：0.001646\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.031007 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1509/1725 loss：0.004916\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.074674 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1510/1725 loss：0.008316\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.114981 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1511/1725 loss：0.005654\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.157354 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1512/1725 loss：0.000542\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.197716 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1513/1725 loss：0.004050\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.241166 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1514/1725 loss：0.005492\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.281784 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1515/1725 loss：0.010661\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.347813 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1516/1725 loss：0.000888\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.411050 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：65 step:1517/1725 loss：0.005777\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.465714 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1518/1725 loss：0.004909\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.515134 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1519/1725 loss：0.005395\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.561355 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1520/1725 loss：0.025993\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.613012 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1521/1725 loss：0.002783\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.656871 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1522/1725 loss：0.016961\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.680890 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1523/1725 loss：0.005781\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.698879 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1524/1725 loss：0.005144\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.704999 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1525/1725 loss：0.005210\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.691642 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1526/1725 loss：0.008375\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.692727 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1527/1725 loss：0.006103\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.682299 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1528/1725 loss：0.003231\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.671589 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1529/1725 loss：0.003867\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.661868 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1530/1725 loss：0.017073\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.661433 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1531/1725 loss：0.033055\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.662925 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1532/1725 loss：0.003592\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.661117 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1533/1725 loss：0.005052\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.655734 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1534/1725 loss：0.007078\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.639042 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1535/1725 loss：0.015585\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.659008 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1536/1725 loss：0.019991\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.690322 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1537/1725 loss：0.002301\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.716292 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1538/1725 loss：0.005620\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.741529 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1539/1725 loss：0.005359\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.766857 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：66 step:1540/1725 loss：0.000395\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.789575 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1541/1725 loss：0.002740\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.807813 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1542/1725 loss：0.003122\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.827608 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1543/1725 loss：0.001994\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.840660 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1544/1725 loss：0.001812\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.852084 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1545/1725 loss：0.007866\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.853821 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1546/1725 loss：0.002663\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.856033 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1547/1725 loss：0.000863\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.859017 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1548/1725 loss：0.010418\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.858686 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1549/1725 loss：0.015550\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.872397 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1550/1725 loss：0.006489\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.883510 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1551/1725 loss：0.005447\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.888595 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1552/1725 loss：0.009621\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.898138 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1553/1725 loss：0.003012\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.904796 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1554/1725 loss：0.009452\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.916485 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1555/1725 loss：0.007718\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.931760 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1556/1725 loss：0.006185\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.926235 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1557/1725 loss：0.003125\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.919251 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1558/1725 loss：0.003150\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.911656 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1559/1725 loss：0.011167\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.908374 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1560/1725 loss：0.001887\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.905197 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1561/1725 loss：0.037815\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.863219 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1562/1725 loss：0.004437\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.827372 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：67 step:1563/1725 loss：0.008963\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.796984 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1564/1725 loss：0.004554\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.780519 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1565/1725 loss：0.008676\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.775874 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1566/1725 loss：0.009159\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.745901 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1567/1725 loss：0.032129\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.772559 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1568/1725 loss：0.006306\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.797759 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1569/1725 loss：0.013714\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.782250 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1570/1725 loss：0.020340\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.725022 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1571/1725 loss：0.026291\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.694158 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1572/1725 loss：0.010380\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.667896 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1573/1725 loss：0.016227\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.613095 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1574/1725 loss：0.008520\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.561865 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1575/1725 loss：0.010303\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.498399 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1576/1725 loss：0.002542\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.442484 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1577/1725 loss：0.005103\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.390125 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1578/1725 loss：0.001288\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.347189 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1579/1725 loss：0.004206\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.313701 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1580/1725 loss：0.071140\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.387627 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1581/1725 loss：0.014655\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.451354 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1582/1725 loss：0.016148\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.538244 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1583/1725 loss：0.012483\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.626948 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1584/1725 loss：0.002394\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.715072 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1585/1725 loss：0.005369\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.799013 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：68 step:1586/1725 loss：0.006129\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.873047 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1587/1725 loss：0.022263\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.964467 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1588/1725 loss：0.011871\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.041862 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1589/1725 loss：0.014630\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.104062 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1590/1725 loss：0.000997\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.160094 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1591/1725 loss：0.001787\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.212368 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1592/1725 loss：0.001807\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.254409 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1593/1725 loss：0.000869\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.293224 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1594/1725 loss：0.001676\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.331016 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1595/1725 loss：0.004387\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.367583 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1596/1725 loss：0.013696\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.276020 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1597/1725 loss：0.002487\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.191034 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1598/1725 loss：0.001909\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.113171 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1599/1725 loss：0.001538\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.048689 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1600/1725 loss：0.010009\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.998217 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1601/1725 loss：0.012852\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.964100 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1602/1725 loss：0.027374\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.876098 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1603/1725 loss：0.002779\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.799366 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1604/1725 loss：0.003875\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.725416 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1605/1725 loss：0.020480\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.650542 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1606/1725 loss：0.006657\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.585124 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1607/1725 loss：0.002692\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.528282 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1608/1725 loss：0.000962\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.479927 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：69 step:1609/1725 loss：0.002125\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.441579 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1610/1725 loss：0.001303\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.408419 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1611/1725 loss：0.012124\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.371366 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1612/1725 loss：0.004707\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.316895 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1613/1725 loss：0.001669\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.274108 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1614/1725 loss：0.013077\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.189176 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1615/1725 loss：0.007384\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.125552 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1616/1725 loss：0.003778\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.077826 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1617/1725 loss：0.008616\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.036950 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1618/1725 loss：0.012234\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.003478 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1619/1725 loss：0.005077\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.974702 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1620/1725 loss：0.008066\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.954322 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1621/1725 loss：0.006292\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.939323 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1622/1725 loss：0.004667\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.929177 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1623/1725 loss：0.016618\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.927246 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1624/1725 loss：0.004177\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.926722 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1625/1725 loss：0.003279\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.926061 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1626/1725 loss：0.000437\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.925504 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1627/1725 loss：0.002773\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.925412 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1628/1725 loss：0.002954\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.926303 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1629/1725 loss：0.005203\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.928287 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1630/1725 loss：0.007903\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.930552 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1631/1725 loss：0.003867\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.931856 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：70 step:1632/1725 loss：0.001684\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.933670 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1633/1725 loss：0.003469\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.935133 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1634/1725 loss：0.003144\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.936488 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1635/1725 loss：0.017684\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.943757 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1636/1725 loss：0.028527\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.957100 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1637/1725 loss：0.003753\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.970686 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1638/1725 loss：0.001426\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.983589 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1639/1725 loss：0.002078\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.994725 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1640/1725 loss：0.001575\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.005054 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1641/1725 loss：0.002163\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.014532 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1642/1725 loss：0.003709\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.021709 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1643/1725 loss：0.001598\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.028232 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1644/1725 loss：0.006218\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.040930 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1645/1725 loss：0.002451\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.053537 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1646/1725 loss：0.001193\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.066273 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1647/1725 loss：0.004131\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.082589 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1648/1725 loss：0.004214\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.096311 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1649/1725 loss：0.009792\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.115849 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1650/1725 loss：0.008834\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.144963 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1651/1725 loss：0.002996\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.173868 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1652/1725 loss：0.014588\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.185471 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1653/1725 loss：0.004541\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.194638 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1654/1725 loss：0.004609\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.202456 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：71 step:1655/1725 loss：0.009532\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.190769 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1656/1725 loss：0.003188\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.180748 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1657/1725 loss：0.011101\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.186771 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1658/1725 loss：0.001397\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.193730 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1659/1725 loss：0.002419\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.202903 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1660/1725 loss：0.006196\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.212456 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1661/1725 loss：0.001186\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.221772 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1662/1725 loss：0.002322\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.226819 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1663/1725 loss：0.003681\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.235505 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1664/1725 loss：0.005816\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.248377 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1665/1725 loss：0.004648\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.259049 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1666/1725 loss：0.009381\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.260806 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1667/1725 loss：0.006981\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.270543 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1668/1725 loss：0.003902\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.277792 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1669/1725 loss：0.004630\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.283780 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1670/1725 loss：0.004113\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.288145 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1671/1725 loss：0.001711\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.291309 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1672/1725 loss：0.041828\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.393900 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1673/1725 loss：0.002265\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.500313 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1674/1725 loss：0.001229\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.610663 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1675/1725 loss：0.004264\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.730003 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1676/1725 loss：0.001624\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.829999 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1677/1725 loss：0.002452\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.919127 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：72 step:1678/1725 loss：0.003167\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.002818 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1679/1725 loss：0.002644\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.080806 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1680/1725 loss：0.010187\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.138536 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1681/1725 loss：0.003535\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.193407 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1682/1725 loss：0.003100\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.240390 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1683/1725 loss：0.004088\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.281897 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1684/1725 loss：0.003911\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.324788 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1685/1725 loss：0.000934\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.362860 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1686/1725 loss：0.004432\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.390492 accuracy：0.3636 micro_f1：0.3636 macro_f1：0.4325\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1687/1725 loss：0.035261\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.947036 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1688/1725 loss：0.006329\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.613038 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1689/1725 loss：0.036672\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.319091 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1690/1725 loss：0.004852\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.128871 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1691/1725 loss：0.001097\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.008137 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1692/1725 loss：0.002602\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.931516 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1693/1725 loss：0.003538\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.885095 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "------------>Save best model\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1694/1725 loss：0.000900\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.856960 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1695/1725 loss：0.002223\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.840584 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1696/1725 loss：0.007275\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.829990 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1697/1725 loss：0.005317\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.823612 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1698/1725 loss：0.008764\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.820793 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1699/1725 loss：0.001154\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.820370 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1700/1725 loss：0.001382\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.822044 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：73 step:1701/1725 loss：0.004249\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.822407 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6114\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1702/1725 loss：0.005758\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.826777 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6114\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1703/1725 loss：0.002128\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.831216 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6114\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1704/1725 loss：0.071514\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.728386 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1705/1725 loss：0.003390\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.649046 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1706/1725 loss：0.002771\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.590844 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1707/1725 loss：0.006103\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.551674 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1708/1725 loss：0.002642\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.528061 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1709/1725 loss：0.002162\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.516272 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1710/1725 loss：0.048388\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.538923 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1711/1725 loss：0.002541\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.578627 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1712/1725 loss：0.009813\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.644511 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1713/1725 loss：0.001456\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.735384 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1714/1725 loss：0.003624\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：12.863620 accuracy：0.5455 micro_f1：0.5455 macro_f1：0.6278\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1715/1725 loss：0.003116\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.014011 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1716/1725 loss：0.005617\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.179515 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1717/1725 loss：0.005979\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.331995 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1718/1725 loss：0.014633\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.508648 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1719/1725 loss：0.002430\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.682960 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1720/1725 loss：0.002389\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.846020 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1721/1725 loss：0.002441\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：13.986821 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1722/1725 loss：0.013574\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.046444 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1723/1725 loss：0.007569\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.099108 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "torch.Size([2, 4, 768])\n",
      "【train】 epoch：74 step:1724/1725 loss：0.013490\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【dev】 loss：14.115695 accuracy：0.4545 micro_f1：0.4545 macro_f1：0.5444\n",
      "======== Calculate Testing========\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "【test】 loss：12.885095 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Cause_of_disease       0.50      0.75      0.60         4\n",
      "Treatment_of_disease       0.50      0.33      0.40         3\n",
      "            Negative       1.00      0.67      0.80         3\n",
      "         Association       1.00      1.00      1.00         1\n",
      "\n",
      "            accuracy                           0.64        11\n",
      "           macro avg       0.75      0.69      0.70        11\n",
      "        weighted avg       0.68      0.64      0.64        11\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! bash \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/run_demo.sh\""
   ],
   "metadata": {
    "id": "_jYrUj6-sZ30",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654539206577,
     "user_tz": -420,
     "elapsed": 65886,
     "user": {
      "displayName": "Dimas Dwi Putra",
      "userId": "07843601127335338044"
     }
    },
    "outputId": "14833fc7-4a76-4c5a-9b67-2da667622fe9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Cause_of_disease': 0, 'Treatment_of_disease': 1, 'Negative': 2, 'Association': 3}\n",
      "======== Prediction ========\n",
      "Halothane is known to oppose <e1start> digitalis <e1end>-induced <e2start> ventricular arrhythmias <e2end>. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "Both cases proved to be <e1start> cotton <e1end>-material-induced <e2start> granulomas <e2end>. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "The evidence for <e1start> soybean <e1end> products as <e2start> cancer <e2end> preventive agents.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Treatment_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "[Mortality trends in <e2start> cancer <e2end> attributable to <e1start> tobacco <e1end> in Mexico].  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "<e1start> Areca <e1end> nut chewing has a significant association with <e2start> systemic inflammation <e2end>.\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Association\n",
      "==========================\n",
      "<e2start> major depression <e2end> (MD) and regular <e1start> tobacco <e1end> use (RU) or nicotine dependence (ND).\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Association\n",
      "==========================\n",
      "Benefits of whole <e1start> ginger <e1end> extract in <e2start> prostate cancer <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Treatment_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "<e2start> schizophrenia <e2end> and <e1start> cannabis <e1end> is due to a shared genetic aetiology.\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Association\n",
      "==========================\n",
      "These risks may be even higher among <e1start> tobacco <e1end>-related <e2start> cancer <e2end> survivors (TRCS). \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "Role of Dau c 1 in three different patterns of <e1start> carrot <e1end>-induced <e2start> asthma <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Treatment_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "<e1start> Tobacco <e1end>-associated <e2start> cancers <e2end> included lung, esophageal, and H/N cancers. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Negative\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "<e1start> Coffee <e1end> consumption not associated with risk of <e2start> pancreas cancer <e2end> in Finland.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Negative\n",
      "==========================\n",
      "Optimal dose of <e1start> garlic <e1end> to inhibit dimethylhydrazine-induced <e2start> colon cancer <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "<e2start> major depression <e2end> (MD) and regular tobacco use (<e1start> RU <e1end>) or nicotine dependence (ND).\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Association\n",
      "==========================\n",
      "Chinese <e1start> green tea <e1end> ameliorates <e2start> lung injury <e2end> in cigarette smoke-exposed rats.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Treatment_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "Studies on magnesium's mechanism of action in <e1start> digitalis <e1end>-induced <e2start> arrhythmias <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Association\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "Caffeine and <e1start> coffee <e1end> as therapeutics against <e2start> Alzheimer's disease <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Treatment_of_disease\n",
      "true label：Treatment_of_disease\n",
      "==========================\n",
      "recent <e1start> coffee <e1end> drinking and the incidence of <e2start> cardiovascular disease <e2end>.\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Negative\n",
      "true label：Association\n",
      "==========================\n",
      "In nonexposed, tobacco-, or <e1start> marijuana <e1end>-smoke-exposed <e2start> breast cancer <e2end> cultures. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Treatment_of_disease\n",
      "true label：Negative\n",
      "==========================\n",
      "Aggressive <e1start> tobacco <e1end> control could avert millions of deaths from <e2start> tuberculosis <e2end>.  \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Treatment_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "She had <e2start> asthma <e2end> when handling raw <e1start> carrots <e1end>. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "<e1start> Tobacco <e1end>-associated cancers included lung, <e2start> esophageal, and H/N cancers <e2end>. \n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Cause_of_disease\n",
      "==========================\n",
      "major depression (<e2start> MD <e2end>) and regular <e1start> tobacco <e1end> use (RU) or nicotine dependence (ND).\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels：Cause_of_disease\n",
      "true label：Association\n",
      "==========================\n",
      "Halothane is known to oppose <e1start> digitalis <e1end>-induced <e2start> ventricular arrhythmias <e2end>.\n",
      "torch.Size([1, 4, 768])\n",
      "predict labels： ['Cause_of_disease']\n",
      "true label： Treatment_of_disease\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color/48/undefined/7-circle--v1.png\"/>**Summary**"
   ],
   "metadata": {
    "id": "Lkml6AWbmpQG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Train Output***"
   ],
   "metadata": {
    "id": "WW-YrpB5fejQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "url = 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/biobert-train.csv'\n",
    "\n",
    "biobert_train = pd.read_csv(url)\n",
    "\n",
    "print(biobert_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1IOejCyYK6P",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542294660,
     "user_tz": -420,
     "elapsed": 1602,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "5564d4f4-8d42-49ee-a5aa-96e1bcc935fa"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                     Time  Epoch  Step      Loss\n",
      "0     2022-06-06 18:01:59      0     0  2.566099\n",
      "1     2022-06-06 18:02:05      0     1  2.137553\n",
      "2     2022-06-06 18:02:05      0     2  1.132333\n",
      "3     2022-06-06 18:02:11      0     3  0.964150\n",
      "4     2022-06-06 18:02:11      0     4  1.834854\n",
      "...                   ...    ...   ...       ...\n",
      "1720  2022-06-06 18:12:14     74  1720  0.002389\n",
      "1721  2022-06-06 18:12:15     74  1721  0.002441\n",
      "1722  2022-06-06 18:12:15     74  1722  0.013574\n",
      "1723  2022-06-06 18:12:15     74  1723  0.007569\n",
      "1724  2022-06-06 18:12:16     74  1724  0.013490\n",
      "\n",
      "[1725 rows x 4 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "with open(url, 'r') as csvfile:\n",
    "    lines = csv.reader(csvfile, delimiter=',')\n",
    "    for row in lines:\n",
    "        x.append(int(row[2]))\n",
    "        y.append(float(row[3]))\n",
    "\n",
    "plt.plot(x, y, color='g', linestyle='dashed',\n",
    "         marker='o', label=\"Training Loss\")\n",
    "\n",
    "plt.xticks(rotation=25)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "3cbqip1Sebup",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542459040,
     "user_tz": -420,
     "elapsed": 1142,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "9b884bac-95f4-450c-fe53-ecb2cab38bff"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/biobert-train-chart.py\""
   ],
   "metadata": {
    "id": "qBakHLckaYX8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542509513,
     "user_tz": -420,
     "elapsed": 1746,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Dev Output***"
   ],
   "metadata": {
    "id": "zsGFfknyfm8u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dev_url = 'drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/biobert-dev.csv'\n",
    "\n",
    "biobert_dev = pd.read_csv(dev_url)\n",
    "\n",
    "print(biobert_dev)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8RrH_Y1i9mn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542309986,
     "user_tz": -420,
     "elapsed": 328,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "13cff211-7c82-4515-ba34-220a70a2d7ac"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                     Time       Loss  accuracy  micro_f1  macro_f1\n",
      "0     2022-06-06 18:01:59   8.110209    0.4545    0.4545    0.3250\n",
      "1     2022-06-06 18:02:05   8.117139    0.4545    0.4545    0.3250\n",
      "2     2022-06-06 18:02:05   8.161147    0.4545    0.4545    0.4262\n",
      "3     2022-06-06 18:02:11   8.228177    0.3636    0.3636    0.3625\n",
      "4     2022-06-06 18:02:11   8.259426    0.2727    0.2727    0.2556\n",
      "...                   ...        ...       ...       ...       ...\n",
      "1720  2022-06-06 18:12:14  13.846020    0.4545    0.4545    0.5444\n",
      "1721  2022-06-06 18:12:15  13.986821    0.4545    0.4545    0.5444\n",
      "1722  2022-06-06 18:12:15  14.046444    0.4545    0.4545    0.5444\n",
      "1723  2022-06-06 18:12:15  14.099108    0.4545    0.4545    0.5444\n",
      "1724  2022-06-06 18:12:16  14.115695    0.4545    0.4545    0.5444\n",
      "\n",
      "[1725 rows x 5 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dev_x = []\n",
    "dev_y = []\n",
    "\n",
    "with open(dev_url, 'r') as dev_csvfile:\n",
    "    dev_lines = csv.reader(dev_csvfile, delimiter=',')\n",
    "    for dev_row in dev_lines:\n",
    "        dev_x.append(float(dev_row[4]))\n",
    "        dev_y.append(float(dev_row[2]))\n",
    "\n",
    "plt.plot(dev_x, dev_y, color='g', linestyle='None',\n",
    "         marker='o', label=\"Dev Accuracy\")\n",
    "\n",
    "plt.xticks(rotation=25)\n",
    "plt.xlabel('F-1')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Development', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "ZHO-83IVjhic",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542514775,
     "user_tz": -420,
     "elapsed": 904,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "7abf61a9-0601-4e19-a468-6ce1cd13164a"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEhCAYAAABycqfJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU9Z3/8deHEEoiGhCFqphAd/GOiIB4q4XGC65FW60/aVMptpp6QdvtZWt/cQuo2e32suv+1LJNf6uUbTRStQoVb6RQe/l1C1grFVdRIRFtlSIGMVxC+Pz+OGfSYTKTTJKZzGTO+/l4zCM53/M93/P5zCTnM+cyZ8zdERGR6BqU6wBERCS3VAhERCJOhUBEJOJUCEREIk6FQEQk4lQIREQiToVAJIGZjTUzN7PFuY5FpD8MznUAUhjMLPEDKXuBHcDrwLPAQ8BT7t7e37FJdpnZZgB3H5vbSKS3VAgk0xaGP4uA4cCJwJXA54G1Zlbl7i/nKjgR6UyFQDLK3RcktpnZaOBO4HJgpZlNcfe3+zs2EUlO5wgk69z9LWA2sBo4GvjfiX3M7FAz+2cze9HMdplZi5k1mtn5Cf1uDo/ffzHZuszsSDPbZ2ZrE9oHm9n1ZvZbM9thZq1m9nszm2dmaf8fmNkRZna3mW02s71mttXMHjazyUn6zg1jnWtmF5nZb8zsfTPbbmYPmtn4JMssDpcZF8a2wcx2h+v732ZmYb/Lzex34Xhvm9ldZlaSIubjwnFfD2N+y8zuM7Nju1j/WDP7gpmtD9f/lpnVmVlZXN/p4SHBCqAiXC72WJzucyp5wN310KPPD8CDP6cu+1SG/d4CLK69AtgUznsG+DegDngT2A9cE9f3KKAdWJdiHf8QjjMvrq0YeCJs/x/gP4A7gD+Ebf+VMMbYsH1xQvs44I1wXiPwz8CPgT3h42MJ/eeGfZcBbcBS4J+AFWH7NuDYhGUWh/MeCucvDmN9LWxfANwEtAL3Ad8Dng/nLUryfMwM+7YBDwPfDpfbDbQAp6ZY/9Jw/o/DdTwbtv884XlaALwbPhbEPT6e679JPdJ/5DwAPQrjkWYh+EC4QXJgXFz76nCDPzuh/3DgOWAXMDqu/clwjJOSrOOFcKM8Mq5tQdj/TqAorr0I+M9w3iVx7akKQWy9NQntZwL7wg33sLj2WCHwJEXii2F7Y0J7bEO8GTgq4bn4C/A+sBU4PuF53RDmPSqufQSwPVzuhIT1nATsBJ5Nsf5moDyufTBBkXbgtIRlNgObc/03qEfvHzo0JP3G3fcQbCwBDgcws4nAR4CH3L0hof+7wHxgKHBZ3KwfhT8/G9/fzKYAJwCPufu2sG0QcCPwZ+DvPe6qpfD3rxBs3Kq6it3MxgDnE2wgv50Q52+A+4FDgUuTLP5zd/9ZQttdwKvAR82sIskyt7n7G3HreJdgz6KU4J3/i3Hz9gAPAEOA4+PGmENQQOa7+4aEmP8I/BCYZGYnJFn/re7eHNd/H3BvOHlakv4ygOlksfQ3C3/GLjc9I/xZZmYLkvQ/PPwZv4H7KcFhiyozuzlu4x4rDIvj+h5DsIHeCNwSHmJPtCth/GQmhT9/6e5tSeb/HPhM2G9JwrxfJHZ293Yz+xXwN+EyTQld1iYuQ3CoDGBdknmxojEmri323E5M8dweE/48nmCPorv1vx7+HJFkngxgKgTSb8xsKMFGGYLDGwAjw5/nhY9UhsV+cfddZrYUuIbgXfrjZjYE+FQ47uNxy8XGH0+wd9Ht+CnETpL+KcX8WPvwJPPeSrHMnxPGjteSpG1fGvOK49piuV+TYv0xyXJ/t4t1FHUzngwwOjQk/elsgjcfb7n75rAttlH7ortbF4+rEsZKPDx0EcGG776Ed+yx8X/azfjjuok9Ns4HU8w/IqFfvNEplomNlWyZTIiNO7Gb3H/U5ShS8FQIpF+Ex+prwsn74mb9Nvz54Z6M5+6/Jjjcc0l4SWOsICRu1P6H4N3t6WZWTO/9Pvx5tpkl25OeEf58Nsm8jyQ2mFkRQWGMHzvTevXc9kI72ksY0FQIJOvMbBTQAEwnONn6T7F57r4W+CVwqZl9LsXyE8IxEv2I4ETy9cDfAc+7+wEb1fAk550E79j/T7Jr7cPPBiQ7YRo/zhbgaYIrir6UsPw04NMEV+j8NMniHzWzjyW0zSM4P7DK3RPPD2TKvQRFcL6ZdTrBa2aDzGx6BtazDTg81ecYJP/pHIFkVNxJyUH89RYTZxNc0fI7oMrd/5Kw2KcJTrb+p5ndBPw3wQZsDHAywaWOZwCJn0b+L+BWgttaFNN5byDmNmAicC0wy8x+TnBydRTBuYOzCPZWEk+YJroW+DXwnfCDbmsJPiB3OcHlr1e5+3tJllsO/NTMfgq8ApwCXAi8Q1DEssLdt5nZJwmK02/NrJHg8loP4z6D4HDa0D6uqhGYCjxhZs8QXMb6B3df3sdxpZ+oEEimxU7I7gXeI7gaZgl/venc/sQF3H1L+MncGwkuE60iONTwZ4KN853A+iTLNZvZKoIPqu0D6pMF5O5tZvZxgqt65gIfIzhBupXgg2z/mGrZhHFeCy9RvYVgD2Q6wY31ngBq3X1NikUfJviAXA3BuYzYh7u+4Vm+75K7N5rZycBXgQsIDhPtJbgC6ecEr0tf3U5Q9GcRFNUigqKsQjBAmHviTSNFJBPMbC7B4Zmr3H1xbqMRSU3nCEREIk6FQEQk4lQIREQiTucIREQiTnsEIiIRN+AuHz3ssMN87NixvVr2/fff56CDDspsQDmiXPJPoeQByiVf9SWXdevW/cXdD082b8AVgrFjx7J2bbIbI3Zv9erVTJ8+PbMB5YhyyT+Fkgcol3zVl1zMLOUn2HVoSEQk4lQIREQiToVARCTiBtw5gmTa2trYsmULu3fv7rJfWVkZL774Ypd9BoqBlMvQoUMZM2YMxcV9uQu0iGRLQRSCLVu2cPDBBzN27FhSfBUhAO+99x4HH3xwP0aWPQMlF3dn27ZtbNmyhXHjuvvuFxFJxhbGbdfCLz71+Zn7DFhBHBravXs3I0eO7LIISG6YGSNHjux2b01EkjugCKTR3hsFUQgAFYE8ptdGJL8VTCHItaKiIk455RROPPFEJk6cyPe+9z327+906/1eu+OOOxg6dCgtLdn6elsRiapIFoL69fWMvWMsgxYOYuwdY6lf3+13knSrpKSE5557jhdeeIGnn36axx9/nIULF2Yg2sD999/P1KlTefjhhzM2ZiJ3z2jxEpGBIXKFoH59PdXLq2lqacJxmlqaqF5enZFiEDNq1Cjq6uq46667cHfa29v52te+xtSpUzn55JP5wQ9+AMDs2bN57LHHOpabO3cuDz74YKfxXn31VXbu3Mntt9/O/fff39G+c+dOrrrqKiZMmMDJJ5/MQw8FXzb1xBNPcOqppzJx4kQqKysBWLBgAd/97nc7lj3ppJPYvHkzmzdv5thjj2XOnDmcdNJJvP7661x33XVMmTKFE088kfnz53css2bNGs4880wmTpzIaaedxnvvvcc555zDc88919Hn7LPP5g9/+EOGnkkR6Q8FcdVQT9Q01tDa1npAW2tbKzWNNVRNqMrYej70oQ/R3t7O22+/zaOPPkpZWRlr1qxhz549nHXWWZx//vlcccUVLF26lIsuuoi9e/fS2NjIokWLOo3V0NDA7Nmz+fCHP8xLL73EW2+9RWlpKbfddhtlZWWsXx98i+P27dvZunUr11xzDc888wzjxo3jnXfe6TbWjRs38qMf/YjTTz8dgNraWg499FDa29uprKzk+eef57jjjuOKK67ggQceYOrUqezYsYOSkhI+//nPs3jxYu644w5efvlldu/ezcSJEzP2PIpEnc/3pCeGddVQHzS3NPeoPROeeuoplixZwimnnMK0adPYtm0bGzdu5MILL2TVqlXs2bOHxx9/nHPOOYeSkpJOy99///3Mnj2bQYMGcdlll/GTn/wEgJUrV3LDDTd09BsxYgS//e1vOeecczou1Tz00EO7ja+ioqKjCAAsXbqUU089lUmTJvHCCy+wYcMGXnrpJY444gimTp0KwCGHHMLgwYO5/PLL+dnPfkZbWxv33HMPc+fO7ctTJSJJ+HzH5zurPrKq4/dMitweQXlZOU0tne+9VF5WntH1vPbaaxQVFTFq1CjcnTvvvJMLLrigU7/p06fz5JNP8sADDzB79uxO89evX8/GjRs577zzANi7dy/jxo3js5/9bI/iGTx48AHH/+Mv54y/m+GmTZv47ne/y5o1axgxYgRz587t8tLP0tJSzjvvPB599FGWLl3KunXrehSXiORe5PYIaitrKS0uPaCttLiU2srajK1j69atXHvttcybNw8z44ILLmDRokW0tbUB8PLLL/P+++8DcMUVV3Dvvffyy1/+kpkzZ3Ya6/7772fBggUdx/PffPNN3nzzTZqbmznvvPO4++67O/pu376d008/nWeeeYZNmzYBdBwaGjt2LM8++ywAzz77bMf8RDt27OCggw6irKyMt956i8cffxyAY489lj/96U+sWbMGCD7Qtm/fPgCuvvpqbrrpJqZOncqIESP6/PyJSP+K3B5B7DxATWMNzS3NlJeVU1tZ2+fzA7t27eKUU06hra2NwYMHc+WVV/LlL38ZCDaUmzdv5tRTT8XdOfzww3nkkUcAOP/887nyyiu55JJLGDJkSKdxGxoaWLFixQFtn/jEJ3jooYe45ZZbuOGGGzjppJMoKipi/vz5XHrppdTV1XHppZeyf/9+Ro0axdNPP81ll13GkiVLOPHEE5k2bRrHHHNM0jwmTpzIpEmTOO644zj66KM566yzABgyZAgPPPAAN954I7t27aKkpISVK1cybNgwJk+ezCGHHMJVV13Vp+dQRHLE3QfUY/LkyZ5ow4YNndqS2bFjR1r9BoJ8yuWNN97w8ePHe3t7e8o+Xb1Gq1atykJU/a9Q8nBXLvmqL7kAaz3FdjVyh4Yks5YsWcK0adOora1l0CD9OYkMRJE7NCSZNWfOHObMmZPrMESkD/QWTkQk4gqmEASHwCQf6bURyW9ZLQRmNtPMXjKzV8zs5hR9/peZbTCzF8zsvt6sZ+jQoWzbtk0bnDzk4fcRDB06NNehiEgKWTtHYGZFwN3AecAWYI2ZLXP3DXF9xgPfAM5y9+1mNqo36xozZgxbtmxh69atXfbbvXt3wWyQBlIusW8oE5H8lM2TxacBr7j7awBm1gBcAmyI63MNcLe7bwdw97d7s6Li4uK0vv1q9erVTJo0qTeryDuFlIuI5JZl63CKmX0SmOnuV4fTVwLT3H1eXJ9HgJeBs4AiYIG7P5FkrGqgGmD06NGTGxoaehXTzp07GTZsWK+WzTfKJf8USh6gXPJVX3KZMWPGOnefkmxeri8fHQyMB6YDY4BnzGyCu78b38nd64A6gClTpvj06dN7tbLVq1fT22XzjXLJP4WSByiXfJWtXLJ5svgN4Oi46TFhW7wtwDJ3b3P3TQR7B+OzGJOIiCTIZiFYA4w3s3FmNgSYDSxL6PMIwd4AZnYYcAzwWhZjEhGRBFkrBO6+D5gHPAm8CCx19xfM7FYzuzjs9iSwzcw2AKuAr7n7tmzFJCIinWX1HIG7rwBWJLR9M+53B74cPkREJAcK5pPFIiLSOyoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRp0IgIhJxuf7OYpE+GfGtEby7569fcT38A8PZfvP2HEYUHfXr66lprKG5pZnysnJqK2upmlCV67BSSvxbiakcV8nKOSs7pm2hderj8z2rseWa9ghkwEr2j/3unncZ8a0ROYooOurX11O9vJqmliYcp6mlierl1dSvr891aEmlKgIAjZsaOXfJuUDyItBVe6FQIZABK9U/dqp2yZyaxhpa21oPaGtta6WmsSZHEXWtu7+Jxk2N/RRJflIhEJEea25p7lG75DcVAhHpsfKy8h61S35TIZABa/gHhveoXTKntrKW0uLSA9pKi0uprazNUURd6+5vonJcZT9Fkp9UCGTA2n7z9k7/4LpqqH9UTaiiblYdFWUVGEZFWQV1s+ry9qqhZH8rMfFXDaW6OqjQrxrS5aMyoGmjnztVE6rydsOfTLp/K4W+0U9GewQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRl9VCYGYzzewlM3vFzG5OMn+umW01s+fCx9XZjEdERDrL2k3nzKwIuBs4D9gCrDGzZe6+IaHrA+4+L1txiIhI17K5R3Aa8Iq7v+bue4EG4JIsrk9ERHohm4XgKOD1uOktYVuiy8zseTN70MyOzmI8IiKShLln597bZvZJYKa7Xx1OXwlMiz8MZGYjgZ3uvsfMvgBc4e4fTTJWNVANMHr06MkNDQ29imnnzp0MGzasV8vmG+WSfwolD1Au+aovucyYMWOdu09JOtPds/IAzgCejJv+BvCNLvoXAS3djTt58mTvrVWrVvV62XyjXPJPoeThrlzyVV9yAdZ6iu1qNg8NrQHGm9k4MxsCzAaWxXcwsyPiJi8GXsxiPCIikkTWrhpy931mNg94kuDd/j3u/oKZ3UpQmZYBN5nZxcA+4B1gbrbiERGR5LL6ncXuvgJYkdD2zbjfv0FwyEhERHJEnywWEYk4FQIRkYhTIRARiTgVAhGRiFMhEBGJOBUCEZGIUyEQEYk4FQIRkYhTIRARiTgVAhGRiFMhEBGJOBUCEZGIy+pN52RgO3fJuTRuauyYrhxXyco5KwEovb2UXe27uh2j2Io58pAjaW5p5tCSQwF4Z9c7lJeVU1tZy2ce/kzQ8Rd/XcbnJ/+ypOsfu566dXW0eztFVkT15GrOKj+LmsYamluaO8asmlDVozxtoXVqqyir6NOYMfXr61PG19W8vqhfX//X5zXBIAbRPr+9z+vojWTPc6rXWvqXCoEklVgEABo3NXLuknP5TfNv0ioCAG3eRlNLEwDbdm3raG9qaUq5sbKF1mkDcf1j17No7aKO6XZvZ9HaRfzw2R+yb/++jjGrl1cDpL1BTbZxio3V2zFj6tfXU728mta21k5jASnn9aUYdFUEAPazn6KFRf1eDFI9z8lea+l/3R4aMrNZZqZDSBGTWATi29MtAplUt64uaXusCMS0trVS01iT0XX3dsyaxpqODX3iWF3N64t0lt/P/j6tQwpPOhv4K4CNZvZtMzsu2wGJJNPu6b+DbW5pzvj6ezNmqmWaW5q7nNcX2chdCl+3hcDdPwNMAl4FFpvZ/zOzajM7OOvRiYSKrCjtvuVl5Rlff2/GTLVMeVl5l/P6Ihu5S+FL65CPu+8AHgQagCOATwDPmtmNWYxNcqhyXGXK9pKikn6OBqonVydtHzzowNNcpcWl1FbWZnTdvR2ztrKW0uLSpGN1Na8v0ll+kC4WlATpnCO42Mx+CqwGioHT3P1CYCLwleyGJ7mycs7KTsUgdtVQ6y2taReDYiumoqwCwxhZMpKRJSMxjIqyCn586Y+TLpPs5OH3L/o+1025rmPPoMiKuG7KdSz++OKO8SvKKqibVdejk62pTlT2ZcyYqglV1M2qSzpWV/P6ompCVcrnFXJ31VCq51knivOEu3f5AH4EnJNiXmV3y2f6MXnyZO+tVatW9XrZfKNc8k+h5OGuXPJVX3IB1nqK7Wo6l48uAP4UmzCzEmC0u2929+SXloiIyICRzsHCn8AB15u1h20iIlIA0ikEg919b2wi/H1I9kISEZH+lE4h2GpmF8cmzOwS4C/ZC0lERPpTOucIrgXqzewuwIDXgTlZjUpERPpNt4XA3V8FTjezYeH0zqxHJSIi/Satm86Z2UXAicBQs+DmUe5+axbjEhGRfpLOB8r+g+B+QzcSHBq6HKjIclwiItJP0jlZfKa7zwG2u/tC4AzgmOyGJSIi/SWdQrA7/NlqZkcCbQT3GxIRkQKQzjmC5WY2HPgO8CzgwA+zGpWIiPSbLgtB+IU0je7+LvCQmf0MGOruLf0SnYiIZF2Xh4bcfT9wd9z0HhUBEZHCks45gkYzu8xi142KiEhBSacQfIHgJnN7zGyHmb1nZjuyHJeIiPSTdL6q8mB3H+TuQ9z9kHD6kHQGN7OZZvaSmb1iZjd30e8yM3Mzm9KT4EVEpO+6vWrIzM5J1u7uz3SzXBHB+YXzgC3AGjNb5u4bEvodDHwR+O90gxYRkcxJ5/LRr8X9PhQ4DVgHfLSb5U4DXnH31wDMrAG4BNiQ0O824F8S1iMiIv3Egm8w68ECZkcDd7j7Zd30+yQw092vDqevBKa5+7y4PqcCNe5+mZmtBr7q7muTjFUNVAOMHj16ckNDQ49ijtm5cyfDhg3r1bL5Rrnkn0LJA5RLvupLLjNmzFjn7kkPv6d107kEW4DjexVJnPAzCv8KzO2ur7vXAXUAU6ZM8enTp/dqnatXr6a3y+Yb5ZJ/CiUPUC75Klu5pHOO4E6CTxNDcHL5FIJPGHfnDeDouOkxYVvMwcBJwOrwytQPAsvM7OJkewUiIpId6ewRxG+U9wH3u/uv01huDTDezMYRFIDZwKdjM8MPph0Wm+7q0JCIiGRPOoXgQWC3u7dDcDWQmZW6e2tXC7n7PjObBzwJFAH3uPsLZnYrsNbdl/U1eBER6bt0CkEjcC4Q+2ayEuAp4MzuFnT3FcCKhLZvpug7PY1YREQkw9L5ZPHQ+K+nDH8vzV5IIiLSn9IpBO+Hl3kCYGaTgV3ZC0lERPpTOoeGvgT8xMzeJPiqyg8SfHWliIgUgG4LgbuvMbPjgGPDppfcvS27YYmISH9J58vrbwAOcvc/uvsfgWFmdn32QxMRkf6QzjmCa8JvKAPA3bcD12QvJBER6U/pFIKi+C+lCe8qOiR7IYmISH9K52TxE8ADZvaDcPoLwOPZCyk/2cL0vqDN5/fsJn59lW5cMRVlFTS1NPV4PUVWRPXkar5/0fcBOHfJuTRuauyYXzmukpVzVnYZV389N/Xr66lprKG5pZnysnJqK2upmlDVqc8XH/8i23ZtA2BkyUj+/cJ/79Svv+Ty+RJJZ4/g68DPgWvDx3qCD5VFRk82tj3dMPdFb9bVmyIA0O7tLFq7iOsfu75TEQBo3NTIuUvO7TKu/nhu6tfXU728mqaWJhynqaWJ6uXV1K+vP6DPVY9c1VEEALbt2sbnHv3cAf36Sy6fLxFI7xvK9hN8acxmgu8Y+CjwYnbDknxVt66uUxGISdXen2oaa2htO/DuJ61trdQ01hzQp21/5wvf9rbvPaCfSFSkPDRkZscAnwoffwEeAHD3Gf0TmuSj9uCWU3mruaW52/ZUfbqbJ1Koutoj+B+Cd/8fc/ez3f1OIL+3ApJ1RVaU6xC6VF5W3m17qj7dzRMpVF0VgkuBPwGrzOyHZlZJ8MliibDqydVUjqtMOi9Ve3+qrayltPjAW2GVFpdSW1l7QJ/iQcWdlh1SNOSAfiJRkbIQuPsj7j4bOA5YRXCriVFmtsjMzu+vAPNBT67e6M8rPXqzroqyil6tq8iKuG7KdXz/ou+zcs7KThv9+KuGUsXVH89N1YQq6mbVUVFWgWFUlFVQN6vugKuBqiZUce/H72VkyciOtpElI7nnkntyctVQLp8vEUjvFhPvA/cB95nZCOBygiuJnspybHklX/8pcxVX/KWiyeTy+aqaUNXtBj2dPv0pX/++JBrSuXy0g7tvd/c6d8/9MQAREcmIHhUCEREpPCoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEZfVQmBmM83sJTN7xcxuTjL/WjNbb2bPmdmvzOyEbMYjIiKdZa0QmFkRcDdwIXAC8KkkG/r73H2Cu58CfBv412zFIyIiyWVzj+A04BV3f83d9wINwCXxHdx9R9zkQYBnMR4REUlicBbHPgp4PW56CzAtsZOZ3QB8GRgCfDSL8YiISBLmnp034Wb2SWCmu18dTl8JTHP3eSn6fxq4wN0/m2ReNVANMHr06MkNDQ29imnnzp0MGzasV8vmG+WSfwolD1Au+aovucyYMWOdu09JOtPds/IAzgCejJv+BvCNLvoPAlq6G3fy5MneW6tWrer1svlGueSfQsnDXbnkq77kAqz1FNvVbJ4jWAOMN7NxZjYEmA0si+9gZuPjJi8CNmYxHhERSSJr5wjcfZ+ZzQOeBIqAe9z9BTO7laAyLQPmmdm5QBuwHeh0WEhERLIrmyeLcfcVwIqEtm/G/f7FbK5fRES6p08Wi4hEnAqBiEjEqRCIiEScCoGISMRl9WTxQGELLa1+Pt+T9vX5nnIcn+8c9b2jeHPnm92Of+SwI7vsN4hBtM9vTyvWZOrX11PTWENzSzPlZeX83fi/Y8XGFR3TtZW1VE2oOmCZEd8awbt73u2YHv6B4Wy/eXuvYxCR/BP5QpBuEeiqb1dj9GT87orFfvZTtLCoV8Wgfn091curaW1rBaCppYlFaxd1zG9qaaJ6eTVARzFILAIA7+55lxHfGqFiIFJAdGhogNnP/l4tV9NY01EEUmlta6WmsaZjOrEIdNcuIgOTCkFENLc0Z7SfiBQOFYKIKC8rz2g/ESkcKgQDzKBevmS1lbWUFpd22ae0uJTaytqO6eEfGJ60X6p2ERmYIl8IYlf89KWvz/cu5x057Mi0xu+uX1+uGqqaUEXdrDoqyiowjIqyCq6bct0B03Wz6g64amj7zds7bfR11ZBI4Yn8VUOQmWLQ1bw3vvJGj2PKhqoJVZ0uD+2ONvoihS/yewQiIlGnQiAiEnEqBCIiEadCICIScSoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRp0IgIhJxKgQiIhGnQiAiEnEqBCIiEadCICIScSoEIiIRl9VCYGYzzewlM3vFzG5OMqcUOrYAAAmPSURBVP/LZrbBzJ43s0Yzq8hmPCIi0lnWCoGZFQF3AxcCJwCfMrMTErr9Hpji7icDDwLfzlY8IiKSXDb3CE4DXnH319x9L9AAXBLfwd1XuXtrOPlbYEwW4xERkSTM3bMzsNkngZnufnU4fSUwzd3npeh/F/Bnd789ybxqoBpg9OjRkxsaGnoV086dOxk2bFivls03yiX/FEoeoFzyVV9ymTFjxjp3n5Js3uA+RZUhZvYZYArwkWTz3b0OqAOYMmWKT58+vVfrWb16Nb1dNt8ol/xTKHmAcslX2colm4XgDeDouOkxYdsBzOxcoAb4iLvvyWI8IiKSRDbPEawBxpvZODMbAswGlsV3MLNJwA+Ai9397SzGIiIiKWStELj7PmAe8CTwIrDU3V8ws1vN7OKw23eAYcBPzOw5M1uWYjgREcmSrJ4jcPcVwIqEtm/G/X5uNtcfYwvtrxO/CNc93w9sj/XFKC8r580db9LmbR3tJUUltN7S2ql/b9Wvr6emsYbmlmbKy8qpraylakJVxsYXEUlXwX+yONnGvqt2x2lqaTqgCADsat9F6e2lGYmpfn091curaWpp6lhf9fJq6tfXZ2R8EZGeKPhCkEm72ndlZJyaxhpa2w7cu2hta6WmsSYj44uI9IQKQQ40tzT3qF1EJJtUCHKgvKy8R+0iItmkQtADJUUlGRmntrKW0uIDzzeUFpdSW1mbkfFFRHqi4AuBz09+C41U7YZRUVZBsRUf0J7Jq4aqJlRRN6uOirKKjvXVzarTVUMikhN5cYuJbItt9BM/np2qGPSHqglV2vCLSF4o+D0CERHpmgqBiEjEqRCIiEScCoGISMSpEIiIRFzWvqEsW8xsK9DUy8UPA/6SwXBySbnkn0LJA5RLvupLLhXufniyGQOuEPSFma1N9VVtA41yyT+Fkgcol3yVrVx0aEhEJOJUCEREIi5qhaAu1wFkkHLJP4WSByiXfJWVXCJ1jkBERDqL2h6BiIgkUCEQEYk4FQIRiRwzS/6l5QNMpvKIXCGwwIcK4Q8hzOVyMzvKzIpyHU9fhLl8xszGm9mQWFuu4+oNM/uSmX0413H0VfiaXG9m15nZB3IdT1+Eucwzs3ozG+kD9ORomMcXzKzZzP42U3lEphCET+DngDbgn4EB+72QZjbYzL4CPA9cA9wO3BzOG1CvaVwuzwGzga8Ct8Vm5yywXjKzMQSvx+VmNjzX8fSGmQ0ysy8BG4AzgV+6+54ch9VrZjYMeBCYAfxfoCW3EfWcmX3AzL4OrAMuAF4GTsnU+ANqo9FHw4C9wJeAd4ATcxtOn3wI+CBwibufT/DHfb6ZDXf3/bkNrceOBtqBS939Y8BDwDgzKx6AuQCUAr8H/hY4doDu1XyQYCPzlLt/xt3/mOuA+uhY4GB3v8zdVxH8vQ00E4ESgv+TS4HXyeBtMwq2EJjZ4PCnAbj7e8AKd78LeBuYZmZH5jDEtMXlMgjA3V8Gfujur4VdWoHXGADfOJckl03ufoe7vxq+Hl8n2JCWxffLN4l/X3GmAbUEOVw2EA5BJPlfeRP4GbDHzCrN7Jtm9mkzOz7sl5evCaR8XQYDz5vZsWb2H8DtZvbxnASYpiT/J79z9wXuvjnsMho4Pb5PX+TtC9pbZvYRM3sIqDWzsfH/iO7+TvjrIwTvqo/PRYzpSpJLxzvksBjEHAb8jbvn7Y21usolnH8EQRF4leAd2zIzK823vYJUf19x52gOBsYDC4BJ4fmCvLzPTVf/K8B6gr21/yLYyzkBeNTMDsq31wS6zeVI4FBgHsENK38N3GFmZ+Qg1C6l+j+JFbZYgQAeAw4HyMTrUVCFwMxGA/9I8G5mP3CrmVWG8zreIbj774E/A6fHnwTLp934dHKJi/c84OGE5QdULu7+J+Dv3b3a3b9NcBz36/F9cq2rPMJpCPZkfgVcApwMzAeG9HOo3eomF4CNwL8Bx7r7ze5+C/AS8JVw+bx4TSCtXJ4keLN0PPCv7r4CaACqwuXzIpc08sDd94W/HkFwiDsj8RdUIQAmAcXufi9wK0Hl/4SZHeruHp4wjuW8hODJ/LiZ3QaQZ7vx3eYS/iwCRgBLzazczG6CgZcLdHpn8xugOWzPl1y6zCPsM57ghN5ngYXAWoK9nHyTMhfoeC3WhodUY9YR3gI+j14T6D6XVoKjAJuB2N7ZWsKLEfIol55sv14GZmZqxYVWCJ4nOK451t13Ab8D9hH3hMVtbPYBnyJ413OYBWfl8+KdQai7XGKxHkWQx3cI9goOM7PiAZYLAGY23MwmmNkPgFnAM/0fapfSyeMfgZPdfZa7fx/YQnCyMt90mUv4RmO/mQ0xs5PMrA64iGDjlG/SeV1+QrCndpOZ/Rj4F2Bpv0fatZ5sv14K+47ORCErtELQCvyBvz5xrxDs4pZDUPnNrMjMhgLXA4uAse5+nbvvyaN3BtB9LrE/iI8QbGx+A5zp7t9097YBlkss1rOAOwhOfJ/t7hv7Oc7udJlH6C13/6OFn4UAPufu+VbQIP3X5GzguwSvyVnu/ko/x5mOdF6Xne6+GLgTeBw4wd1/0Z9BpiGd7VfsHMFQgtfl7UysuNAKQQvwLMGx/8PD3dpDgEPNrMzMvgYc7+673f1Gd7/F3ffmNOLUusvl62b2IeAhdz/O3e8ewLn8g5mNJ7hcsdLd/yVPc+kqj0PM7KuEFyDE4s+zghwvndfkGOAZd5/p7t/K09cEus/lqwTna3D3X7l7vefn5yLSyeMEAHf/hbs/kam/r4IqBOGT8hRBZV0QNpcC77p7C7DSB8g10Wnk8pS7vxYe/8xraeTytLtvdPe2HIWYlm7y2AE0uvv6HIXXI2m+Ji/HnZzMW2nk0ujuf8hReGlLM4/ns7HugrwNtZmNIjjEcDzwHvD5PDzMkBblkn8KJQ9QLvkoF3kUZCEAMLNi4HAPPhwzoCmX/FMoeYByyUf9nUfBFgIREUlPQZ0jEBGRnlMhEBGJOBUCEZGIUyEQEYk4FQKRHjKzdjN7Lu4xNkmfy83sBTPbb3l691GRmLy/f71IHtrl7t19O9QfgUuBH/RDPCJ9okIgkgXu/iJAft37TyQ5FQKRnisxs+fC3ze5+ydyGo1IH6kQiPRcOoeGRAYMnSwWyQAzuzc8cbwi17GI9JT2CEQywN2vynUMIr2lPQKRLDCzT5jZFuAM4DEzezLXMYmkopvOiYhEnPYIREQiToVARCTiVAhERCJOhUBEJOJUCEREIk6FQEQk4lQIREQiToVARCTi/j89cYjIdpDReAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! python \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/visualization/biobert-dev-chart.py\""
   ],
   "metadata": {
    "id": "DqvTUDNxaiBh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542534393,
     "user_tz": -420,
     "elapsed": 1610,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Training, Validation, Test***"
   ],
   "metadata": {
    "id": "WkqNCgLBWx8-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "2022-06-06 18:12:00,009 - INFO - main.py - train - 86 - 【train】 epoch：73 step:1693/1725 loss：0.003538\n",
    "2022-06-06 18:12:00,267 - INFO - main.py - train - 92 - 【dev】 loss：12.885095 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
    "2022-06-06 18:12:00,268 - INFO - main.py - train - 94 - ------------>Save best model\n",
    "...\n",
    "2022-06-06 18:12:16,443 - INFO - main.py - <module> - 247 - ======== Calculate Testing========\n",
    "2022-06-06 18:12:18,922 - INFO - main.py - <module> - 251 - 【test】 loss：12.885095 accuracy：0.6364 micro_f1：0.6364 macro_f1：0.7000\n",
    "```"
   ],
   "metadata": {
    "id": "S6A6oZJRORfn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "                        precision    recall  per-class   support\n",
    "                                             f1-scores\n",
    "\n",
    "    Cause_of_disease       0.50       0.75      0.60         4\n",
    "Treatment_of_disease       0.50       0.33      0.40         3\n",
    "            Negative       1.00       0.67      0.80         3\n",
    "         Association       1.00       1.00      1.00         1\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://img.icons8.com/external-royyan-wijaya-detailed-outline-royyan-wijaya/24/undefined/external-arrow-arrow-line-royyan-wijaya-detailed-outline-royyan-wijaya-8.png\"/>\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "```\n",
    "                          precision    recall    Average     support\n",
    "                                                f1-scores\n",
    "\n",
    "            accuracy                              0.64         11\n",
    "           macro avg         0.75       0.69      0.70         11\n",
    "        weighted avg         0.68       0.64      0.64         11\n",
    "```"
   ],
   "metadata": {
    "id": "MJFJB4USMOjU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Model Output**"
   ],
   "metadata": {
    "id": "cNYFmRkrqzOk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! ls -lh \"/content/drive/MyDrive/Colab Notebooks/bert_relation_extraction/output/checkpoint\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSCC79Znq4K3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654542892164,
     "user_tz": -420,
     "elapsed": 379,
     "user": {
      "displayName": "research dimas",
      "userId": "15515874475659534288"
     }
    },
    "outputId": "4aa14667-caaa-4901-f52a-2ea7d6246bb0"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total 2.5G\n",
      "-rw------- 1 root root 1.3G Jun  6 18:14 best-Biobert.pt\n",
      "-rw------- 1 root root 1.3G Jun  6 17:51 best-BiomedNLP-PubMedBERT.pt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <img src=\"https://img.icons8.com/color-glass/48/undefined/code.png\"/> **Source Code on** [**Gitlab**](https://gitlab.com/research.dimas/nlp_bert_relation_extraction/) <img src=\"https://img.icons8.com/color/48/undefined/gitlab.png\"/>\n",
    "# ![#f03c15](https://via.placeholder.com/15/f03c15/000000?text=+) [**NLP - Bert Relation Extraction Biomedical**](https://gitlab.com/research.dimas/nlp_bert_relation_extraction/)"
   ],
   "metadata": {
    "id": "QBZWC4JOLUfM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "# \"*Alone we can do so little, together we can do so much*\""
   ],
   "metadata": {
    "id": "ThHpTmKTZC4Y"
   }
  }
 ]
}